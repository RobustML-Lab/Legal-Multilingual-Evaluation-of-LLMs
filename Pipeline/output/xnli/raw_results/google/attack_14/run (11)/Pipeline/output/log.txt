README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 111MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  42%|####1     | 21.0M/50.2M [00:00<00:00, 186MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 231MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 219MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 248MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 346MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###1      | 125000/392702 [00:00<00:00, 1241735.39 examples/s]Generating train split:  65%|######5   | 256000/392702 [00:00<00:00, 1274315.97 examples/s]Generating train split:  99%|#########8| 387000/392702 [00:00<00:00, 1282963.57 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1274217.05 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1170536.04 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1024807.87 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 399kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 5.36MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 87.0MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 29.6MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/440M [00:00<00:08, 50.3MB/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:03, 105MB/s] model.safetensors:  12%|#1        | 52.4M/440M [00:00<00:02, 132MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:02, 148MB/s]model.safetensors:  21%|##1       | 94.4M/440M [00:00<00:02, 157MB/s]model.safetensors:  26%|##6       | 115M/440M [00:00<00:02, 158MB/s] model.safetensors:  31%|###       | 136M/440M [00:00<00:01, 163MB/s]model.safetensors:  36%|###5      | 157M/440M [00:01<00:01, 165MB/s]model.safetensors:  40%|####      | 178M/440M [00:01<00:01, 168MB/s]model.safetensors:  45%|####5     | 199M/440M [00:01<00:01, 171MB/s]model.safetensors:  50%|####9     | 220M/440M [00:01<00:01, 173MB/s]model.safetensors:  55%|#####4    | 241M/440M [00:01<00:01, 174MB/s]model.safetensors:  60%|#####9    | 262M/440M [00:01<00:01, 174MB/s]model.safetensors:  64%|######4   | 283M/440M [00:01<00:00, 174MB/s]model.safetensors:  69%|######9   | 304M/440M [00:01<00:00, 176MB/s]model.safetensors:  74%|#######3  | 325M/440M [00:02<00:00, 177MB/s]model.safetensors:  79%|#######8  | 346M/440M [00:02<00:00, 176MB/s]model.safetensors:  83%|########3 | 367M/440M [00:02<00:00, 176MB/s]model.safetensors:  88%|########8 | 388M/440M [00:02<00:00, 175MB/s]model.safetensors:  93%|#########2| 409M/440M [00:02<00:00, 174MB/s]model.safetensors:  98%|#########7| 430M/440M [00:02<00:00, 175MB/s]model.safetensors: 100%|##########| 440M/440M [00:02<00:00, 164MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '2\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n']
Saved predictions to: predicted.json
Accuracy en: 0.485
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  28%|##8       | 21.0M/73.8M [00:00<00:00, 101MB/s]train-00000-of-00001.parquet:  85%|########5 | 62.9M/73.8M [00:00<00:00, 211MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 194MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 263MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 245MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  21%|##1       | 83000/392702 [00:00<00:00, 824797.51 examples/s]Generating train split:  44%|####3     | 172000/392702 [00:00<00:00, 853321.20 examples/s]Generating train split:  66%|######6   | 260000/392702 [00:00<00:00, 857989.02 examples/s]Generating train split:  89%|########8 | 349000/392702 [00:00<00:00, 867719.47 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 861876.99 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 923384.59 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 773215.14 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 21.9kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 3.52MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 46.2MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 979kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   9%|9         | 41.9M/454M [00:00<00:01, 348MB/s]pytorch_model.bin:  18%|#8        | 83.9M/454M [00:00<00:01, 354MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:00, 351MB/s] pytorch_model.bin:  37%|###6      | 168M/454M [00:00<00:00, 358MB/s]pytorch_model.bin:  46%|####6     | 210M/454M [00:00<00:00, 352MB/s]pytorch_model.bin:  55%|#####5    | 252M/454M [00:00<00:00, 349MB/s]pytorch_model.bin:  65%|######4   | 294M/454M [00:00<00:00, 347MB/s]pytorch_model.bin:  74%|#######3  | 336M/454M [00:00<00:00, 345MB/s]pytorch_model.bin:  83%|########3 | 377M/454M [00:01<00:00, 350MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:01<00:00, 353MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 348MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '0\n', '1\n', '0\n', '0\n', '1\n', '0\n', '2\n', '2\n', '0\n', '1\n', '2\n', '2\n', '1\n', '1\n', '2\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_1.json
Accuracy el: 0.46
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  32%|###2      | 21.0M/65.4M [00:00<00:00, 144MB/s]train-00000-of-00001.parquet:  80%|########  | 52.4M/65.4M [00:00<00:00, 201MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 205MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 72.1MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 217MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  23%|##2       | 89000/392702 [00:00<00:00, 878654.99 examples/s]Generating train split:  47%|####7     | 185000/392702 [00:00<00:00, 925079.37 examples/s]Generating train split:  71%|#######1  | 279000/392702 [00:00<00:00, 926521.53 examples/s]Generating train split:  95%|#########4| 372000/392702 [00:00<00:00, 926852.49 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 921247.13 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 967515.22 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 887551.37 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 549kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 6.72MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 12.5MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 61.8MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   2%|1         | 10.5M/672M [00:00<00:12, 54.8MB/s]model.safetensors:   5%|4         | 31.5M/672M [00:00<00:05, 110MB/s] model.safetensors:   8%|7         | 52.4M/672M [00:00<00:04, 134MB/s]model.safetensors:  11%|#         | 73.4M/672M [00:00<00:04, 147MB/s]model.safetensors:  14%|#4        | 94.4M/672M [00:00<00:03, 155MB/s]model.safetensors:  17%|#7        | 115M/672M [00:00<00:03, 160MB/s] model.safetensors:  20%|##        | 136M/672M [00:00<00:03, 162MB/s]model.safetensors:  23%|##3       | 157M/672M [00:01<00:03, 165MB/s]model.safetensors:  27%|##6       | 178M/672M [00:01<00:02, 166MB/s]model.safetensors:  30%|##9       | 199M/672M [00:01<00:02, 166MB/s]model.safetensors:  33%|###2      | 220M/672M [00:01<00:02, 165MB/s]model.safetensors:  36%|###5      | 241M/672M [00:01<00:02, 165MB/s]model.safetensors:  39%|###8      | 262M/672M [00:01<00:02, 167MB/s]model.safetensors:  42%|####2     | 283M/672M [00:01<00:02, 168MB/s]model.safetensors:  45%|####5     | 304M/672M [00:01<00:02, 170MB/s]model.safetensors:  48%|####8     | 325M/672M [00:02<00:02, 164MB/s]model.safetensors:  51%|#####1    | 346M/672M [00:02<00:02, 163MB/s]model.safetensors:  55%|#####4    | 367M/672M [00:02<00:01, 166MB/s]model.safetensors:  58%|#####7    | 388M/672M [00:02<00:01, 168MB/s]model.safetensors:  61%|######    | 409M/672M [00:02<00:01, 167MB/s]model.safetensors:  64%|######3   | 430M/672M [00:02<00:01, 168MB/s]model.safetensors:  67%|######7   | 451M/672M [00:02<00:01, 166MB/s]model.safetensors:  70%|#######   | 472M/672M [00:02<00:01, 168MB/s]model.safetensors:  73%|#######3  | 493M/672M [00:03<00:01, 168MB/s]model.safetensors:  76%|#######6  | 514M/672M [00:03<00:00, 169MB/s]model.safetensors:  80%|#######9  | 535M/672M [00:03<00:00, 168MB/s]model.safetensors:  83%|########2 | 556M/672M [00:03<00:00, 170MB/s]model.safetensors:  86%|########5 | 577M/672M [00:03<00:00, 170MB/s]model.safetensors:  89%|########8 | 598M/672M [00:03<00:00, 172MB/s]model.safetensors:  92%|#########2| 619M/672M [00:03<00:00, 160MB/s]model.safetensors:  95%|#########5| 640M/672M [00:03<00:00, 164MB/s]model.safetensors:  98%|#########8| 661M/672M [00:04<00:00, 167MB/s]model.safetensors: 100%|##########| 672M/672M [00:04<00:00, 162MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', 'Отговорът е 1.\n\nПървото изречение описва ситуация, в която вратите са заключени, а второто изречение описва ситуация, в която някои врати са отворени.  Двете изречения не се включват взаимно, нито си противоречат.  Те просто описват различни ситуации.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', 'Предложението "когато имаше оно, което можех да направя" предполага, че е имало нещо, което може да се направи.  Предложението "това, че нищо не е да направя" твърди обратното – че няма нищо, което може да се направи.  Тези двете твърдения си противоречат.\n\nОтговор: 2\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '0\n', '0\n', '0\n', '0\n', '2\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n']
Saved predictions to: predicted_2.json
Accuracy bg: 0.435
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  20%|#9        | 10.5M/53.2M [00:00<00:00, 55.2MB/s]train-00000-of-00001.parquet:  59%|#####9    | 31.5M/53.2M [00:00<00:00, 112MB/s] train-00000-of-00001.parquet:  99%|#########8| 52.4M/53.2M [00:00<00:00, 129MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 116MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 190MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 320MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  28%|##8       | 111000/392702 [00:00<00:00, 1090077.51 examples/s]Generating train split:  58%|#####8    | 229000/392702 [00:00<00:00, 1137752.99 examples/s]Generating train split:  89%|########9 | 351000/392702 [00:00<00:00, 1169759.22 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1159631.48 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1106554.14 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 898470.14 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.37MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 5.54MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 2.98MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 65.9MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.04MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   5%|4         | 21.0M/440M [00:00<00:02, 184MB/s]pytorch_model.bin:  10%|9         | 41.9M/440M [00:00<00:02, 181MB/s]pytorch_model.bin:  14%|#4        | 62.9M/440M [00:00<00:02, 179MB/s]pytorch_model.bin:  19%|#9        | 83.9M/440M [00:00<00:01, 179MB/s]pytorch_model.bin:  24%|##3       | 105M/440M [00:00<00:01, 178MB/s] pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:01, 175MB/s]pytorch_model.bin:  33%|###3      | 147M/440M [00:00<00:01, 174MB/s]pytorch_model.bin:  38%|###8      | 168M/440M [00:00<00:01, 176MB/s]pytorch_model.bin:  43%|####2     | 189M/440M [00:01<00:01, 176MB/s]pytorch_model.bin:  48%|####7     | 210M/440M [00:01<00:01, 177MB/s]pytorch_model.bin:  52%|#####2    | 231M/440M [00:01<00:01, 169MB/s]pytorch_model.bin:  57%|#####7    | 252M/440M [00:01<00:01, 152MB/s]pytorch_model.bin:  62%|######2   | 273M/440M [00:01<00:01, 156MB/s]pytorch_model.bin:  67%|######6   | 294M/440M [00:01<00:00, 162MB/s]pytorch_model.bin:  72%|#######1  | 315M/440M [00:01<00:00, 166MB/s]pytorch_model.bin:  76%|#######6  | 336M/440M [00:01<00:00, 169MB/s]pytorch_model.bin:  81%|########1 | 357M/440M [00:02<00:00, 172MB/s]pytorch_model.bin:  86%|########5 | 377M/440M [00:02<00:00, 169MB/s]pytorch_model.bin:  91%|######### | 398M/440M [00:02<00:00, 171MB/s]pytorch_model.bin:  95%|#########5| 419M/440M [00:02<00:00, 158MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:02<00:00, 158MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:02<00:00, 167MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', 'La respuesta es 2.\n\nLa premisa anterior (5 hijos, 4 murieron) contradice la premisa posterior (todos los hijos sobrevivieron).\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa "¡y en realidad era ligera!" sugiere que algo era inesperadamente ligero.  La conclusión "ella no dura mucho" sugiere que algo tiene una corta vida útil. No hay una relación lógica de implicación ni contradicción entre la ligereza de un objeto y su durabilidad.  Por lo tanto, la premisa ni implica ni contradice la hipótesis.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '0\n', '2\n', '0\n', '1\n', '2\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_3.json
Accuracy es: 0.495
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  38%|###7      | 21.0M/55.4M [00:00<00:00, 102MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 201MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 180MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 40.9MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 388MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###1      | 122000/392702 [00:00<00:00, 1201050.32 examples/s]Generating train split:  62%|######2   | 244000/392702 [00:00<00:00, 1205150.23 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1183418.78 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1187483.15 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1112706.54 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 992098.12 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 235kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 5.20MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 26.1MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 45.1MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/445M [00:00<00:09, 43.5MB/s]model.safetensors:  12%|#1        | 52.4M/445M [00:00<00:02, 174MB/s] model.safetensors:  21%|##1       | 94.4M/445M [00:00<00:01, 244MB/s]model.safetensors:  31%|###       | 136M/445M [00:00<00:01, 288MB/s] model.safetensors:  40%|####      | 178M/445M [00:00<00:00, 315MB/s]model.safetensors:  49%|####9     | 220M/445M [00:00<00:00, 324MB/s]model.safetensors:  59%|#####8    | 262M/445M [00:00<00:00, 332MB/s]model.safetensors:  68%|######8   | 304M/445M [00:01<00:00, 327MB/s]model.safetensors:  78%|#######7  | 346M/445M [00:01<00:00, 332MB/s]model.safetensors:  87%|########7 | 388M/445M [00:01<00:00, 337MB/s]model.safetensors:  97%|#########6| 430M/445M [00:01<00:00, 340MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 300MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '0\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.41
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  27%|##7       | 21.0M/76.5M [00:00<00:00, 107MB/s]train-00000-of-00001.parquet:  69%|######8   | 52.4M/76.5M [00:00<00:00, 182MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 198MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 298MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 318MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  19%|#9        | 75000/392702 [00:00<00:00, 740927.91 examples/s]Generating train split:  40%|####      | 159000/392702 [00:00<00:00, 793699.36 examples/s]Generating train split:  62%|######1   | 243000/392702 [00:00<00:00, 810147.65 examples/s]Generating train split:  92%|#########1| 360000/392702 [00:00<00:00, 789961.81 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 792412.01 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 779084.35 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 711044.18 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 1.77MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 4.43MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 30.9MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/423M [00:00<00:04, 93.9MB/s]model.safetensors:   5%|4         | 21.0M/423M [00:00<00:04, 99.2MB/s]model.safetensors:  12%|#2        | 52.4M/423M [00:00<00:01, 193MB/s] model.safetensors:  20%|#9        | 83.9M/423M [00:00<00:01, 199MB/s]model.safetensors:  27%|##7       | 115M/423M [00:00<00:01, 233MB/s] model.safetensors:  35%|###4      | 147M/423M [00:00<00:01, 252MB/s]model.safetensors:  45%|####4     | 189M/423M [00:00<00:00, 283MB/s]model.safetensors:  54%|#####4    | 231M/423M [00:00<00:00, 304MB/s]model.safetensors:  64%|######4   | 273M/423M [00:01<00:00, 302MB/s]model.safetensors:  72%|#######1  | 304M/423M [00:01<00:00, 288MB/s]model.safetensors:  79%|#######9  | 336M/423M [00:01<00:00, 274MB/s]model.safetensors:  87%|########6 | 367M/423M [00:01<00:00, 267MB/s]model.safetensors:  94%|#########4| 398M/423M [00:01<00:00, 269MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 256MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['คำตอบคือ 1\n', '0\n', '2\n', '0\n', '2\n', 'คำตอบคือ **2**\n\nหลักฐานแสดงให้เห็นว่าผู้เขียนไม่มีสิทธิพิเศษและได้รับการปฏิบัติอย่างเท่าเทียมกัน  นี่ขัดแย้งกับสมมติฐานที่อาจสันนิษฐานว่าพวกเขาได้รับสิทธิพิเศษหรือการปฏิบัติที่แตกต่างออกไป\n', '2\nหลักฐานแสดงให้เห็นว่ามีคนบอกผู้พูดว่าอีกคนจะติดต่อพวกเขา  นี่ขัดแย้งกับสมมติฐานที่ว่าผู้พูดไม่เคยพูดคุยเรื่องการประชุมกับใคร\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าคนคนนั้นมาช้า  สมมติฐานคือเขาอาจมาช้า  หลักฐานไม่ได้ยืนยันหรือปฏิเสธสมมติฐานอย่างชัดเจน แต่เป็นเพียงการเสนอความเป็นไปได้หนึ่ง  ดังนั้นจึงเป็นความขัดแย้ง\n', '2\n', '2\n', '1\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานแสดงถึงความไม่แน่ใจและการขาดความรู้ ซึ่งสอดคล้องกับสมมติฐานที่ว่าคนๆ นั้นไม่แน่ใจว่าทำไมถึงต้องย้าย', '0\n', '2\n', '1\n', '0\n', '2\n', '2\n', 'คำตอบคือ 0\n\nข้อความแสดงความลำบากใจและความยากลำบากในการขออะไรบางอย่าง  ซึ่งไม่สนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ  ไม่มีข้อมูลที่เกี่ยวข้องกับสมมติฐานใดๆในข้อความนี้  ดังนั้น จึงเป็น 0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดเป็นเพียงคนเดียวที่ดำเนินการกับหน่วยควบคุมสำหรับสัญญาทางคณิตศาสตร์ระดับสูงหรือสมมติฐาน ในทางกลับกัน สมมติฐานระบุว่าผู้พูดไม่ต้องการที่จะเป็นคนเดียวที่ดำเนินนโยบายเกี่ยวกับมัน  สิ่งนี้แสดงให้เห็นถึงความขัดแย้งกัน  หลักฐานกล่าวว่าเป็นเช่นนั้นแล้วในขณะที่สมมติฐานแสดงความปรารถนาที่ตรงกันข้าม\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่ามีบุคคลจำนวนน้อย (ผู้เขียนข้อความ) ที่เกี่ยวข้องกับการควบคุม ซึ่งสนับสนุนสมมติฐานที่ว่ามีเพียงไม่กี่คนที่ดำเนินนโยบายเกี่ยวกับการควบคุม\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดเป็นพันจ่าอากาศโทที่เกษียณแล้ว  ซึ่งไม่สนับสนุนหรือขัดแย้งกับสมมติฐานที่ว่า "[3] ยังคงทำงานอยู่ทุกวันนี้"  หลักฐานแค่ให้ข้อมูลเกี่ยวกับสถานะการเกษียณของผู้พูดเท่านั้น  ไม่เกี่ยวข้องกับบุคคลที่ระบุในสมมติฐาน  ([3])\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุเพียงว่ามีการประมาณการกระแสเงินสดและลูกค้ารายหนึ่งชื่อแคทตี้ทำรายได้ 10,000 ดอลลาร์ต่อเดือน  ไม่มีข้อมูลที่เกี่ยวข้องกับสมมติฐานใดๆ  ดังนั้นจึงไม่เกี่ยวข้องและไม่ขัดแย้ง\n', '0\n', '2\n', 'คำตอบคือ 2\n', '2\n', '2\n', 'คำตอบคือ **2**\n\nหลักฐานแสดงให้เห็นว่ามีการแบ่งประชาชนตามการทำงาน (ลูกจ้างในท้องนา vs. คนงานบ้าน) ซึ่งขัดแย้งกับสมมติฐานที่ว่าทุกคนตกลงกันที่จะทำงานในไร่  สมมติฐานระบุถึงความเห็นพ้องต้องกัน แต่หลักฐานแสดงให้เห็นถึงการแบ่งแยกทางสังคมและการทำงานที่ไม่สอดคล้องกับสมมติฐาน\n', '0\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐานว่ามีการแบ่งแยกแรงงานระหว่างประชากรในพื้นที่และคนรับใช้ และความขัดแย้งเกี่ยวกับการแบ่งงานนั้นแสดงให้เห็นว่าการแบ่งแยกแรงงานนั้นไม่ชัดเจนหรือไม่แน่นอน', '0\nหลักฐานระบุว่ามีการวางแผนการพูดคุย แต่ไม่ได้บอกว่าเขาได้ตัดสินใจแล้วว่าจะพูดอะไรต่อไป  หลักฐานจึงไม่สนับสนุนหรือขัดแย้งกับสมมติฐาน\n', '1\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีลูกสาว 5 คน สมมติฐานกล่าวว่าหนึ่งในนั้นเสียชีวิต หลักฐานนั้นสนับสนุนสมมติฐานได้ แต่ไม่ได้พิสูจน์มัน  มีลูกสาว 5 คนไม่ขัดแย้งกับการเสียชีวิตของหนึ่งในนั้น\n', '0\n', '0\nหลักฐานระบุว่ามีภาพยนตร์อย่างน้อยสองเรื่องที่ใช้ไปแล้ว  แต่นี่ไม่ใช่หลักฐานที่สนับสนุนหรือขัดแย้งกับสมมติฐานที่ว่ายูทูได้รับภาพยนตร์จำนวนมาก  หลักฐานแสดงให้เห็นเพียงส่วนเล็กๆของภาพยนตร์ที่ยูทูอาจมีอยู่\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานแสดงให้เห็นว่าเธอร้องไห้และโจเห็นเธอที่ชานบ้าน  สมมติฐานกล่าวว่าเธอบอกให้โจขึ้นมาที่ระเบียง  หลักฐานสนับสนุนส่วนหนึ่งของสมมติฐาน (เธอร้องไห้) แต่ไม่ได้ยืนยันส่วนที่เหลือ (เธอเรียกโจขึ้นมาที่ระเบียง)  ดังนั้นจึงเป็นความสัมพันธ์ที่เกี่ยวข้องกัน แต่ไม่ใช่การยืนยันสมมติฐานอย่างสมบูรณ์\n', '2\n', '0\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าพลอากาศโทฟรานซิสเกษียณจากกองทัพอากาศสหรัฐฯ  สมมติฐานกล่าวถึงผู้นำชาวอเมริกันที่เกษียณอายุราชการเมื่อไม่กี่สัปดาห์ที่ผ่านมา  ในขณะที่ทั้งสองข้อความเกี่ยวข้องกับการเกษียณอายุ แต่ไม่ได้ระบุว่าพลอากาศโทฟรานซิสเป็นผู้นำของประเทศสหรัฐอเมริกา  ดังนั้นหลักฐานจึงไม่สนับสนุนหรือขัดแย้งกับสมมติฐานอย่างสมบูรณ์\n', '2\n', 'คำตอบคือ 0\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานกล่าวถึงการฝึกอบรมกับชุดความดันอากาศ  สมมติฐานกล่าวถึงระยะเวลาของการฝึกอบรม  ทั้งสองอย่างนั้นเกี่ยวข้องกับประสบการณ์ของผู้พูดในการฝึกอบรมชุดความดันอากาศ  แต่หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับระยะเวลาที่ระบุไว้ในสมมติฐาน\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานกล่าวถึงประสบการณ์ของบุคคลกับชุดสูทความดันอากาศ สมมติฐานมุ่งเน้นไปที่การให้แรงดันสูงภายในสิ้นวันนี้ หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานโดยตรง  จึงไม่เกี่ยวข้องกัน\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐานอย่างสมบูรณ์  หลักฐานระบุว่าไม่มีอันตรายใดๆจากการกระแทก  ซึ่งสอดคล้องกับสมมติฐานที่ว่าไม่มีโอกาสระเบิด  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', '2\nหลักฐานระบุว่าระเบิดนั้นปลอดภัยและจะไม่ระเบิด ขณะที่สมมติฐานระบุว่าระเบิดนั้นอันตรายมาก ดังนั้นจึงขัดแย้งกัน\n', '0\n', 'คำตอบคือ 1\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานบ่งชี้ว่าผู้พูดจำเป็นต้องรวบรวมตัวเลขเพื่อคำนวณบางสิ่งบางอย่าง สมมติฐานระบุว่าจำเป็นต้องมีผลรวมเพื่อแก้ปัญหา  ทั้งสองอย่างมีความสอดคล้องกัน  หลักฐานสนับสนุนสมมติฐาน\n', '1\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n', '2\n', 'หลักฐานแสดงให้เห็นถึงความผิดหวังของบุคคลนั้นซึ่งขัดแย้งกับสมมติฐานที่ว่าเขากำลังพยายามทำให้พวกเขารู้สึกไม่ผิด ดังนั้นคำตอบคือ **2**\n', 'คำตอบคือ 1\nหลักฐานทั้งสองชิ้นสนับสนุนสมมติฐานที่ว่าบุคคลนั้นรู้สึกผิดหวัง\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่า "ฉันไม่มีเรื่องใดเรื่องหนึ่งคือ: มีสินทรัพย์มากมาย"  ซึ่งขัดแย้งกับสมมติฐานที่ไม่ได้ระบุไว้ แต่โดยทั่วไปแล้ว สมมติฐานที่เกี่ยวข้องกับการมีสินทรัพย์มากมายจะถูกสันนิษฐานว่าเป็นจริง  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐานที่เป็นไปได้\n', 'คำตอบคือ 2\nหลักฐานระบุว่าเขาไม่ได้พัฒนาเลย  ซึ่งขัดแย้งกับสมมติฐานที่ว่าเขาได้รับความช่วยเหลือ  ถ้าเขาได้รับความช่วยเหลือ ก็ควรจะมีการพัฒนาบ้าง  ดังนั้นหลักฐานและสมมติฐานจึงขัดแย้งกัน\n', '2\n', 'คำตอบคือ 1\n', 'คำตอบคือ 1\n', '2\n', '2\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้เขียนไม่แน่ใจว่าบุคคลนั้นอาศัยอยู่ที่ Ojita หรือไม่หลังจากนั้น สมมติฐานระบุว่าบุคคลนั้นยังคงอาศัยอยู่ใน Ojita สมมติฐานนั้นไม่สามารถยืนยันหรือปฏิเสธได้โดยใช้หลักฐานที่ให้มา ดังนั้นหลักฐานจึงไม่เกี่ยวข้องกับสมมติฐานหรือขัดแย้งกับสมมติฐาน\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลเหล่านี้ไม่เคยถูกสังเกตเห็นว่าไปที่ใดหรือเพิ่มสถานที่ที่พวกเขาไปแม้แต่เมื่อออกจากปลายทางสุดท้ายไปยังที่อื่นเพื่อพักอยู่สักระยะ สมมติฐานถามว่าพวกเขาจะไปที่ไหน หลักฐานจึงขัดแย้งกับสมมติฐานเพราะหลักฐานกล่าวว่าเราไม่รู้ว่าพวกเขาไปไหนในขณะที่สมมติฐานถามเกี่ยวกับสถานที่ที่พวกเขาไป\n', '2\n', '0\n', '2\n', '2\n', '2\n', '1\n', '2\n', '2\n', '0\n', '0\n', '2\n', '0\n', '0\n', '2\nหลักฐานแสดงให้เห็นว่าปู่ย่าตายายและพ่อแม่ของผู้เขียนเป็นคนโรแมนติกและผู้เขียนมีความสุขที่บ้านของพวกเขา  สมมติฐานระบุว่าปู่ย่าตายายของผู้เขียนมักจะบ้าบอ  หลักฐานและสมมติฐานไม่เกี่ยวข้องกัน  ดังนั้นคำตอบจึงคือ 2\n', '0\n', '0\n', '0\n', '2\n', '0\n', '1\n', '0\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐานที่ว่ามีการใช้ชุดปรับความดันที่คล้ายกับของนักบินอวกาศ แต่มีการปรับเปลี่ยนด้านวัสดุ (เงินสะท้อนความร้อน)', '2\n', '1\n', '2\n', '2\n', 'คำตอบคือ 2\nหลักฐานระบุว่ามีการฝึกนักบินร่วมกับนักบินอังกฤษ ซึ่งขัดแย้งกับสมมติฐานที่ว่าไม่มีการฝึกฝนร่วมกับใคร\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีการฝึกนักบินอังกฤษในเครื่องบินจำนวนหนึ่ง สมมติฐานระบุว่าในเดือนเมษายนมีการฝึกนักบินอังกฤษ 5 คนเต็ม หลักฐานไม่ได้ระบุจำนวนนักบินที่ฝึกหรือระยะเวลาของการฝึก จึงไม่สามารถยืนยันหรือหักล้างสมมติฐานได้  หลักฐานและสมมติฐานมีความเกี่ยวข้องกันในระดับหนึ่ง แต่ไม่เพียงพอที่จะยืนยันหรือปฏิเสธสมมติฐาน\n', '1\n', '2\n', '2\nหลักฐานที่ว่า "ไม่มี" ขัดแย้งกับสมมติฐานที่บอกให้หาบางอย่าง\n', '0\n', 'คำตอบคือ 0\n', '0\n', '0\n', '1\n', '2\n', '2\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานอธิบายถึงการเปลี่ยนแปลงทางอารมณ์จากความสุขไปสู่ความยากลำบาก ซึ่งสนับสนุนสมมติฐาน\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nการใช้ "วัตถุดิบใหม่" ขัดแย้งกับการ "ปกปิดเรื่องเดิม"  ทั้งสองอย่างนี้เป็นเหตุการณ์ที่ไม่สอดคล้องกัน\n', '2\n', '2\n', '2\n', '0\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานและสมมติฐานขัดแย้งกัน  หลักฐานระบุว่ามีบางสิ่งที่ผู้พูดสามารถทำได้ ในขณะที่สมมติฐานกล่าวว่าไม่มีอะไรที่ใครๆทำได้\n', '0\n', 'คำตอบคือ 2\nหลักฐานระบุว่าเธอเคยบอกน้องสาวของเธอว่ากำลังทำผิด ซึ่งขัดแย้งกับสมมติฐานที่ว่าเธอให้กำลังใจหลานสาวของเธอเสมอ', '2\n', '0\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุถึงการกระทำที่ดำเนินการ (ไปสถานที่และโทรศัพท์)  แต่ไม่ได้ให้ข้อมูลเพียงพอที่จะระบุว่ามันสนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ  มันเป็นเพียงข้อมูลที่เป็นกลาง  จึงไม่ถือว่าสนับสนุนหรือขัดแย้ง\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดเคยไปที่นั่นในตอนเช้าแล้วลืมเหตุการณ์ที่เกิดขึ้น  สมมติฐานระบุว่าผู้พูดไม่ได้ไปที่นั่นในวันนั้น ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '0\n', 'คำตอบคือ 1\n', '0\n', 'คำตอบคือ 2\nหลักฐานระบุตำแหน่งที่แน่นอนที่พวกเขากำลังจะไป ในขณะที่สมมติฐานนั้นเป็นเพียงการคาดเดาโดยไม่ทราบสถานที่ปลายทางที่แน่นอน  ดังนั้นหลักฐานและสมมติฐานจึงขัดแย้งกัน\n', '2\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดกำลังจะไปทานอาหารกลางวัน  สมมติฐานระบุว่าผู้พูดคิดถึงอาหารเย็น  สองอย่างนี้ขัดแย้งกัน', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้เขียนกำลังจะเลิกสมมติฐาน  นั่นเป็นความขัดแย้ง', 'คำตอบคือ 1', 'คำตอบคือ 1\n', 'คำตอบคือ 0\n', '2\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี ค.ศ. 1880 กว่าๆ ในขณะที่สมมติฐานระบุว่าบุคคลนั้นเกิดในปี ค.ศ. 1984  ข้อมูลทั้งสองนี้ขัดแย้งกันอย่างชัดเจน\n', '2\n', '2\n', '2\n', '0\n', '2\n', '0\n', 'นี่คือคำตอบ: 2\n\nหลักฐานระบุว่าเด็กๆ ไม่สามารถดื่มแชมเปญได้ สมมติฐานคือเด็กๆ ดื่มแชมเปญไปจำนวนหนึ่ง  ข้อความทั้งสองนี้ขัดแย้งกัน\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าทุกคนได้รับแชมเปญและบางคนไม่ได้ดื่มมัน นอกจากนี้ยังระบุว่าเด็ก ๆ ไม่ดื่มนม แต่ดื่มแชมเปญแทน\n\nสมมติฐานระบุว่าเด็ก ๆ ดื่มแชมเปญเอง\n\nหลักฐานสนับสนุนสมมติฐาน เพราะมันระบุว่าเด็ก ๆ ดื่มแชมเปญแทนที่จะดื่มนม  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐานอย่างสมบูรณ์\n', 'หลักฐานระบุว่ามีการเสิร์ฟแชมเปญ ซึ่งเป็นเครื่องดื่มแอลกอฮอล์ ดังนั้นหลักฐานจึงสนับสนุนสมมติฐานที่ว่ามีการเสิร์ฟเครื่องดื่มแอลกอฮอล์  คำตอบคือ **1**\n', '2\n', '0\n', '0\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 0. หลักฐานนั้นสอดคล้องกับสมมติฐาน\n', 'คำตอบคือ 1\n', '2\n', '0\n']
Saved predictions to: predicted_5.json
Accuracy th: 0.465
'XNLI' object has no attribute 'evaluate_results'
