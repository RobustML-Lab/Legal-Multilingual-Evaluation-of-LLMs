README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 59.3MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  42%|####1     | 21.0M/50.2M [00:00<00:00, 179MB/s]train-00000-of-00001.parquet:  84%|########3 | 41.9M/50.2M [00:00<00:00, 187MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 194MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 308MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 371MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###2      | 126000/392702 [00:00<00:00, 1189889.55 examples/s]Generating train split:  65%|######4   | 254000/392702 [00:00<00:00, 1234662.21 examples/s]Generating train split:  99%|#########9| 390000/392702 [00:00<00:00, 1289150.93 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1267066.40 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1223064.03 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1082148.69 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 469kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 4.84MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 34.3MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 33.9MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:01, 245MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:01, 298MB/s]model.safetensors:  26%|##6       | 115M/440M [00:00<00:01, 320MB/s] model.safetensors:  36%|###5      | 157M/440M [00:00<00:00, 328MB/s]model.safetensors:  45%|####5     | 199M/440M [00:00<00:00, 333MB/s]model.safetensors:  55%|#####4    | 241M/440M [00:00<00:00, 337MB/s]model.safetensors:  64%|######4   | 283M/440M [00:00<00:00, 337MB/s]model.safetensors:  74%|#######3  | 325M/440M [00:00<00:00, 340MB/s]model.safetensors:  83%|########3 | 367M/440M [00:01<00:00, 340MB/s]model.safetensors:  93%|#########2| 409M/440M [00:01<00:00, 342MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 330MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '2\n', '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 8
Accuracy en: 0.390625
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  28%|##8       | 21.0M/73.8M [00:00<00:00, 110MB/s]train-00000-of-00001.parquet:  57%|#####6    | 41.9M/73.8M [00:00<00:00, 141MB/s]train-00000-of-00001.parquet:  99%|#########9| 73.4M/73.8M [00:00<00:00, 185MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 165MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 231MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 90.7MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##4       | 95000/392702 [00:00<00:00, 932189.67 examples/s]Generating train split:  49%|####8     | 192000/392702 [00:00<00:00, 944478.58 examples/s]Generating train split:  73%|#######3  | 288000/392702 [00:00<00:00, 945266.74 examples/s]Generating train split:  98%|#########8| 385000/392702 [00:00<00:00, 951783.04 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 946423.30 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 869726.54 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 857034.05 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 18.5kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 4.32MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 8.53MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 851kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   7%|6         | 31.5M/454M [00:00<00:01, 241MB/s]pytorch_model.bin:  14%|#3        | 62.9M/454M [00:00<00:01, 248MB/s]pytorch_model.bin:  21%|##        | 94.4M/454M [00:00<00:01, 250MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:01, 253MB/s] pytorch_model.bin:  35%|###4      | 157M/454M [00:00<00:01, 253MB/s]pytorch_model.bin:  42%|####1     | 189M/454M [00:00<00:01, 248MB/s]pytorch_model.bin:  48%|####8     | 220M/454M [00:00<00:00, 250MB/s]pytorch_model.bin:  55%|#####5    | 252M/454M [00:01<00:00, 251MB/s]pytorch_model.bin:  62%|######2   | 283M/454M [00:01<00:00, 252MB/s]pytorch_model.bin:  69%|######9   | 315M/454M [00:01<00:00, 250MB/s]pytorch_model.bin:  76%|#######6  | 346M/454M [00:01<00:00, 252MB/s]pytorch_model.bin:  83%|########3 | 377M/454M [00:01<00:00, 256MB/s]pytorch_model.bin:  90%|######### | 409M/454M [00:01<00:00, 260MB/s]pytorch_model.bin:  97%|#########6| 440M/454M [00:01<00:00, 258MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 252MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '2\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '2\n', '0\n', '1\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '2\n', '2\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n']
Saved predictions to: predicted_1.json
Accuracy el: 0.43
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  16%|#6        | 10.5M/65.4M [00:00<00:00, 94.5MB/s]train-00000-of-00001.parquet:  32%|###2      | 21.0M/65.4M [00:00<00:00, 100MB/s] train-00000-of-00001.parquet:  80%|########  | 52.4M/65.4M [00:00<00:00, 183MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 177MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 199MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 364MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  26%|##5       | 102000/392702 [00:00<00:00, 1012330.59 examples/s]Generating train split:  52%|#####1    | 204000/392702 [00:00<00:00, 1010120.36 examples/s]Generating train split:  79%|#######8  | 309000/392702 [00:00<00:00, 1020674.15 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1018719.52 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 978918.43 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 838524.04 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 399kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 4.45MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 34.5MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 29.4MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   3%|3         | 21.0M/672M [00:00<00:04, 151MB/s]model.safetensors:   8%|7         | 52.4M/672M [00:00<00:02, 222MB/s]model.safetensors:  14%|#4        | 94.4M/672M [00:00<00:02, 270MB/s]model.safetensors:  20%|##        | 136M/672M [00:00<00:01, 295MB/s] model.safetensors:  27%|##6       | 178M/672M [00:00<00:01, 306MB/s]model.safetensors:  33%|###2      | 220M/672M [00:00<00:01, 318MB/s]model.safetensors:  39%|###8      | 262M/672M [00:00<00:01, 321MB/s]model.safetensors:  45%|####5     | 304M/672M [00:01<00:01, 326MB/s]model.safetensors:  51%|#####1    | 346M/672M [00:01<00:00, 330MB/s]model.safetensors:  58%|#####7    | 388M/672M [00:01<00:00, 330MB/s]model.safetensors:  64%|######3   | 430M/672M [00:01<00:00, 329MB/s]model.safetensors:  70%|#######   | 472M/672M [00:01<00:00, 326MB/s]model.safetensors:  76%|#######6  | 514M/672M [00:01<00:00, 321MB/s]model.safetensors:  83%|########2 | 556M/672M [00:01<00:00, 325MB/s]model.safetensors:  89%|########8 | 598M/672M [00:01<00:00, 328MB/s]model.safetensors:  95%|#########5| 640M/672M [00:02<00:00, 328MB/s]model.safetensors: 100%|##########| 672M/672M [00:02<00:00, 313MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', 'Отговорът е 1.\n\nПредположението описва ситуация, в която работата изглежда добре, но не се изпълнява напълно, и е свързана с трудностите да се завърши проектът навреме. Хипотезата не е дефинирана, поради което не може да се определи дали предположението я включва, противоречи или не е свързано с нея.\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '2\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_2.json
Accuracy bg: 0.46
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  39%|###9      | 21.0M/53.2M [00:00<00:00, 191MB/s]train-00000-of-00001.parquet:  99%|#########8| 52.4M/53.2M [00:00<00:00, 256MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 240MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 259MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 250MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###2      | 127000/392702 [00:00<00:00, 1255978.02 examples/s]Generating train split:  65%|######5   | 257000/392702 [00:00<00:00, 1273447.91 examples/s]Generating train split:  99%|#########8| 387000/392702 [00:00<00:00, 1279081.57 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1272664.42 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1216056.89 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1034143.67 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.17MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 4.84MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 13.6MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 15.9MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.17MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   7%|7         | 31.5M/440M [00:00<00:01, 251MB/s]pytorch_model.bin:  14%|#4        | 62.9M/440M [00:00<00:01, 250MB/s]pytorch_model.bin:  21%|##1       | 94.4M/440M [00:00<00:01, 255MB/s]pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:01, 262MB/s] pytorch_model.bin:  36%|###5      | 157M/440M [00:00<00:01, 259MB/s]pytorch_model.bin:  43%|####2     | 189M/440M [00:00<00:00, 260MB/s]pytorch_model.bin:  50%|#####     | 220M/440M [00:00<00:00, 267MB/s]pytorch_model.bin:  57%|#####7    | 252M/440M [00:00<00:00, 268MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:01<00:00, 272MB/s]pytorch_model.bin:  72%|#######1  | 315M/440M [00:01<00:00, 271MB/s]pytorch_model.bin:  79%|#######8  | 346M/440M [00:01<00:00, 264MB/s]pytorch_model.bin:  86%|########5 | 377M/440M [00:01<00:00, 264MB/s]pytorch_model.bin:  93%|#########3| 409M/440M [00:01<00:00, 266MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 271MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 264MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\n', '1\n', '1\n', '0\n', 'La respuesta es 1.\n\nLa premisa indica que el hablante creía tener un privilegio único relacionado con su número de serie (922t).  La hipótesis sugiere que este privilegio era una mentira y que todos tenían el mismo número.  La premisa no implica ni contradice directamente la hipótesis.  La creencia del hablante sobre su privilegio único es subjetiva y no prueba o refuta la afirmación de la hipótesis sobre la igualdad de los números de serie.\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa establece que el hablante cree que fue a la casa de alguien y luego se supone que debe llamar a un número. La hipótesis establece que se ordenó al hablante que llamara, pero no lo hizo.  La premisa no afirma ni niega si el hablante llamó o no.  Por lo tanto, la premisa no implica ni contradice la hipótesis.\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', 'La respuesta es 1.\n\nLa premisa describe una situación en la que alguien prueba un avión y aprende.  La hipótesis establece que la persona no sabe nada sobre probar aviones.  No hay implicación ni contradicción directa; simplemente son dos afirmaciones que describen diferentes estados de conocimiento.\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_3.json
Accuracy es: 0.46
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  57%|#####6    | 31.5M/55.4M [00:00<00:00, 242MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 237MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 185MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 46.9MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###       | 121000/392702 [00:00<00:00, 1191888.25 examples/s]Generating train split:  63%|######2   | 246000/392702 [00:00<00:00, 1218715.55 examples/s]Generating train split:  95%|#########4| 372000/392702 [00:00<00:00, 1233675.81 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1225549.50 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1156810.52 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 977885.48 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 263kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.04MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 25.5MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 33.6MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/445M [00:00<00:10, 41.7MB/s]model.safetensors:   5%|4         | 21.0M/445M [00:00<00:06, 63.0MB/s]model.safetensors:   7%|7         | 31.5M/445M [00:00<00:05, 72.2MB/s]model.safetensors:   9%|9         | 41.9M/445M [00:00<00:05, 76.7MB/s]model.safetensors:  12%|#1        | 52.4M/445M [00:00<00:05, 76.5MB/s]model.safetensors:  14%|#4        | 62.9M/445M [00:00<00:04, 78.8MB/s]model.safetensors:  16%|#6        | 73.4M/445M [00:00<00:04, 80.0MB/s]model.safetensors:  19%|#8        | 83.9M/445M [00:01<00:04, 79.2MB/s]model.safetensors:  21%|##1       | 94.4M/445M [00:01<00:04, 80.1MB/s]model.safetensors:  24%|##3       | 105M/445M [00:01<00:04, 80.2MB/s] model.safetensors:  26%|##5       | 115M/445M [00:01<00:04, 79.4MB/s]model.safetensors:  28%|##8       | 126M/445M [00:01<00:03, 79.8MB/s]model.safetensors:  31%|###       | 136M/445M [00:01<00:03, 79.6MB/s]model.safetensors:  33%|###2      | 147M/445M [00:01<00:03, 80.7MB/s]model.safetensors:  35%|###5      | 157M/445M [00:02<00:03, 81.5MB/s]model.safetensors:  38%|###7      | 168M/445M [00:02<00:03, 81.4MB/s]model.safetensors:  40%|####      | 178M/445M [00:02<00:03, 82.0MB/s]model.safetensors:  42%|####2     | 189M/445M [00:02<00:03, 82.7MB/s]model.safetensors:  45%|####4     | 199M/445M [00:02<00:03, 80.2MB/s]model.safetensors:  47%|####7     | 210M/445M [00:02<00:02, 80.8MB/s]model.safetensors:  49%|####9     | 220M/445M [00:02<00:02, 81.0MB/s]model.safetensors:  52%|#####1    | 231M/445M [00:02<00:02, 76.6MB/s]model.safetensors:  54%|#####4    | 241M/445M [00:03<00:02, 77.0MB/s]model.safetensors:  57%|#####6    | 252M/445M [00:03<00:02, 77.1MB/s]model.safetensors:  59%|#####8    | 262M/445M [00:03<00:02, 78.9MB/s]model.safetensors:  61%|######1   | 273M/445M [00:03<00:02, 79.4MB/s]model.safetensors:  64%|######3   | 283M/445M [00:03<00:01, 81.2MB/s]model.safetensors:  66%|######5   | 294M/445M [00:03<00:01, 82.4MB/s]model.safetensors:  68%|######8   | 304M/445M [00:03<00:01, 83.3MB/s]model.safetensors:  71%|#######   | 315M/445M [00:03<00:01, 84.3MB/s]model.safetensors:  73%|#######3  | 325M/445M [00:04<00:01, 83.0MB/s]model.safetensors:  75%|#######5  | 336M/445M [00:04<00:01, 83.7MB/s]model.safetensors:  78%|#######7  | 346M/445M [00:04<00:01, 85.1MB/s]model.safetensors:  80%|########  | 357M/445M [00:04<00:01, 85.6MB/s]model.safetensors:  82%|########2 | 367M/445M [00:04<00:00, 86.4MB/s]model.safetensors:  85%|########4 | 377M/445M [00:04<00:00, 86.9MB/s]model.safetensors:  87%|########7 | 388M/445M [00:04<00:00, 85.9MB/s]model.safetensors:  90%|########9 | 398M/445M [00:04<00:00, 85.7MB/s]model.safetensors:  92%|#########1| 409M/445M [00:05<00:00, 86.2MB/s]model.safetensors:  94%|#########4| 419M/445M [00:05<00:00, 78.9MB/s]model.safetensors:  97%|#########6| 430M/445M [00:05<00:00, 81.0MB/s]model.safetensors:  99%|#########8| 440M/445M [00:05<00:00, 83.0MB/s]model.safetensors: 100%|##########| 445M/445M [00:05<00:00, 80.4MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', None, '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '0\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '0\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '0\n', '0\n', '1\n', None, '1\n', '1\n', '0\n', '0\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '0\n']
Saved predictions to: predicted_4.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 13
Accuracy fr: 0.39037433155080214
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  41%|####1     | 31.5M/76.5M [00:00<00:00, 263MB/s]train-00000-of-00001.parquet:  82%|########2 | 62.9M/76.5M [00:00<00:00, 287MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 286MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 90.6MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 290MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  22%|##1       | 86000/392702 [00:00<00:00, 847290.35 examples/s]Generating train split:  45%|####4     | 175000/392702 [00:00<00:00, 864563.13 examples/s]Generating train split:  67%|######6   | 263000/392702 [00:00<00:00, 869718.84 examples/s]Generating train split:  90%|########9 | 352000/392702 [00:00<00:00, 872063.13 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 868356.47 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 925458.60 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 810981.28 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.92MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 4.34MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 25.1MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/423M [00:00<00:03, 115MB/s]model.safetensors:  12%|#2        | 52.4M/423M [00:00<00:04, 84.5MB/s]model.safetensors:  20%|#9        | 83.9M/423M [00:00<00:04, 84.6MB/s]model.safetensors:  25%|##4       | 105M/423M [00:01<00:03, 86.7MB/s] model.safetensors:  27%|##7       | 115M/423M [00:01<00:03, 88.9MB/s]model.safetensors:  32%|###2      | 136M/423M [00:01<00:03, 76.5MB/s]model.safetensors:  37%|###7      | 157M/423M [00:01<00:03, 79.7MB/s]model.safetensors:  45%|####4     | 189M/423M [00:02<00:02, 87.6MB/s]model.safetensors:  50%|####9     | 210M/423M [00:02<00:02, 76.3MB/s]model.safetensors:  57%|#####6    | 241M/423M [00:02<00:01, 91.7MB/s]model.safetensors:  62%|######1   | 262M/423M [00:03<00:01, 85.0MB/s]model.safetensors:  69%|######9   | 294M/423M [00:03<00:01, 95.6MB/s]model.safetensors:  74%|#######4  | 315M/423M [00:03<00:01, 82.6MB/s]model.safetensors:  82%|########1 | 346M/423M [00:04<00:00, 86.1MB/s]model.safetensors:  87%|########6 | 367M/423M [00:04<00:00, 85.5MB/s]model.safetensors:  94%|#########4| 398M/423M [00:04<00:00, 95.2MB/s]model.safetensors:  99%|#########9| 419M/423M [00:04<00:00, 91.6MB/s]model.safetensors: 100%|##########| 423M/423M [00:04<00:00, 88.0MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าแม้ว่าผู้พูดจะผิดหวังแต่ก็กลับไปคุยกับบุคคลนั้นอีกครั้ง  ซึ่งสนับสนุนสมมติฐานที่ว่าผู้พูดนั้นคาดหวังที่จะคุยกับบุคคลนั้นอีกครั้ง และความรู้สึกแย่ที่เกิดขึ้นนั้นก็เป็นผลมาจากการคาดหวังนี้\n', "ฉันต้องการสมมติฐานที่จะประเมินความสัมพันธ์กับหลักฐานที่ให้ไว้  หลักฐานแสดงความรู้สึกผิดหวังและความปรารถนาที่จะสื่อสารอีกครั้ง  ฉันไม่สามารถระบุได้ว่าหลักฐานนี้สนับสนุนหรือขัดแย้งกับสมมติฐานใดๆโดยไม่มีสมมติฐาน  ดังนั้น ฉันจึงไม่สามารถให้คำตอบได้ว่าเป็น '0', '1', หรือ '2'\n", '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดเป็นหนึ่งในเก้าคนที่มีสาขาอาชีพที่ไม่ชัดเจน (เนื่องจากมีคำที่ไม่รู้จัก)  สมมติฐานกล่าวว่าผู้พูดเชื่อว่าพวกเขาเป็นคนเดียวที่มีสาขาอาชีพนั้น  นี่เป็นข้อความที่ขัดแย้งกัน\n', '2\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n\nหลักฐานและสมมติฐานพูดถึงเรื่องเดียวกัน  คือ มีข้อมูลเพิ่มเติมเกี่ยวกับเรื่องนั้น แต่จะไม่พูดถึงมัน  หลักฐานยืนยันความคิดในสมมติฐาน\n', 'คำตอบคือ 0\n\nหลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐาน  หลักฐานเพียงแค่ระบุว่าจะอธิบายข้อกำหนด  ในขณะที่สมมติฐานระบุว่าจะไม่พูดถึงประวัติศาสตร์ของเมือง  ทั้งสองอย่างไม่เกี่ยวข้องกัน\n', '2\n', '2\n', '1\n', '0\n', '0\n', '1\n', '0\n', '0\n', '0\n', '0\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 2\nหลักฐานแสดงให้เห็นว่าผู้เขียนคิดว่าพวกเขากำลังใช้หน่วยควบคุมการทดสอบคนเดียว ในขณะที่สมมติฐานที่ไม่ปรากฏชัดในข้อความนั้นบ่งบอกถึงกลุ่มคนจำนวนหนึ่ง  นี่จึงเป็นความขัดแย้ง\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดเกษียณอายุแล้วจากตำแหน่งพันจ่าอากาศเอก สมมติฐานระบุว่าผู้พูดเกษียณก่อนอายุการทำงานครบกำหนด  หลักฐานไม่ได้บอกเราว่าผู้พูดเกษียณก่อนอายุการทำงานครบกำหนดหรือไม่ ดังนั้นจึงไม่เกี่ยวข้องหรือขัดแย้งกับสมมติฐาน\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานที่ว่าลูกค้ารายหนึ่งทำรายได้ 80,000 ดอลลาร์ต่อเดือนนั้นสนับสนุนสมมติฐานที่ว่ารายได้ของลูกค้าคือ 80,000 ดอลลาร์ต่อเดือน', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ 0  หลักฐานที่ให้มานั้นไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐาน  หลักฐานเป็นเพียงคำอธิบายถึงสิ่งที่โค้ชพูดคุย และไม่ได้ให้ข้อมูลเกี่ยวกับว่าโค้ชตัดสินใจจะพูดอะไรต่อ\n', '2\n', '2\n', '2\n', '0\n', '0\n', '0\n', '2\n', 'คำตอบคือ 0  หลักฐานที่ว่า "เรามีข้อมูลทั้งหมดจากภาพยนตร์ว่า <unk>2 ที่ใช้สมมติฐาน:พวกเราทีมวีดีโอ" บอกเป็นนัยว่าหลักฐานนั้นสนับสนุนสมมติฐาน (แม้ว่าจะเป็นหลักฐานที่ไม่ชัดเจนและมีข้อมูลที่ขาดหายไป) แต่ไม่ได้พิสูจน์หรือหักล้างสมมติฐานอย่างสิ้นเชิง  จึงเข้าร่วมกับสมมติฐาน\n', '2\n', 'คำตอบคือ 0 (เข้ากันได้)\n\nหลักฐานที่แสดงว่าน้ำตาไหลและโจกล่าวคำอำลาที่ระเบียงสอดคล้องกับสมมติฐานที่ว่าเธอเช็ดน้ำตาและผลักโจออกจากระเบียง  หลักฐานและสมมติฐานแสดงให้เห็นถึงสถานการณ์เดียวกันแต่เพียงจากมุมมองที่แตกต่างกัน  หลักฐานอธิบายถึงอารมณ์และการจากลาในขณะที่สมมติฐานแสดงถึงการกระทำที่เป็นผลมาจากเหตุการณ์เหล่านั้น\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าเพื่อนของผู้พูดร้องไห้เพราะความสุขในการพบกับ Tenōe ซึ่งสนับสนุนสมมติฐานที่ว่า Tenōe ปรากฏตัวที่บ้านของเพื่อนผู้พูดในวันนี้\n', '2\n', '0\n', '2\n', '0\n', '0\n', '2\n', '2\n', '0\n', '2\nหลักฐานระบุว่ามีเครื่องบินมาถึง ในขณะที่สมมติฐานระบุว่าไม่ทราบว่าเครื่องบินใดมาถึง  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '0\n', '0\n', '0\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐานอย่างสมบูรณ์  หลักฐานระบุว่าวัตถุนั้นไม่เป็นอันตรายแม้จะได้รับแรงกระแทกอย่างรุนแรง  นี่หมายความว่าไม่มีโอกาสที่มันจะระเบิดได้ ซึ่งสอดคล้องกับสมมติฐาน\n', '2\n', '2\n', 'ไม่สามารถกำหนดความสัมพันธ์ระหว่างหลักฐานและสมมติฐานได้อย่างถูกต้องเนื่องจากมีคำที่ไม่รู้จัก (“<unk>”)  ดังนั้นฉันจึงไม่สามารถให้คำตอบ 0, 1 หรือ 2 ได้\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐาน  ผู้พูดระบุว่าพวกเขาต้องมีผลรวมเพื่ออ่านสมการ ซึ่งสอดคล้องกับความเชื่อที่ว่าจำเป็นต้องมีผลรวมเพื่อที่จะคำนวณและทำความเข้าใจสมการได้\n', 'คำตอบคือ 0\n\nหลักฐานระบุถึงความไม่แน่นอนและความต้องการความช่วยเหลือในการคำนวณผลรวม  มันไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ  จึงเป็นการเข้าร่วมที่เป็นกลาง (0)\n', "ฉันไม่สามารถกำหนดความสัมพันธ์ระหว่างหลักฐานและสมมติฐานได้อย่างถูกต้องโดยไม่มีข้อมูลเพิ่มเติมเกี่ยวกับสมมติฐานที่เป็นปัญหา  หลักฐานที่ให้มาอธิบายถึงกระบวนการคำนวณ แต่ไม่ได้ระบุว่าการคำนวณนั้นเกี่ยวข้องกับสมมติฐานใด  ดังนั้น คำตอบจึงไม่สามารถเป็น '0', '1', หรือ '2' ได้อย่างแน่นอน  จำเป็นต้องมีข้อมูลเพิ่มเติม\n", '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้เขียนเห็นสีหน้าของคนที่เปิดประตูและสามารถอนุมานอารมณ์ของเขาได้  สมมติฐานพูดถึงการไม่รู้ว่าใครเปิดประตูหลังจากที่ประตูปิดไปแล้ว  หลักฐานสนับสนุนส่วนหนึ่งของสมมติฐาน (ไม่รู้ว่าใคร) แต่ยังเพิ่มข้อมูลเพิ่มเติมเกี่ยวกับการเห็นสีหน้าก่อนที่ประตูจะปิด  ดังนั้นหลักฐานเกี่ยวข้องกับสมมติฐาน แต่ไม่ได้สนับสนุนหรือขัดแย้งอย่างสมบูรณ์\n', 'คำตอบคือ 1\n', '2\n', '2\n', 'คำตอบคือ 1\n', '0\n', '2\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าพวกเขาบอกสถานที่ทั้งหมดที่พวกเขาไป และแม้กระทั่งเวลาที่พวกเขาออกเดินทางไปยังที่อื่น สมมติฐานระบุว่าฉันไม่เคยถามพวกเขาเลย หลักฐานและสมมติฐานจึงขัดแย้งกัน\n', 'คำตอบคือ 0\nหลักฐานแสดงให้เห็นว่ากลุ่มคนไม่เคยเปิดเผยปลายทางแม้ในกรณีที่พวกเขาจะไปที่นั่นชั่วคราว สมมติฐานกล่าวว่ากลุ่มคนนี้บอกเพียงว่าพวกเขาจะไม่ไปไหนและจะไปไหน ซึ่งสอดคล้องกับหลักฐานเนื่องจากการไม่เปิดเผยปลายทางเป็นวิธีการหนึ่งในการบอกว่าพวกเขาไม่ได้ไปที่ใดที่หนึ่ง', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่ากลุ่มคนที่กล่าวถึงไม่เคยเปิดเผยสถานที่ที่พวกเขาอยู่ แม้กระทั่งเมื่อพวกเขาเดินทางไปยังสถานที่อื่นชั่วคราว  สมมติฐานก็กล่าวว่าพวกเขาไม่เคยเปิดเผยสถานที่ของพวกเขาเช่นกัน ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', '2\n', '1\n', '1\n', '2\n', '2\n', '0\n', '2\n', '0\n', '0\n', 'คำตอบคือ 0.  หลักฐานเป็นเรื่องราวเกี่ยวกับความทรงจำในวัยเด็กของผู้พูดเกี่ยวกับการเยี่ยมปู่ย่าตายาย  สมมติฐานนั้นพูดถึงการขับรถไปที่บ้านปู่ย่าตายาย  หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานโดยตรง  มันเป็นข้อมูลที่เกี่ยวข้องแต่ไม่ใช่หลักฐานที่พิสูจน์หรือหักล้างสมมติฐานได้\n', '0\n', '2\n', '0\n', '0\n', '0\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 2\n\nหลักฐาน (ยายเล่าเรื่องราวเกี่ยวกับการเลี้ยงดูลูกสาวและอารมณ์ความรู้สึกในขณะนั้น) ขัดแย้งกับสมมติฐาน (แม่ปฏิเสธบางสิ่งเกี่ยวกับวัยเด็ก)  เพราะถ้าแม่ปฏิเสธที่จะพูดคุยเกี่ยวกับเรื่องราวในวัยเด็ก  ก็ไม่น่าจะมีเรื่องราวเหล่านั้นจากยายมาเล่าได้\n', '0\n', '2\n', '0\n', '2\nหลักฐานระบุว่าชุดสูทในโรงงานนั้นเป็นสีดำ  สมมติฐานระบุว่าสามารถขอชุดสูทได้ในสีใดก็ได้ ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '2\n', '0\n', '2\n', 'หลักฐานระบุว่าการฝึกอบรมใช้เวลา 5 สัปดาห์กับชาวอังกฤษ สมมติฐานระบุว่าการฝึกอบรมใช้เวลา 5 สัปดาห์กับชาวอังกฤษ หลักฐานสนับสนุนสมมติฐาน ดังนั้นคำตอบคือ 1\n', '1\n', '2\n', 'ไม่สามารถระบุได้ว่าหลักฐานนั้นสนับสนุน สมมติฐาน หรือขัดแย้งกับสมมติฐานใดๆ เพราะหลักฐานที่ให้มานั้นไม่ชัดเจนและไม่มีสมมติฐานที่ระบุไว้  คำตอบคือไม่มีข้อมูลเพียงพอที่จะตอบคำถามได้  ดังนั้นจึงไม่ใช่ 0, 1 หรือ 2\n', 'คำตอบคือ **0**\n\nหลักฐานที่ให้มานั้นไม่เกี่ยวข้องกับสมมติฐานใดๆ  มันเป็นเพียงความคิดเห็นเกี่ยวกับบริษัทที่ควรปรับปรุงกลยุทธ์ทางการเงิน  ไม่มีสมมติฐานที่ถูกนำเสนอมาเพื่อเปรียบเทียบกับหลักฐานนี้\n', '0\n', 'คำตอบคือ 2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าบุคคลนั้นไม่ได้อ่านหนังสือภาษาอังกฤษที่มีความยาวเกินกว่า 100 หน้า  ซึ่งขัดแย้งกับสมมติฐานที่ว่าพวกเขาเคยอ่านหนังสือสำคัญๆ ที่ควรอ่านมาแล้ว  เพราะหนังสือสำคัญๆ มักจะยาวกว่า 100 หน้า\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดไม่เคยอ่านงานวิจัยใด ๆ สมมติฐานระบุว่าผู้พูดไม่ได้อ่านพจนานุกรมมากมาย หลักฐานไม่ได้สนับสนุนหรือหักล้างสมมติฐานใดๆ  ทั้งสองอย่างไม่เกี่ยวข้องกัน', '2\n', '2\n', '2\n', '0\n', '2\n', '1\n', '0\n', 'คำตอบคือ 2\n', 'คำตอบคือ 1\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานกล่าวถึงขั้นตอนที่ต้องผ่านเพื่อให้สามารถบินได้  แต่สมมติฐานกล่าวว่าคนส่วนใหญ่ *ไม่* ผ่านการทดสอบและไม่เคยได้บิน  ทั้งสองข้อความจึงขัดแย้งกัน\n', 'คำตอบคือ 0\n\nหลักฐานที่ให้ไว้ ("พวกเขาต้องออกเดินทางไปยังหมายเลขห้องชั้นที่สูงล่วงหน้า...ขี่ก่อนที่พวกเขาจะเริ่มบิน") ไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานที่ว่า "การฝึกอบรมก่อนการบินเป็นสิ่งจำเป็น"  ข้อมูลที่ให้มาอธิบายถึงขั้นตอนก่อนการบิน แต่ไม่ได้พูดถึงการฝึกอบรมโดยตรง\n', '2\n', '2\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nถ้อยคำของแม่บ่งชี้ว่าเธอกำลังปกปิดเรื่องราวบางอย่าง ขณะที่สมมติฐานระบุว่าเธอได้กล่าวถึงเรื่องราวเดียวกันอย่างชัดเจนในนิตยสารอื่นๆ  ทั้งสองข้อความนี้ขัดแย้งกัน\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ามีสิ่งที่สามารถบันทึกได้ สมมติฐานระบุว่ามีเพียงสิ่งเดียวที่สามารถทำได้  สองข้อความนี้ขัดแย้งกัน  ถ้ามีสิ่งที่บันทึกได้  นั่นหมายความว่ามีอย่างน้อยสองสิ่งที่ทำได้ (บันทึก และสิ่งที่ถูกบันทึก)\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐาน เนื่องจากมันแสดงให้เห็นว่าผู้หญิงคนนั้นพยายามที่จะทำให้แน่ใจว่าน้องสาวของเธอไม่สามารถอธิบายสถานการณ์ได้อย่างถูกต้อง ซึ่งสอดคล้องกับความคิดที่ว่าเธอถูกบังคับให้ทำเช่นนั้น\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดได้ยืมโทรศัพท์ของเธอที่บ้านและได้รับหมายเลขคาราโอเกะ  สิ่งนี้สนับสนุนสมมติฐานที่ว่าผู้พูดได้ยืมโทรศัพท์ของเธอ  ไม่มีอะไรในหลักฐานที่ขัดแย้งกับสมมติฐานนี้\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้เขียนตั้งใจจะโทร แต่ไม่ได้โทร  นี่ขัดแย้งกับสมมติฐานที่ไม่ได้ระบุไว้โดยชัดแจ้ง แต่สามารถอนุมานได้ว่าผู้เขียนได้โทรหาบุคคลดังกล่าวแล้ว\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้พูดอยู่ในสถานที่เมื่อเช้าและโทรศัพท์ แต่ลืมรายละเอียดแล้ว  สมมติฐานระบุว่าผู้พูดไม่เชื่อว่าบุคคลนั้นมาในตอนเช้า หลักฐานและสมมติฐานขัดแย้งกันเนื่องจากหลักฐานแสดงให้เห็นว่าผู้พูดอยู่ในสถานที่ดังกล่าวและมีปฏิสัมพันธ์กัน แต่ไม่แน่ใจในรายละเอียด  สมมติฐานแสดงความไม่เชื่อว่ามีปฏิสัมพันธ์กัน\n', 'คำตอบคือ 0', '0\n', '0\n', '0\n', '0\n', '2\n', '1\n', 'คำตอบคือ 1\n', 'คำตอบคือ 1\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1880 กว่าๆ ซึ่งหมายความว่าเขาเกิดก่อนปี 1900 สมมติฐานระบุว่าเขาเกิด *หลัง* ปี 1900  ดังนั้น หลักฐานและสมมติฐานจึงขัดแย้งกัน\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าขันสกรูที่ปิดลงเองอาจทำลายปอดได้ง่าย  ซึ่งขัดแย้งกับสมมติฐานที่ว่าขันสกรูไม่สามารถทำร้ายใครได้\n', '2\n', '0\n', '2\n', '2\nหลักฐานระบุว่าผู้เขียนจะไปยังฐานทัพอากาศ Laughlin ซึ่งตั้งอยู่ในเท็กซัส  เนื่องจากสมมติฐานระบุว่าผู้เขียนไม่เคยไปเท็กซัสมาก่อน  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 1\n\nข้อความระบุถึงการเดินทางไปยังฐานทัพทางอากาศ  ซึ่งสอดคล้องกับสมมติฐานที่เกี่ยวกับการเดินทางโดยเครื่องบินไปยังเดล ริโอ เท็กซัส ในปี 2001 แม้ว่ารายละเอียดบางอย่างจะคลุมเครือและไม่สมบูรณ์ แต่ก็ไม่มีอะไรขัดแย้งกับสมมติฐานหลัก\n', '2\n', '2\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nข้อความระบุว่าทุกคนได้รับแชมเปญ แต่บางคนไม่ได้ดื่ม  สิ่งนี้ขัดแย้งกับข้อความที่ว่า "ทุกคนที่เห็นดื่ม"  ข้อความยังระบุว่างานเลี้ยงไม่ได้สนุกและไม่มีการรณรงค์เครื่องดื่มแอลกอฮอล์  สิ่งนี้เกี่ยวข้องกับข้อเท็จจริงที่ว่าแชมเปญถูกแจกจ่ายแต่ไม่ได้รับการดื่มทั้งหมด\n', '2\n', '0\n', '0\n', 'คำตอบคือ 0\n', '0\n', '2\n', '2\n', '0\n', '0\n', '2\n', '0\n']
Saved predictions to: predicted_5.json
Accuracy th: 0.46
'XNLI' object has no attribute 'evaluate_results'
