README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 21.0MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  63%|######2   | 31.5M/50.2M [00:00<00:00, 196MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 210MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 340MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 327MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###       | 120000/392702 [00:00<00:00, 1182457.26 examples/s]Generating train split:  63%|######2   | 247000/392702 [00:00<00:00, 1228619.57 examples/s]Generating train split:  96%|#########5| 376000/392702 [00:00<00:00, 1250996.76 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1237543.00 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1130911.31 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 969533.69 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 419kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 5.15MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 13.7MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 19.4MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   5%|4         | 21.0M/440M [00:00<00:02, 191MB/s]model.safetensors:  12%|#1        | 52.4M/440M [00:00<00:01, 256MB/s]model.safetensors:  19%|#9        | 83.9M/440M [00:00<00:01, 280MB/s]model.safetensors:  26%|##6       | 115M/440M [00:00<00:01, 292MB/s] model.safetensors:  36%|###5      | 157M/440M [00:00<00:00, 302MB/s]model.safetensors:  43%|####2     | 189M/440M [00:00<00:00, 302MB/s]model.safetensors:  52%|#####2    | 231M/440M [00:00<00:00, 307MB/s]model.safetensors:  62%|######1   | 273M/440M [00:00<00:00, 310MB/s]model.safetensors:  69%|######9   | 304M/440M [00:01<00:00, 310MB/s]model.safetensors:  76%|#######6  | 336M/440M [00:01<00:00, 311MB/s]model.safetensors:  86%|########5 | 377M/440M [00:01<00:00, 312MB/s]model.safetensors:  93%|#########2| 409M/440M [00:01<00:00, 312MB/s]model.safetensors: 100%|#########9| 440M/440M [00:01<00:00, 311MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 301MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '2\n', '2\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 2
Accuracy en: 0.4292929292929293
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  28%|##8       | 21.0M/73.8M [00:00<00:00, 178MB/s]train-00000-of-00001.parquet:  71%|#######1  | 52.4M/73.8M [00:00<00:00, 245MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 243MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 383MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 264MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  23%|##2       | 90000/392702 [00:00<00:00, 889601.70 examples/s]Generating train split:  47%|####6     | 184000/392702 [00:00<00:00, 915041.06 examples/s]Generating train split:  70%|#######   | 276000/392702 [00:00<00:00, 916304.88 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 891493.52 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 897391.35 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 984929.13 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 839670.12 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 18.7kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 4.86MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 17.0MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 981kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   7%|6         | 31.5M/454M [00:00<00:01, 249MB/s]pytorch_model.bin:  14%|#3        | 62.9M/454M [00:00<00:01, 247MB/s]pytorch_model.bin:  21%|##        | 94.4M/454M [00:00<00:01, 268MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:01, 269MB/s] pytorch_model.bin:  35%|###4      | 157M/454M [00:00<00:01, 283MB/s]pytorch_model.bin:  42%|####1     | 189M/454M [00:00<00:00, 289MB/s]pytorch_model.bin:  48%|####8     | 220M/454M [00:00<00:00, 294MB/s]pytorch_model.bin:  58%|#####7    | 262M/454M [00:00<00:00, 299MB/s]pytorch_model.bin:  65%|######4   | 294M/454M [00:01<00:00, 298MB/s]pytorch_model.bin:  72%|#######1  | 325M/454M [00:01<00:00, 296MB/s]pytorch_model.bin:  78%|#######8  | 357M/454M [00:01<00:00, 296MB/s]pytorch_model.bin:  85%|########5 | 388M/454M [00:01<00:00, 294MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:01<00:00, 292MB/s]pytorch_model.bin:  99%|#########9| 451M/454M [00:01<00:00, 291MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 287MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '2\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', 'Η απάντηση είναι 1.\n\nΗ εργασία δηλώνει ότι δεν μας ενημέρωναν ποτέ για την εργασία μας, ακόμη και όταν έφευγαν από τη βάση για σύντομο χρονικό διάστημα.  Η υπόθεση δηλώνει ότι δεν μας ενημέρωναν ποτέ για το πού πήγαιναν.  Δεν υπάρχει  συνέπεια ή αντίφαση μεταξύ τους.  Η μία δεν συνεπάγεται ούτε αντιφάσκει με την άλλη.\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '2\n', '2\n', '2\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '1\n', '2\n', '1\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy el: 0.4371859296482412
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  32%|###2      | 21.0M/65.4M [00:00<00:00, 190MB/s]train-00000-of-00001.parquet:  80%|########  | 52.4M/65.4M [00:00<00:00, 253MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 250MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 255MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 147MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##4       | 96000/392702 [00:00<00:00, 952168.90 examples/s]Generating train split:  50%|####9     | 196000/392702 [00:00<00:00, 976357.92 examples/s]Generating train split:  75%|#######5  | 295000/392702 [00:00<00:00, 978715.77 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 970935.55 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 998501.45 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 871189.27 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 496kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 7.87MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 24.0MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 60.9MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   2%|1         | 10.5M/672M [00:00<00:20, 32.4MB/s]model.safetensors:   3%|3         | 21.0M/672M [00:00<00:17, 36.8MB/s]model.safetensors:   5%|4         | 31.5M/672M [00:01<00:21, 30.3MB/s]model.safetensors:   6%|6         | 41.9M/672M [00:01<00:29, 21.2MB/s]model.safetensors:   8%|7         | 52.4M/672M [00:02<00:29, 20.8MB/s]model.safetensors:   9%|9         | 62.9M/672M [00:02<00:27, 22.4MB/s]model.safetensors:  11%|#         | 73.4M/672M [00:03<00:25, 23.5MB/s]model.safetensors:  12%|#2        | 83.9M/672M [00:03<00:21, 27.3MB/s]model.safetensors:  14%|#4        | 94.4M/672M [00:03<00:20, 28.3MB/s]model.safetensors:  16%|#5        | 105M/672M [00:03<00:18, 31.1MB/s] model.safetensors:  17%|#7        | 115M/672M [00:04<00:21, 26.4MB/s]model.safetensors:  19%|#8        | 126M/672M [00:05<00:27, 19.7MB/s]model.safetensors:  20%|##        | 136M/672M [00:06<00:36, 14.6MB/s]model.safetensors:  22%|##1       | 147M/672M [00:08<00:50, 10.5MB/s]model.safetensors:  23%|##3       | 157M/672M [00:10<01:11, 7.20MB/s]model.safetensors:  25%|##4       | 168M/672M [00:13<01:24, 5.94MB/s]model.safetensors:  27%|##6       | 178M/672M [00:15<01:25, 5.76MB/s]model.safetensors:  28%|##8       | 189M/672M [00:16<01:15, 6.42MB/s]model.safetensors:  30%|##9       | 199M/672M [00:17<01:04, 7.35MB/s]model.safetensors:  31%|###1      | 210M/672M [00:18<00:57, 8.00MB/s]model.safetensors:  33%|###2      | 220M/672M [00:18<00:49, 9.09MB/s]model.safetensors:  34%|###4      | 231M/672M [00:19<00:43, 10.0MB/s]model.safetensors:  36%|###5      | 241M/672M [00:20<00:37, 11.5MB/s]model.safetensors:  37%|###7      | 252M/672M [00:20<00:31, 13.5MB/s]model.safetensors:  39%|###8      | 262M/672M [00:21<00:31, 12.8MB/s]model.safetensors:  41%|####      | 273M/672M [00:22<00:29, 13.4MB/s]model.safetensors:  42%|####2     | 283M/672M [00:22<00:25, 15.3MB/s]model.safetensors:  44%|####3     | 294M/672M [00:23<00:22, 16.6MB/s]model.safetensors:  45%|####5     | 304M/672M [00:23<00:17, 20.7MB/s]model.safetensors:  47%|####6     | 315M/672M [00:23<00:15, 23.4MB/s]model.safetensors:  48%|####8     | 325M/672M [00:24<00:12, 28.6MB/s]model.safetensors:  51%|#####1    | 346M/672M [00:24<00:08, 39.5MB/s]model.safetensors:  53%|#####3    | 357M/672M [00:24<00:07, 44.9MB/s]model.safetensors:  55%|#####4    | 367M/672M [00:24<00:05, 51.2MB/s]model.safetensors:  56%|#####6    | 377M/672M [00:24<00:05, 52.2MB/s]model.safetensors:  59%|#####9    | 398M/672M [00:25<00:03, 68.7MB/s]model.safetensors:  61%|######    | 409M/672M [00:25<00:04, 62.0MB/s]model.safetensors:  64%|######3   | 430M/672M [00:25<00:02, 81.6MB/s]model.safetensors:  67%|######7   | 451M/672M [00:25<00:02, 93.0MB/s]model.safetensors:  70%|#######   | 472M/672M [00:25<00:01, 107MB/s] model.safetensors:  73%|#######3  | 493M/672M [00:25<00:01, 119MB/s]model.safetensors:  76%|#######6  | 514M/672M [00:26<00:01, 111MB/s]model.safetensors:  80%|#######9  | 535M/672M [00:26<00:01, 120MB/s]model.safetensors:  83%|########2 | 556M/672M [00:26<00:00, 133MB/s]model.safetensors:  86%|########5 | 577M/672M [00:26<00:00, 128MB/s]model.safetensors:  89%|########8 | 598M/672M [00:26<00:00, 119MB/s]model.safetensors:  92%|#########2| 619M/672M [00:26<00:00, 116MB/s]model.safetensors:  95%|#########5| 640M/672M [00:27<00:00, 129MB/s]model.safetensors:  98%|#########8| 661M/672M [00:27<00:00, 144MB/s]model.safetensors: 100%|##########| 672M/672M [00:27<00:00, 24.7MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '2\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', '1\n', '2\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_2.json
Accuracy bg: 0.445
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  39%|###9      | 21.0M/53.2M [00:00<00:00, 167MB/s]train-00000-of-00001.parquet:  99%|#########8| 52.4M/53.2M [00:00<00:00, 236MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 220MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 152MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 326MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  30%|###       | 119000/392702 [00:00<00:00, 1177905.58 examples/s]Generating train split:  61%|######1   | 241000/392702 [00:00<00:00, 1193570.55 examples/s]Generating train split:  93%|#########2| 365000/392702 [00:00<00:00, 1211837.99 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1204623.31 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1181394.45 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1040220.81 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.56MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 5.84MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 2.18MB/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 2.17MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 19.8MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.46MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   7%|7         | 31.5M/440M [00:00<00:01, 297MB/s]pytorch_model.bin:  14%|#4        | 62.9M/440M [00:00<00:01, 287MB/s]pytorch_model.bin:  21%|##1       | 94.4M/440M [00:00<00:01, 286MB/s]pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:01, 281MB/s] pytorch_model.bin:  36%|###5      | 157M/440M [00:00<00:00, 284MB/s]pytorch_model.bin:  43%|####2     | 189M/440M [00:00<00:00, 283MB/s]pytorch_model.bin:  50%|#####     | 220M/440M [00:00<00:00, 285MB/s]pytorch_model.bin:  57%|#####7    | 252M/440M [00:00<00:00, 286MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:00<00:00, 289MB/s]pytorch_model.bin:  72%|#######1  | 315M/440M [00:01<00:00, 290MB/s]pytorch_model.bin:  79%|#######8  | 346M/440M [00:01<00:00, 288MB/s]pytorch_model.bin:  86%|########5 | 377M/440M [00:01<00:00, 287MB/s]pytorch_model.bin:  93%|#########3| 409M/440M [00:01<00:00, 287MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 285MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 285MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', 'La respuesta es 1.\n\nLa premisa establece que una persona no entró en Augusta después de un evento específico.  La hipótesis establece que la persona se mudó inmediatamente de Augusta.  Si bien la hipótesis es *consistente* con la premisa (es posible que la persona se haya mudado y por lo tanto no haya entrado más en Augusta), la premisa no *implica* la hipótesis.  La persona podría haber estado en otro lugar, sin mudarse permanentemente de Augusta.  Por lo tanto, no hay implicación ni contradicción.\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '0\n', '1\n', 'La respuesta es 1.\n\nLa premisa indica una incertidumbre sobre si se hizo una promesa o visita, y si fue hoy o no.  La hipótesis afirma con seguridad que no se ha ido hoy.  No hay implicación ni contradicción directa, ya que la premisa deja abierta la posibilidad de que la visita haya sucedido o no hoy.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '2\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n']
Saved predictions to: predicted_3.json
Accuracy es: 0.455
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  38%|###7      | 21.0M/55.4M [00:00<00:00, 175MB/s]train-00000-of-00001.parquet:  95%|#########4| 52.4M/55.4M [00:00<00:00, 244MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 233MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 299MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 359MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  30%|###       | 118000/392702 [00:00<00:00, 1164352.61 examples/s]Generating train split:  61%|######    | 239000/392702 [00:00<00:00, 1186235.71 examples/s]Generating train split:  92%|#########1| 360000/392702 [00:00<00:00, 1194532.96 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1186727.68 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1169428.63 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 961146.42 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 255kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.50MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 15.7MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 48.2MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/445M [00:00<00:01, 308MB/s]model.safetensors:  14%|#4        | 62.9M/445M [00:00<00:01, 292MB/s]model.safetensors:  21%|##1       | 94.4M/445M [00:00<00:01, 290MB/s]model.safetensors:  28%|##8       | 126M/445M [00:00<00:01, 289MB/s] model.safetensors:  35%|###5      | 157M/445M [00:00<00:00, 290MB/s]model.safetensors:  42%|####2     | 189M/445M [00:00<00:00, 292MB/s]model.safetensors:  49%|####9     | 220M/445M [00:00<00:00, 291MB/s]model.safetensors:  57%|#####6    | 252M/445M [00:00<00:00, 294MB/s]model.safetensors:  64%|######3   | 283M/445M [00:00<00:00, 295MB/s]model.safetensors:  71%|#######   | 315M/445M [00:01<00:00, 295MB/s]model.safetensors:  78%|#######7  | 346M/445M [00:01<00:00, 293MB/s]model.safetensors:  85%|########4 | 377M/445M [00:01<00:00, 295MB/s]model.safetensors:  92%|#########1| 409M/445M [00:01<00:00, 297MB/s]model.safetensors:  99%|#########8| 440M/445M [00:01<00:00, 295MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 292MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '2\n', '2\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.475
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  27%|##7       | 21.0M/76.5M [00:00<00:00, 150MB/s]train-00000-of-00001.parquet:  69%|######8   | 52.4M/76.5M [00:00<00:00, 224MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 229MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 229MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 198MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  21%|##1       | 83000/392702 [00:00<00:00, 818593.22 examples/s]Generating train split:  43%|####3     | 169000/392702 [00:00<00:00, 838170.37 examples/s]Generating train split:  65%|######4   | 254000/392702 [00:00<00:00, 837239.70 examples/s]Generating train split:  86%|########6 | 339000/392702 [00:00<00:00, 835824.13 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 835144.25 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 880846.04 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 788153.12 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 1.31MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 5.77MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 25.6MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/423M [00:00<00:09, 44.5MB/s]model.safetensors:   5%|4         | 21.0M/423M [00:00<00:06, 63.1MB/s]model.safetensors:  10%|9         | 41.9M/423M [00:00<00:04, 92.2MB/s]model.safetensors:  15%|#4        | 62.9M/423M [00:00<00:03, 114MB/s] model.safetensors:  22%|##2       | 94.4M/423M [00:00<00:02, 149MB/s]model.safetensors:  30%|##9       | 126M/423M [00:00<00:01, 172MB/s] model.safetensors:  37%|###7      | 157M/423M [00:01<00:01, 188MB/s]model.safetensors:  45%|####4     | 189M/423M [00:01<00:01, 198MB/s]model.safetensors:  52%|#####1    | 220M/423M [00:01<00:00, 205MB/s]model.safetensors:  57%|#####6    | 241M/423M [00:01<00:00, 205MB/s]model.safetensors:  62%|######1   | 262M/423M [00:01<00:00, 194MB/s]model.safetensors:  69%|######9   | 294M/423M [00:01<00:00, 200MB/s]model.safetensors:  74%|#######4  | 315M/423M [00:01<00:00, 199MB/s]model.safetensors:  79%|#######9  | 336M/423M [00:01<00:00, 197MB/s]model.safetensors:  84%|########4 | 357M/423M [00:02<00:00, 198MB/s]model.safetensors:  89%|########9 | 377M/423M [00:02<00:00, 198MB/s]model.safetensors:  94%|#########4| 398M/423M [00:02<00:00, 190MB/s]model.safetensors:  99%|#########9| 419M/423M [00:02<00:00, 170MB/s]model.safetensors: 100%|##########| 423M/423M [00:02<00:00, 171MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\nหลักฐานแสดงให้เห็นถึงความรู้สึกผิดหวัง แต่ก็ยังกลับไปคุยกับเขาอีกครั้ง  ซึ่งสอดคล้องกับความรู้สึกกังวล (หรือความรู้สึกอื่นๆที่ถูกแทนด้วย <unk>) ที่เริ่มต้นขึ้นอีกครั้งเมื่อกลับไปคุยกับเขา\n', 'คำตอบคือ 1\n', '2\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานที่ว่า "เขาจะเรียกเด็ก ๆ เข้ามาหนึ่งคนในตอนท้ายให้ฉันเจอ" ขัดแย้งกับสมมติฐานที่ว่า "ฉันไม่เคยพูดถึงการประชุมของฉัน"  เพราะคำพูดนี้บอกเป็นนัยว่ามีการประชุมเกิดขึ้นแล้ว และผู้พูดรู้เรื่องการประชุมนั้น\n', '1\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', '0\n', '0\n', '0\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานมีข้อความที่ไม่สมบูรณ์ แต่ก็สนับสนุนสมมติฐานที่ Annie Lono มีชีวิตและเรื่องราวในวัยเด็ก', 'คำตอบคือ 0 เนื่องจากหลักฐาน ("ฉันได้ห้ากองออกมาจาก U2") ไม่เกี่ยวข้องกับสมมติฐาน ("จัดการกับ <unk>")  ไม่สามารถระบุได้ว่าหลักฐานสนับสนุนหรือขัดแย้งกับสมมติฐานเนื่องจากสมมติฐานไม่สมบูรณ์และไม่ชัดเจน\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐานระบุว่าผู้พูดได้นำ "ห้ากอง" ออกมา ซึ่งหมายความว่าพวกเขามีส่วนร่วมในบางสิ่งบางอย่าง  ในขณะที่สมมติฐานระบุว่าพวกเขาไม่ได้ติดต่อกับ <unk>2  นี่เป็นความขัดแย้งกัน', '2\n', '1\n', '0\n', '2\n', '0\n', '2\n', '1\n', '0\n', 'คำตอบคือ 1.  หลักฐานระบุว่ามีชื่อลูกค้าคือ "e<unk>utty" ซึ่งสนับสนุนสมมติฐานว่ามีชื่อลูกค้าอยู่', '2\nหลักฐานระบุว่ามีกระแสเงินสดและลูกค้าชื่อ "xx<unk>utty" สมมติฐานระบุว่าไม่มีลูกค้าชื่อ "xx<unk>utty"  ดังนั้นหลักฐานและสมมติฐานจึงขัดแย้งกัน\n', '2\n', '2\n', '2\n', '0\n', '0\n', '1\n', '2\nหลักฐานแสดงให้เห็นถึงการเลือกหัวข้อที่จะพูดคุย แต่ไม่ได้บอกว่าเขาได้ตัดสินใจแล้วว่าจะพูดอะไรอีก  ดังนั้นจึงขัดแย้งกับสมมติฐาน\n', '0\n', '0\n', 'คำตอบคือ 0', '2\n', '2\n', '2\n', '0\n', 'ฉันไม่สามารถระบุได้ว่าหลักฐานมีความเกี่ยวข้องหรือขัดแย้งกับสมมติฐานใด ๆ เนื่องจากไม่มีการระบุสมมติฐาน  หลักฐานมีลักษณะเป็นเศษส่วนของประโยคที่ไม่สมบูรณ์และไม่เข้าใจง่าย  จำเป็นต้องมีบริบทเพิ่มเติมเพื่อวิเคราะห์ความสัมพันธ์ระหว่างหลักฐานและสมมติฐาน\n', '0\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', '2\n', '0\n', '0\n', '2\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าการฝึกอบรมชุดความดันสูงนั้นใช้เวลาสักพัก สมมติฐานระบุว่าการฝึกอบรมสามารถเสร็จสิ้นได้ภายในวันเดียว  นี่เป็นความขัดแย้งกัน\n', '2\n', '2\n', '2\n', '2\n', '1\n', '2\nหลักฐานกล่าวถึงการกระทำในปัจจุบัน ("มันเหมือนกับสิ่งที่ฉันพยายามทำ") ในขณะที่สมมติฐานกล่าวถึงอนาคต ("ฉันกำลังทำให้เสร็จในอาทิตย์หน้า")  จึงขัดแย้งกัน\n', '2\n', '2\n', 'คำตอบคือ 1\n', 'คำตอบคือ 0\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าต้องมีการคำนวณผลรวมและแบตเตอรี่  สมมติฐานระบุความพอใจกับผลรวมที่คำนวณได้ หลักฐานอธิบายกระบวนการที่นำไปสู่ผลลัพธ์ที่สมมติฐานแสดงความพึงพอใจ  ดังนั้นจึงเกี่ยวข้องกัน\n', '2\n', '0\n', '2\n', '0\n', 'คำตอบคือ **1**\n\nหลักฐานที่ให้มานั้นสนับสนุนสมมติฐานที่ว่าบุคคลนั้นรู้สึกผิดหวัง  หลักฐานอธิบายถึงการแสดงออกทางสีหน้าของบุคคลนั้นอย่างชัดเจน  ซึ่งสอดคล้องกับสมมติฐาน\n', '0\n', '0\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n', 'คำตอบคือ **2** (ความขัดแย้ง)\n\nหลักฐานระบุว่าเขาไม่เคยทำอะไรเพื่อประโยชน์ตนเองและได้รับความช่วยเหลืออย่างมาก  สิ่งนี้ขัดแย้งกับสมมติฐานที่อาจมีอยู่เกี่ยวกับความสามารถหรือความพยายามของบุคคลนั้นในการช่วยเหลือตนเอง  ถ้าสมมติฐานคือเขาเป็นคนช่วยเหลือตัวเองได้ดี  หลักฐานนี้จะขัดแย้ง  ถ้าสมมติฐานคือเขาพึ่งพาผู้อื่น  หลักฐานนี้จะสนับสนุน\n', '2\n', '1\n', '2\n', '2\n', '0\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n', '0\n', '2\n', '2\n', '2\n', '1\n', '2\n', '1\n', '2\n', '0\n', '2\n', '0\n', '0\n', '0\n', 'คำตอบคือ 0. ข้อมูลที่ให้มานั้นไม่สนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ', 'คำตอบคือ 0', 'คำตอบคือ 1', '2\n', 'คำตอบคือ 2\n\nสมมติฐานคือ "ฉันไม่เชื่อที่จะเข้าไปในทุกสิ่ง"  ประโยค "ฉันสามารถป้อนข้อมูลได้" แสดงว่าอย่างน้อยก็สามารถป้อนข้อมูลบางอย่างได้ ขัดแย้งกับสมมติฐานที่ว่า "ไม่สามารถป้อนข้อมูลได้ทุกอย่าง"  ดังนั้นจึงเป็นความขัดแย้ง\n', '2\n', '0\n', '2\n', 'หลักฐานชี้ให้เห็นว่าตัวเหนี่ยวไกมีบทบาทสำคัญในการทำงานของอาวุธนิวเคลียร์  สมมติฐานกล่าวว่าตัวเหนี่ยวไกทำให้ระเบิดทำงาน  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n\nคำตอบคือ **1**\n', '2\n', '0\n', 'คำตอบคือ **0**\n\nหลักฐานแสดงให้เห็นถึงข้อมูลบางส่วนเกี่ยวกับครอบครัวของยายในช่วงเวลาหนึ่ง  แต่ไม่เพียงพอที่จะสนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ  มันเกี่ยวข้องกับเรื่องราวในครอบครัว แต่ไม่ใช่ข้อมูลที่ชัดเจนหรือมีนัยสำคัญพอที่จะระบุได้ว่าสนับสนุนหรือขัดแย้งกับสมมติฐาน\n', '0\n', 'คำตอบคือ 1\n', 'คำตอบคือ 1\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าบุคคลนั้นเป็นลูกชายของปู่ของผู้พูด ดังนั้นบุคคลนั้นจึงเป็นพ่อหรือลุงของผู้พูด ขึ้นอยู่กับว่าปู่ของผู้พูดเป็นพ่อของผู้พูดหรือไม่\n\nสมมติฐานระบุว่าปู่ของผู้พูดไม่ใช่คนดี  หลักฐานไม่ได้ระบุอะไรเกี่ยวกับตัวละครของปู่ของผู้พูด  ดังนั้นหลักฐานและสมมติฐานจึงไม่เกี่ยวข้องกัน\n', '1\n', '2\n', '2\nหลักฐานแสดงถึงการมีส่วนร่วมกับนักบินจีนและอังกฤษ ขัดแย้งกับสมมติฐานที่ว่าไม่มีการฝึกฝนกับใครเลย\n', '2\n', '0\n', '2\n', '0\n', '1\n', '0\n', '2\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าผู้พูดไม่เคยอ่านหนังสือใดๆ ที่ยาวกว่าร้อยหน้า  ซึ่งสนับสนุนสมมติฐานว่าพวกเขาไม่ได้อ่านหนังสือเล่มยาวๆ\n', '0\n', 'คำตอบคือ 2', '2\n', '0\n', '0\n', '2\n', '0\n', '1\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าผู้คนจำนวนมากไม่ผ่านการทดสอบและไม่เคยได้บิน  ซึ่งสนับสนุนสมมติฐานที่ว่าผู้คนจำนวนมากไม่ผ่านการทดสอบและไม่เคยได้บิน\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐาน  การที่พวกเขาต้องไปยังพื้นที่สูงและต้องฝึกอบรมมากมายก่อนบิน  แสดงให้เห็นว่าการบินในสถานการณ์ที่สมมติขึ้นนี้จำเป็นต้องมีการเตรียมตัวและการฝึกฝนอย่างเข้มข้น  ซึ่งสอดคล้องกับสมมติฐานที่ว่าพวกเขาต้องการการฝึกอบรมเป็นจำนวนมากก่อนที่จะบิน\n', 'คำตอบคือ 2\n\nหลักฐานอธิบายขั้นตอนก่อนการบินที่เกี่ยวข้องกับการรายงานหมายเลขเพดานห้องชั้นและการตรวจสอบชุดสูทแรงดัน  สมมติฐานกล่าวถึงเวลาในการบินในวันแรก  ทั้งสองไม่มีความเกี่ยวข้องกันโดยตรง  ดังนั้นจึงขัดแย้งกัน\n', '2\n', '2\n', '0\n', '2\n', '0\n', '2\n', '0\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าผู้หญิงคนนั้นบอกน้องสาวของเธอทุกวันว่าเธอทำผิด  นี่สนับสนุนสมมติฐานที่ว่าเธอคิดว่าน้องสาวของเธอทำอะไรไม่ถูกต้อง  แม้ว่าหลักฐานไม่ได้ระบุว่าความคิดนี้มาจากความเป็นญี่ปุ่นของน้องสาวโดยตรง แต่ก็แสดงให้เห็นถึงความคิดเชิงลบอย่างต่อเนื่องที่มีต่อน้องสาวของเธอ ซึ่งสอดคล้องกับสมมติฐาน\n', '0\n', '2\n', '0\n', '2\n', '2\n', '1\n', '2\n', '0\n', '0\n', '2\n', '2\nหลักฐานแสดงให้เห็นถึงความหิวโหย ซึ่งขัดแย้งกับสมมติฐานที่ว่าไม่มีความอยากอาหาร\n', '0\n', '0\n', 'คำตอบคือ 1. หลักฐานแสดงให้เห็นถึงการต่อสู้และการเกือบยอมแพ้ ซึ่งสอดคล้องกับสมมติฐานที่ว่าบุคคลนั้นกำลังจะเลิก', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าคนญี่ปุ่นเกิดในปี ค.ศ. 1880 กว่าๆ (อาจเป็น 1889) ซึ่งหมายความว่าเขาเกิดก่อนปี ค.ศ. 1900  ซึ่งสอดคล้องกับสมมติฐาน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าเขาเกิดในปี 1880 อันดับที่ 18 เช่น 1889 และเสียชีวิตในปีนั้น สมมติฐานระบุว่าเขาเกิดในเดือนธันวาคมปี 1880 ข้อมูลที่ขัดแย้งกันคือปีเกิด หลักฐานระบุปี 1889 ในขณะที่สมมติฐานระบุปี 1880 ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1880 หรือ 1889 ซึ่งขัดแย้งกับสมมติฐานที่ว่าบุคคลนั้นไม่ได้เกิดจนกระทั่งปี ค.ศ. 1984\n', 'คำตอบคือ 1\nหลักฐานแสดงให้เห็นว่าการขันสกรูเพิ่มเติมอาจทำให้มองเห็นปอดได้ง่ายขึ้น  สมมติฐานชี้ให้เห็นว่าสกรูอาจทำร้ายปอด  ทั้งสองอย่างนี้เกี่ยวข้องกันเนื่องจากการมองเห็นปอดได้ง่ายขึ้นโดยการขันสกรูอาจเป็นเพราะสกรูได้ทำร้ายปอดแล้ว  ดังนั้นจึงเป็นความสัมพันธ์  ไม่ใช่ความขัดแย้ง\n', '2\n', 'คำตอบคือ 2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าทุกคนได้รับแชมเปญและน้ำ แต่เด็กๆ ไม่ได้ดื่มเบียร์  นี่ไม่ใช่หลักฐานที่สนับสนุนหรือขัดแย้งกับสมมติฐานว่าเด็กๆ ดื่มแชมเปญไปบ้าง  หลักฐานไม่ได้กล่าวถึงว่าเด็กๆ ดื่มแชมเปญหรือไม่ ดังนั้นจึงไม่เกี่ยวข้องกับสมมติฐาน\n', '2\n', '2\n', '0\n', '0\n', '2\n', '1\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานที่ว่า "นั่นคือประเด็นทั้งหมด" ขัดแย้งกับสมมติฐานที่ว่า "ฉันไม่เข้าใจ!?" เพราะมันบ่งบอกว่ามีการเข้าใจในประเด็นแล้ว ในขณะที่สมมติฐานแสดงความไม่เข้าใจ\n', '2\n', '0\n', '2\n', '0\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy th: 0.49748743718592964
'XNLI' object has no attribute 'evaluate_results'
