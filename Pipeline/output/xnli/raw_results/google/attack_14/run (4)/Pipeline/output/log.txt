README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 95.3MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  84%|########3 | 41.9M/50.2M [00:00<00:00, 397MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 385MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 281MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 254MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  30%|###       | 119000/392702 [00:00<00:00, 1175024.43 examples/s]Generating train split:  63%|######3   | 248000/392702 [00:00<00:00, 1235952.31 examples/s]Generating train split:  97%|#########6| 379000/392702 [00:00<00:00, 1264668.99 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1251126.33 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1217748.21 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1000749.04 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 432kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 4.82MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 7.46MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 44.2MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:01, 309MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:01, 340MB/s]model.safetensors:  26%|##6       | 115M/440M [00:00<00:00, 353MB/s] model.safetensors:  36%|###5      | 157M/440M [00:00<00:00, 341MB/s]model.safetensors:  45%|####5     | 199M/440M [00:00<00:00, 348MB/s]model.safetensors:  55%|#####4    | 241M/440M [00:00<00:00, 333MB/s]model.safetensors:  64%|######4   | 283M/440M [00:00<00:00, 337MB/s]model.safetensors:  74%|#######3  | 325M/440M [00:00<00:00, 348MB/s]model.safetensors:  83%|########3 | 367M/440M [00:01<00:00, 350MB/s]model.safetensors:  93%|#########2| 409M/440M [00:01<00:00, 358MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 346MB/s]
Attack entry stored in: output/attacks/attack.txt
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
[None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', None, None, '1\n', '2\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 16
Accuracy en: 0.45108695652173914
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  57%|#####6    | 41.9M/73.8M [00:00<00:00, 348MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 338MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 293MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 402MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##4       | 95000/392702 [00:00<00:00, 936668.74 examples/s]Generating train split:  49%|####8     | 192000/392702 [00:00<00:00, 951902.58 examples/s]Generating train split:  74%|#######3  | 290000/392702 [00:00<00:00, 963784.62 examples/s]Generating train split:  99%|#########8| 387000/392702 [00:00<00:00, 961894.05 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 957866.93 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 989753.81 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 883721.18 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 15.2kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 4.63MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 29.0MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 957kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   9%|9         | 41.9M/454M [00:00<00:01, 366MB/s]pytorch_model.bin:  18%|#8        | 83.9M/454M [00:00<00:01, 368MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:00, 375MB/s] pytorch_model.bin:  37%|###6      | 168M/454M [00:00<00:00, 382MB/s]pytorch_model.bin:  46%|####6     | 210M/454M [00:00<00:00, 387MB/s]pytorch_model.bin:  55%|#####5    | 252M/454M [00:00<00:00, 389MB/s]pytorch_model.bin:  65%|######4   | 294M/454M [00:00<00:00, 391MB/s]pytorch_model.bin:  74%|#######3  | 336M/454M [00:00<00:00, 391MB/s]pytorch_model.bin:  83%|########3 | 377M/454M [00:00<00:00, 390MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:01<00:00, 372MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 380MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 15
}
]. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['Η απάντηση είναι 1.\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'Η απάντηση είναι **1**.\n\nΗ πρόταση υπονοεί ότι υπήρχαν τουλάχιστον πέντε παιδιά.  Η υπόθεση δεν λέει κάτι για τον αριθμό των παιδιών. Δεν υπάρχει λοιπόν αντίφαση ούτε συνεπαγωγή.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '0\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '2\n', '1\n', '2\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 2
Accuracy el: 0.4898989898989899
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  64%|######4   | 41.9M/65.4M [00:00<00:00, 352MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 355MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 180MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 402MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  26%|##5       | 102000/392702 [00:00<00:00, 1014164.02 examples/s]Generating train split:  53%|#####2    | 207000/392702 [00:00<00:00, 1027061.28 examples/s]Generating train split:  92%|#########1| 361000/392702 [00:00<00:00, 1020221.40 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1020361.60 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 994390.64 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 885519.50 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 469kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 5.21MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 4.37MB/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 4.35MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 32.5MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   5%|4         | 31.5M/672M [00:00<00:02, 294MB/s]model.safetensors:  11%|#         | 73.4M/672M [00:00<00:01, 322MB/s]model.safetensors:  17%|#7        | 115M/672M [00:00<00:01, 325MB/s] model.safetensors:  23%|##3       | 157M/672M [00:00<00:01, 341MB/s]model.safetensors:  30%|##9       | 199M/672M [00:00<00:01, 345MB/s]model.safetensors:  36%|###5      | 241M/672M [00:00<00:01, 348MB/s]model.safetensors:  42%|####2     | 283M/672M [00:00<00:01, 353MB/s]model.safetensors:  48%|####8     | 325M/672M [00:00<00:00, 356MB/s]model.safetensors:  55%|#####4    | 367M/672M [00:01<00:00, 345MB/s]model.safetensors:  61%|######    | 409M/672M [00:01<00:00, 321MB/s]model.safetensors:  67%|######7   | 451M/672M [00:01<00:00, 325MB/s]model.safetensors:  73%|#######3  | 493M/672M [00:01<00:00, 331MB/s]model.safetensors:  80%|#######9  | 535M/672M [00:01<00:00, 336MB/s]model.safetensors:  86%|########5 | 577M/672M [00:01<00:00, 342MB/s]model.safetensors:  92%|#########2| 619M/672M [00:01<00:00, 341MB/s]model.safetensors:  98%|#########8| 661M/672M [00:01<00:00, 343MB/s]model.safetensors: 100%|##########| 672M/672M [00:01<00:00, 338MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '0\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', 'Отговор: 1\n', '1\n', '1\n', '0\n', '0\n', None, '0\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '0\n', None, '1\n', '2\n', '1\n', '1\n', None, '0\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '2\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '2\n', None, '1\n', '0\n', '1\n', None, '0\n', '2\n', '0\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '2\n', '0\n', '2\n', '1\n', '0\n', '0\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None]
Saved predictions to: predicted_2.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 27
Accuracy bg: 0.4393063583815029
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  79%|#######8  | 41.9M/53.2M [00:00<00:00, 341MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 334MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 499MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 356MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  33%|###2      | 129000/392702 [00:00<00:00, 1275835.42 examples/s]Generating train split:  66%|######6   | 260000/392702 [00:00<00:00, 1290185.72 examples/s]Generating train split: 100%|#########9| 391000/392702 [00:00<00:00, 1294106.28 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1288667.43 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1233112.08 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1075573.32 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.60MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 4.78MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 57.1MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 27.9MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.08MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:  10%|9         | 41.9M/440M [00:00<00:01, 376MB/s]pytorch_model.bin:  19%|#9        | 83.9M/440M [00:00<00:00, 383MB/s]pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:00, 384MB/s] pytorch_model.bin:  38%|###8      | 168M/440M [00:00<00:00, 385MB/s]pytorch_model.bin:  48%|####7     | 210M/440M [00:00<00:00, 364MB/s]pytorch_model.bin:  57%|#####7    | 252M/440M [00:00<00:00, 365MB/s]pytorch_model.bin:  67%|######6   | 294M/440M [00:00<00:00, 373MB/s]pytorch_model.bin:  76%|#######6  | 336M/440M [00:00<00:00, 379MB/s]pytorch_model.bin:  86%|########5 | 377M/440M [00:00<00:00, 384MB/s]pytorch_model.bin:  95%|#########5| 419M/440M [00:01<00:00, 386MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 374MB/s]
Attack entry stored in: output/attacks/attack.txt
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', None, '0\n', '1\n', '2\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_3.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 5
Accuracy es: 0.4717948717948718
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  19%|#8        | 10.5M/55.4M [00:00<00:00, 89.3MB/s]train-00000-of-00001.parquet:  57%|#####6    | 31.5M/55.4M [00:00<00:00, 134MB/s] train-00000-of-00001.parquet:  95%|#########4| 52.4M/55.4M [00:00<00:00, 161MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 151MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 197MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 254MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###1      | 124000/392702 [00:00<00:00, 1233852.95 examples/s]Generating train split:  64%|######4   | 252000/392702 [00:00<00:00, 1255552.13 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1145095.23 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1169141.84 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1163793.92 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1019207.28 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 20.4kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 5.10MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 25.5MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 31.3MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/445M [00:00<00:06, 65.8MB/s]model.safetensors:   7%|7         | 31.5M/445M [00:00<00:03, 110MB/s] model.safetensors:  12%|#1        | 52.4M/445M [00:00<00:02, 142MB/s]model.safetensors:  19%|#8        | 83.9M/445M [00:00<00:01, 182MB/s]model.safetensors:  26%|##5       | 115M/445M [00:00<00:01, 204MB/s] model.safetensors:  33%|###2      | 147M/445M [00:00<00:01, 224MB/s]model.safetensors:  40%|####      | 178M/445M [00:00<00:01, 237MB/s]model.safetensors:  47%|####7     | 210M/445M [00:01<00:00, 247MB/s]model.safetensors:  54%|#####4    | 241M/445M [00:01<00:00, 252MB/s]model.safetensors:  61%|######1   | 273M/445M [00:01<00:00, 256MB/s]model.safetensors:  68%|######8   | 304M/445M [00:01<00:00, 254MB/s]model.safetensors:  75%|#######5  | 336M/445M [00:01<00:00, 249MB/s]model.safetensors:  82%|########2 | 367M/445M [00:01<00:00, 251MB/s]model.safetensors:  90%|########9 | 398M/445M [00:01<00:00, 251MB/s]model.safetensors:  97%|#########6| 430M/445M [00:01<00:00, 255MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 228MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '0\n', '0\n', '0\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.465
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  55%|#####4    | 41.9M/76.5M [00:00<00:00, 339MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 341MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 291MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 333MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##3       | 94000/392702 [00:00<00:00, 927347.51 examples/s]Generating train split:  57%|#####6    | 223000/392702 [00:00<00:00, 872984.17 examples/s]Generating train split:  80%|########  | 316000/392702 [00:00<00:00, 891777.49 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 893024.62 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 923953.00 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 864984.01 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.11MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 5.38MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 32.8MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:  10%|9         | 41.9M/423M [00:00<00:01, 345MB/s]model.safetensors:  20%|#9        | 83.9M/423M [00:00<00:00, 365MB/s]model.safetensors:  30%|##9       | 126M/423M [00:00<00:00, 373MB/s] model.safetensors:  40%|###9      | 168M/423M [00:00<00:00, 369MB/s]model.safetensors:  50%|####9     | 210M/423M [00:00<00:00, 328MB/s]model.safetensors:  59%|#####9    | 252M/423M [00:00<00:00, 345MB/s]model.safetensors:  69%|######9   | 294M/423M [00:00<00:00, 358MB/s]model.safetensors:  79%|#######9  | 336M/423M [00:00<00:00, 361MB/s]model.safetensors:  89%|########9 | 377M/423M [00:01<00:00, 371MB/s]model.safetensors:  99%|#########9| 419M/423M [00:01<00:00, 377MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 362MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานไม่เกี่ยวข้องกับสมมติฐานมากนัก  หลักฐานดูเหมือนจะเป็นเรื่องราวที่สับสนและไม่เกี่ยวข้องกับการที่คนพูดไม่รู้ว่าอยู่ที่ไร่หรือไม่ในวันนั้น\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นถึงความไม่เท่าเทียมกัน ("ฉันคิดว่ามันเป็นสิทธิพิเศษ...") ในขณะที่สมมติฐานกล่าวถึงการปฏิบัติอย่างเท่าเทียมกัน ("เราได้รับการปฏิบัติอย่างเท่าเทียมกัน...")  ดังนั้น หลักฐานจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 2\n', '0\n', '0\n', '0\n', '0\n', '0\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความพยายามที่จะหลีกเลี่ยงการใช้ระเบิดไฮโดรเจน ซึ่งแสดงให้เห็นว่าสมมติฐานนั้นเป็นไปได้  ดังนั้นจึงเกี่ยวข้องกัน\n', '2\n', '0\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่า Annie Lono กำลังจะพูดคุยเกี่ยวกับเรื่องราวบางอย่าง แต่ไม่สามารถทำได้ในวันนี้  นี่สอดคล้องกับสมมติฐานที่ว่า Annie Lono ได้จัดตารางเวลาใหม่ และทีมไม่สามารถพูดคุยกับเราได้ในวันนี้\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่า Annie Lono เติบโตขึ้นใน Augusta และกำลังจะเล่าเรื่องราวในวัยเด็กของเธอ สมมติฐานระบุว่า Annie Lono จะพูดคุยกับเราในวันนี้ หลักฐานสนับสนุนสมมติฐาน เนื่องจากการเล่าเรื่องจากวัยเด็กของเธอหมายความว่าเธอกำลังพูดคุยกับเรา', '2\n', '2\n', '0\n', '2\n', '2\n', '2\nหลักฐานระบุว่ามีเพียงผู้เขียนเท่านั้นที่พยายามหลีกเลี่ยงนโยบายการควบคุมการทดสอบ สมมติฐานบอกว่ามีหลายคนที่ทำเช่นนั้น ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '0\n', '2\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีการประมาณกระแสเงินสดสำหรับคัตตี้ แต่ไม่ได้ระบุจำนวนเงิน  สมมติฐานระบุจำนวนรายได้ของคัตตี้  ทั้งสองอย่างนี้จึงไม่ขัดแย้งกันและไม่เกี่ยวข้องกันโดยตรง  หลักฐานเพียงแค่บอกว่ามีการประเมินกระแสเงินสด  แต่ไม่บอกว่าการประเมินนั้นถูกต้องหรือไม่ตรงกับสมมติฐานหรือไม่\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0 (เข้าร่วม)\n\nหลักฐานแสดงให้เห็นถึงความขัดแย้งเกี่ยวกับการแบ่งงานระหว่างกลุ่มคน  ซึ่งสนับสนุนสมมติฐานที่มีการแบ่งงานอย่างไม่เท่าเทียมกันระหว่างกลุ่มคน\n', '1\n', '0\n', '2\n', 'ฉันไม่เข้าใจข้อความนี้ดีพอที่จะตอบคำถามได้  ข้อความมีคำที่ไม่รู้จัก ("<unk>") และดูเหมือนว่าจะไม่สมบูรณ์  ฉันต้องการข้อมูลเพิ่มเติมเพื่อทำความเข้าใจสมมติฐานและหลักฐานที่ให้มา  โปรดให้ข้อความที่สมบูรณ์และชัดเจนกว่านี้\n', '2\n', '2\n', '0\n', '2\nหลักฐานนั้นไม่สมบูรณ์และยากที่จะตีความความหมาย  มีคำที่ไม่รู้จัก (<unk>) หลายคำ ทำให้ไม่สามารถประเมินความสัมพันธ์ระหว่างหลักฐานกับสมมติฐานได้อย่างชัดเจน  ดังนั้น จึงเลือก 2 (ความขัดแย้ง)\n', 'ไม่สามารถระบุได้ว่าหลักฐานนั้นสนับสนุน ขัดแย้ง หรือไม่เกี่ยวข้องกับสมมติฐานใดๆ เนื่องจากข้อความไม่สมบูรณ์และไม่ชัดเจน  ไม่มีการระบุสมมติฐาน  คำว่า "<unk>" บ่งบอกถึงข้อมูลที่หายไปซึ่งจำเป็นต่อการวิเคราะห์  ดังนั้น จึงไม่สามารถให้คำตอบเป็น \'0\', \'1\' หรือ \'2\' ได้\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าไม่มีวิดีโอและการอนุมานนั้นขึ้นอยู่กับการคาดเดา  ซึ่งสอดคล้องกับสมมติฐานที่ว่าไม่มีวิดีโอและการขาดหลักฐานบ่งชี้ว่าจำเป็นต้องคาดเดา\n', '1\n', '0\n', '2\n', '2\n', '2\n', '2\nหลักฐานกล่าวถึงการรั่วไหลของรังสีเมื่อเกิดไฟไหม้  ในขณะที่สมมติฐานระบุว่าจะไม่มีการรั่วไหลระหว่างการยิง  นี่คือความขัดแย้งกัน\n', '2\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ามีเครื่องบินอวกาศหลายลำ (มากกว่าหนึ่งลำ) ลงจอดทุกสัปดาห์ สมมติฐานระบุว่ามีเพียงลำเดียวที่ลงจอดทุกสัปดาห์ ดังนั้นหลักฐานและสมมติฐานจึงขัดแย้งกัน', 'คำตอบคือ 1\n', '2\n', '2\n', '1\n', '1\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าระเบิดไม่สามารถระเบิดได้ไม่ว่าจะโดนกระแทกแค่ไหน  สิ่งนี้ไม่สนับสนุนหรือขัดแย้งกับสมมติฐานที่ว่าระเบิดไม่ได้ใช้งานโดยนักบิน  ทั้งสองข้อความพูดถึงแง่มุมที่แตกต่างกันของสถานการณ์  หลักฐานพูดถึงความทนทานของระเบิดในขณะที่สมมติฐานพูดถึงผู้ที่ใช้งานมัน\n', '2\nหลักฐานระบุว่า👍ไม่ระเบิดไม่ว่าจะตกกระแทกพื้นแรงแค่ไหน  นี่ขัดแย้งกับสมมติฐานที่ว่ามันระเบิดในอากาศได้\n', '2\nหลักฐานระบุว่าระเบิดไม่เป็นอันตรายไม่ว่าจะตกกระแทกพื้นแรงแค่ไหน ในขณะที่สมมติฐานระบุว่าระเบิดมีอันตราย  นี่คือข้อขัดแย้งกัน\n', 'คำตอบคือ 0\n\nหลักฐานและสมมติฐานไม่เกี่ยวข้องกัน  หลักฐานกล่าวถึงความทนทานของสิ่งของสำหรับงานบางอย่าง ในขณะที่สมมติฐานพูดถึงลักษณะของสิ่งของสำหรับการใช้ในชีวิตประจำวัน ซึ่งเป็นสิ่งที่แตกต่างกัน', '0\n', '0\n', '2\n', '2\n', '2\n', '2\n', 'ไม่สามารถระบุได้ว่าหลักฐานนั้นเกี่ยวข้องหรือขัดแย้งกับสมมติฐานใดๆ  เนื่องจากสมมติฐานนั้นยังไม่ถูกระบุ  คำตอบจึงเป็น **0**\n', '2\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n\nหลักฐานระบุว่าการหาผลรวมนั้นจำเป็นสำหรับการแก้ปัญหา  สมมติฐานระบุว่าการหาผลรวมนั้นจำเป็นสำหรับการแก้ปัญหาเช่นกัน  ทั้งสองอย่างนี้จึงสอดคล้องกัน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดรู้วิธีคำนวณยอดรวมบางอย่างสำหรับลิขสิทธิ์ ในขณะที่สมมติฐานแสดงให้เห็นว่าผู้พูดไม่รู้วิธีคำนวณยอดรวมลิขสิทธิ์อื่นๆ  ทั้งสองข้อความจึงขัดแย้งกัน\n', 'คำตอบคือ 0 (สอดคล้องกัน)\n\nหลักฐานระบุว่าผู้เขียนใช้ผลรวมเพื่อวิเคราะห์บางสิ่ง สมมติฐานกล่าวว่าผู้เขียนจะคำนวณผลลัพธ์จากผลรวม  ทั้งสองข้อความนี้สอดคล้องกัน  ผู้เขียนใช้ผลรวมเพื่อไปถึงผลลัพธ์บางอย่าง ซึ่งเป็นกระบวนการคำนวณ\n', 'คำตอบคือ 2\n\nหลักฐาน ("เขามา, เขาเปิดประตูและยิ้มแย้มมีความสุขมองกระจกและได้เห็นสีหน้าบนใบหน้าของเขา, และผมบอกได้เลยว่าเขาโกหก") ขัดแย้งกับสมมติฐาน ("เขาตื่นเต้นและมีความสุขมากจนกระแทกบานประตูไป").  การกระทำและการแสดงออกทางสีหน้าที่อธิบายไว้ไม่สอดคล้องกัน  การโกหกบ่งบอกถึงความรู้สึกที่แตกต่างจากความตื่นเต้นและความสุขอย่างมาก\n', '1\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐาน  หลักฐานระบุว่าการมองเห็นใบหน้าของคนๆ หนึ่งเพียงอย่างเดียวก็เพียงพอแล้วที่จะทำให้ผู้บรรยายรู้ว่าคนๆ นั้นหมดหวัง  สมมติฐานระบุสิ่งที่คล้ายกัน  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', '0\n', '2\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานกล่าวว่าราโมนอยู่บนพื้นขดตัวอยู่ในท่าเหมือนทารกในครรภ์  ซึ่งขัดแย้งกับสมมติฐานที่ว่าพระเจ้าช่วยและราโมนยืนอยู่  ทั้งสองข้อความไม่สอดคล้องกัน\n', '1\n', '1\n', '2\n', 'คำตอบคือ 2\n\nหลักฐาน “แล้วความจริงก็คือ เธอเป็นความสว่าง!” บ่งบอกถึงการอ้างว่าผู้หญิงคนหนึ่งเป็น “ความสว่าง” ซึ่งเป็นสิ่งที่คลุมเครือและไม่สามารถตรวจสอบได้ง่าย  ส่วน “0: ก็หนักเลย” ดูเหมือนจะเป็นความเห็นส่วนตัวที่ไม่เกี่ยวข้องโดยตรงกับการอ้างว่าเธอเป็น “ความสว่าง”  จึงไม่มีความเกี่ยวข้องหรือสนับสนุนสมมติฐานใดๆได้  ดังนั้นคำตอบจึงเป็น 2 (ความขัดแย้ง) เพราะมันไม่สามารถระบุความสัมพันธ์ที่ชัดเจนระหว่างหลักฐานกับสมมติฐานใดๆได้\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดไม่เคยถามถึงสถานที่ที่กลุ่มบุคคลนั้นไป  หลักฐานนี้ไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ เนื่องจากไม่ได้มีการระบุสมมติฐานใดๆ  หลักฐานเพียงแค่บอกถึงการกระทำของผู้พูดเท่านั้น  ดังนั้นจึงไม่มีความสัมพันธ์ที่ชัดเจนกับสมมติฐานใดๆ\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ากลุ่มคนมักจะแจ้งให้ทราบว่าพวกเขาอยู่ที่ไหนและกำลังจะไปไหน  ซึ่งขัดแย้งกับสมมติฐานที่ว่าพวกเขาจะไม่เปิดเผยสถานที่ที่พวกเขาไปแม้กระทั่งหลังจากอยู่ที่นั่นไปสักพักแล้ว\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานที่ว่า "เรากำลังเตรียมที่อยู่เพื่อเลี้ยงดู" แสดงให้เห็นว่าเรากำลังลงทุนทรัพยากรเพื่อการเลี้ยงดู  ในขณะที่สมมติฐานที่ว่า "พวกเขาไม่จ่ายอะไรให้กับเราเลย" บ่งบอกว่าเราไม่ได้รับการสนับสนุนทางการเงิน  นี่เป็นข้อมูลที่ขัดแย้งกัน  เพราะการเตรียมที่อยู่อาศัยเพื่อเลี้ยงดูมักจะเกี่ยวข้องกับค่าใช้จ่าย  ดังนั้น  หลักฐานจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ **1**\n\nหลักฐานสนับสนุนสมมติฐานที่ว่ามีการจ่ายค่าที่อยู่สำหรับทรัพย์สิน\n\n', '0\n', '0\n', '2\n', '0\n', 'คำตอบคือ 1\n', '0\n', '2\n', '2\n', '0\n', '2\n', '2\n', '0\n', '0\n', '2\n', 'ไม่มีสมมติฐานให้ประเมิน จึงไม่สามารถระบุได้ว่าหลักฐานนั้นเกี่ยวข้องหรือขัดแย้งกับสมมติฐานหรือไม่\n\nคำตอบ: **ไม่สามารถตอบได้** (เนื่องจากไม่มีสมมติฐาน)\n', '2\n', '0\n', '2\n', '0\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าชุดมีความคล้ายคลึงกับชุดอวกาศ  แต่ก็มีคุณสมบัติเพิ่มเติมคือการสะท้อนความร้อน และทำจากวัสดุที่แตกต่างกัน (พลาสติกจากของเหลว)  สิ่งนี้สนับสนุนสมมติฐานที่ว่าชุดคล้ายกับชุดอวกาศ  แต่ยังเพิ่มข้อมูลเพิ่มเติมเกี่ยวกับคุณสมบัติและวัสดุที่ใช้  ดังนั้นจึงมีความเกี่ยวข้องและสนับสนุนสมมติฐาน  แต่ไม่ใช่การซ้ำซ้อนทั้งหมด\n', 'คำตอบคือ 0\n\nหลักฐานอธิบายชุดปรับความดันที่ทำเอง แต่ไม่ได้กล่าวถึงสีของชุด  สมมติฐานอนุญาตให้สวมใส่ชุดที่มีสีใดๆ  ดังนั้นจึงไม่มีความเกี่ยวข้องหรือความขัดแย้งกัน\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0. หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ เนื่องจากไม่มีการระบุสมมติฐาน', '1\n', '2\n', '2\n', '0\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าลูกพูดว่า "ฉันไม่ได้อ่านหนังสือมากมาย" ซึ่งขัดแย้งกับสมมติฐานที่แม่พยายามเลือกหนังสือที่จะอ่าน เพราะถ้าลูกอ่านหนังสือไม่มาก  ลูกจะไม่สามารถแนะนำแม่ได้  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '2\n', '0\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานอธิบายถึงการเปลี่ยนแปลงทางอารมณ์อย่างรวดเร็วและรุนแรง ซึ่งสอดคล้องกับสมมติฐานที่ว่าเธอไม่มีโอกาสมีความสุขเนื่องจากประสบการณ์เหล่านั้นอาจนำไปสู่ความล้มเหลวได้  หลักฐานสนับสนุนสมมติฐาน\n', '1\n', '1\n', '2\n', '1\n', 'คำตอบคือ 1\n', '0\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐานระบุว่ามีขั้นตอนบางอย่างก่อนการบิน (การไปถึงหมายเลขห้องชั้นที่สูง)  สมมติฐานระบุว่าพวกเขา *ปล่อยให้* คุณบิน 2 วินาทีในวันแรก โดยไม่พูดถึงขั้นตอนหรือข้อจำกัดใดๆ  ทั้งสองข้อความนี้จึงขัดแย้งกัน\n', '2\n', '2\n', '2\n', 'หลักฐานนั้นสนับสนุนสมมติฐาน  คำตอบคือ **1**\n', '2\n', '2\n', '0\n', 'คำตอบคือ **1**\n\nหลักฐานสนับสนุนสมมติฐาน  ถ้าผู้พูดสามารถทดสอบสมมติฐานได้  นั่นหมายความว่าพวกเขามองว่าไม่มีอะไรที่เป็นไปไม่ได้  ซึ่งสอดคล้องกับสมมติฐาน\n', '2\n', '2\n', '2\n', '2\nหลักฐานแสดงให้เห็นว่าน้องสาวของเธออาจจะไม่ชอบเธอ และเธออาจจะไม่เชื่อถือคำพูดของเธอ ดังนั้นจึงขัดแย้งกับสมมติฐาน\n', '2\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n', '2\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานและสมมติฐานไม่เกี่ยวข้องกัน  ประโยคทั้งสองกล่าวถึงสถานที่ที่ไม่รู้จัก แต่ต่างกัน  ประโยคแรกกล่าวถึงสัตว์และสถานที่ที่พวกมันจะไป  ประโยคที่สองกล่าวถึงคนและสถานที่ที่พวกเขาไปเที่ยว  ไม่มีความเชื่อมโยงกันระหว่างสองประโยค\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าเราไม่รู้ว่าพวกเขารู้สึกอยากไปที่ไหน แต่เรารู้ว่าพวกเขาจะไปที่ไหน  นี่ขัดแย้งกับสมมติฐานที่อาจจะบอกว่าพวกเขารู้สึกอยากไปที่ไหน และเรารู้อยู่แล้วว่าพวกเขาจะไปที่ไหน  การรู้ว่าพวกเขาจะไปที่ไหน ไม่ได้หมายความว่าเรารู้ความรู้สึกของพวกเขา  จึงเป็นความขัดแย้ง\n', '2\n', '2\n', '0\n', 'คำตอบคือ 0\n', '2\n', 'คำตอบคือ 0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1800 (หรือใกล้เคียง) ในขณะที่สมมติฐานระบุว่าบุคคลนั้นเกิดก่อนปี 1900  หลักฐานและสมมติฐานไม่ขัดแย้งกัน แต่หลักฐานไม่ได้สนับสนุนสมมติฐานอย่างเต็มที่  สมมติฐานเป็นจริงกว้างเกินไป หลักฐานแสดงให้เห็นถึงช่วงเวลาที่แน่นอนกว่าที่สมมติฐานแสดงไว้  ดังนั้น จึงมีความขัดแย้งเล็กน้อย  คำตอบที่เหมาะสมที่สุดคือ 2 (ความขัดแย้ง)\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี พ.ศ. 199480 ซึ่งเป็นไปไม่ได้เนื่องจากปี พ.ศ. 2566 เท่านั้น สมมติฐานระบุว่าบุคคลนั้นไม่ได้เกิดจนกระทั่งปี พ.ศ. 2527 ซึ่งหมายความว่าหลักฐานและสมมติฐานนั้นขัดแย้งกัน\n', '1\n', '2\n', '1\n', '0\n', '2\n', '1\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าเด็กบางคนปฏิเสธแชมเปญ ดังนั้นจึงสนับสนุนสมมติฐานที่ว่าเด็กบางคนปฏิเสธแชมเปญ', '2\n', '2\n', 'คำตอบคือ 0\n', '1\n', '2\n', '0\n', '2\n', 'คำตอบคือ 0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่านี่คือประเด็นทั้งหมด ซึ่งเกี่ยวข้องกับสมมติฐานที่ว่าจุดประสงค์คือการบอกเราว่ามันอันตรายเพียงใด  แต่ไม่ได้พิสูจน์หรือหักล้างสมมติฐานโดยตรง\n', '0\n', '2\n', '0\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 2
Accuracy th: 0.4595959595959596
'XNLI' object has no attribute 'evaluate_results'
