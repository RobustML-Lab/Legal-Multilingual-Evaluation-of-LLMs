README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 89.2MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  63%|######2   | 31.5M/50.2M [00:00<00:00, 274MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 262MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 254MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 338MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###1      | 123000/392702 [00:00<00:00, 1217392.74 examples/s]Generating train split:  64%|######4   | 252000/392702 [00:00<00:00, 1250700.13 examples/s]Generating train split:  97%|#########6| 380000/392702 [00:00<00:00, 1259424.27 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1251190.01 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1164180.78 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1000461.44 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 474kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 3.40MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 34.1MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 49.7MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:01, 247MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:01, 298MB/s]model.safetensors:  26%|##6       | 115M/440M [00:00<00:01, 310MB/s] model.safetensors:  36%|###5      | 157M/440M [00:00<00:00, 318MB/s]model.safetensors:  45%|####5     | 199M/440M [00:00<00:00, 316MB/s]model.safetensors:  55%|#####4    | 241M/440M [00:00<00:00, 323MB/s]model.safetensors:  64%|######4   | 283M/440M [00:00<00:00, 311MB/s]model.safetensors:  71%|#######1  | 315M/440M [00:01<00:00, 308MB/s]model.safetensors:  81%|########  | 357M/440M [00:01<00:00, 315MB/s]model.safetensors:  90%|######### | 398M/440M [00:01<00:00, 314MB/s]model.safetensors:  98%|#########7| 430M/440M [00:01<00:00, 313MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 310MB/s]
Attack entry stored in: output/attacks/attack.txt
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
[None, None, None, None, '1\n', '1\n', None, '0\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '0\n', '0\n', None, '1\n', '1\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, None, None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', None, '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', None, '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 21
Accuracy en: 0.441340782122905
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  43%|####2     | 31.5M/73.8M [00:00<00:00, 251MB/s]train-00000-of-00001.parquet:  85%|########5 | 62.9M/73.8M [00:00<00:00, 259MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 257MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 163MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 50.1MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  23%|##2       | 89000/392702 [00:00<00:00, 875584.18 examples/s]Generating train split:  46%|####5     | 180000/392702 [00:00<00:00, 884133.02 examples/s]Generating train split:  70%|######9   | 273000/392702 [00:00<00:00, 899580.25 examples/s]Generating train split:  93%|#########2| 365000/392702 [00:00<00:00, 906065.92 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 899138.24 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 971945.56 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 829730.43 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 15.4kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 5.05MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 858kB/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 857kB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 821kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   2%|2         | 10.5M/454M [00:00<00:10, 43.3MB/s]pytorch_model.bin:  12%|#1        | 52.4M/454M [00:00<00:02, 165MB/s] pytorch_model.bin:  18%|#8        | 83.9M/454M [00:00<00:01, 212MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:01, 256MB/s] pytorch_model.bin:  35%|###4      | 157M/454M [00:00<00:01, 270MB/s]pytorch_model.bin:  44%|####3     | 199M/454M [00:00<00:00, 289MB/s]pytorch_model.bin:  53%|#####3    | 241M/454M [00:00<00:00, 299MB/s]pytorch_model.bin:  62%|######2   | 283M/454M [00:01<00:00, 310MB/s]pytorch_model.bin:  72%|#######1  | 325M/454M [00:01<00:00, 311MB/s]pytorch_model.bin:  81%|########  | 367M/454M [00:01<00:00, 307MB/s]pytorch_model.bin:  88%|########7 | 398M/454M [00:01<00:00, 309MB/s]pytorch_model.bin:  95%|#########4| 430M/454M [00:01<00:00, 308MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 276MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '2\n', '2\n', '1\n', '1\n', '2\n', '0\n', '1\n', '2\n', '2\n', '1\n', 'Η απάντηση είναι **1**.\n\nΗ προϋπόθεση δηλώνει ότι ο ομιλητής ήταν ο μόνος που έτρεχε τις ρυθμίσεις δοκιμής. Η υπόθεση δηλώνει ότι στον ομιλητή δεν τον ενδιαφέρει αν είναι αυτός που λειτουργεί τις ρυθμίσεις και τις δοκιμές.  Δεν υπάρχει αντίφαση, ούτε η προϋπόθεση συνεπάγεται την υπόθεση.  Η προϋπόθεση περιγράφει ένα γεγονός, ενώ η υπόθεση περιγράφει μια άποψη.\n', None, '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', None, None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', None, '2\n', '2\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, None, '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '2\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '2\n', None, '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', 'Η απάντηση είναι 1.\n\nΗ απάντηση δηλώνει λύπη για κάτι που συνέβη, αλλά η υπόθεση δηλώνει αβεβαιότητα για το αν θα μπορούσε να είχε γίνει κάτι διαφορετικά. Δεν υπάρχει άμεση αντίφαση, ούτε ούτε άμεση συνέπεια.\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '2\n', '1\n', '2\n', '2\n', '2\n', '2\n', '1\n', '2\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 12
Accuracy el: 0.46808510638297873
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  32%|###2      | 21.0M/65.4M [00:00<00:00, 204MB/s]train-00000-of-00001.parquet:  80%|########  | 52.4M/65.4M [00:00<00:00, 254MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 255MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 350MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 356MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  25%|##4       | 98000/392702 [00:00<00:00, 971397.02 examples/s]Generating train split:  50%|#####     | 198000/392702 [00:00<00:00, 985825.38 examples/s]Generating train split:  76%|#######6  | 299000/392702 [00:00<00:00, 992854.04 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 986146.73 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 955983.03 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 776203.42 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 424kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 5.57MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 25.6MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 38.2MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   3%|3         | 21.0M/672M [00:00<00:03, 205MB/s]model.safetensors:   8%|7         | 52.4M/672M [00:00<00:02, 258MB/s]model.safetensors:  12%|#2        | 83.9M/672M [00:00<00:02, 268MB/s]model.safetensors:  17%|#7        | 115M/672M [00:00<00:02, 271MB/s] model.safetensors:  22%|##1       | 147M/672M [00:00<00:01, 285MB/s]model.safetensors:  27%|##6       | 178M/672M [00:00<00:01, 293MB/s]model.safetensors:  31%|###1      | 210M/672M [00:00<00:01, 293MB/s]model.safetensors:  36%|###5      | 241M/672M [00:00<00:01, 291MB/s]model.safetensors:  41%|####      | 273M/672M [00:00<00:01, 291MB/s]model.safetensors:  45%|####5     | 304M/672M [00:01<00:01, 297MB/s]model.safetensors:  50%|####9     | 336M/672M [00:01<00:01, 301MB/s]model.safetensors:  55%|#####4    | 367M/672M [00:01<00:01, 304MB/s]model.safetensors:  59%|#####9    | 398M/672M [00:01<00:00, 301MB/s]model.safetensors:  64%|######3   | 430M/672M [00:01<00:00, 300MB/s]model.safetensors:  69%|######8   | 461M/672M [00:01<00:00, 301MB/s]model.safetensors:  73%|#######3  | 493M/672M [00:01<00:00, 303MB/s]model.safetensors:  78%|#######7  | 524M/672M [00:01<00:00, 305MB/s]model.safetensors:  83%|########2 | 556M/672M [00:01<00:00, 302MB/s]model.safetensors:  87%|########7 | 587M/672M [00:02<00:00, 295MB/s]model.safetensors:  94%|#########3| 629M/672M [00:02<00:00, 305MB/s]model.safetensors: 100%|#########9| 671M/672M [00:02<00:00, 304MB/s]model.safetensors: 100%|##########| 672M/672M [00:02<00:00, 294MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '2\n', '0\n', '1\n', '0\n', 'Отговорът е 2.\n\nПредположението е, че някои хора плащат за място, където да трябва, докато легендата е, че някои хора не плащат за нищо. Тези две твърдения си противоречат.\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', 'За да отговоря на въпроса, се нуждая от хипотезата.  Не е дадена в описанието.  Без хипотеза не мога да определя дали дадените примери я включват, противоречат или нито едното.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '0\n', '2\n', '0\n', '1\n', '2\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', 'Отговорът е 1.\n\nПредпоставката гласи, че не са прочетени две книги, които са били необходими за четене.  Задължението е, че някои книги не са прочетени, и по-късно някои страници от книги са били прочетени.  Двете твърдения не се включват едно в друго, нито си противоречат.  Няма връзка между броя на непрочетените книги и броя на прочетените страници в тези книги.\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '2\n', '2\n', '0\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_2.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy bg: 0.4472361809045226
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  59%|#####9    | 31.5M/53.2M [00:00<00:00, 248MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 269MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 310MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 267MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###1      | 123000/392702 [00:00<00:00, 1221017.41 examples/s]Generating train split:  63%|######2   | 246000/392702 [00:00<00:00, 1221304.76 examples/s]Generating train split:  94%|#########4| 370000/392702 [00:00<00:00, 1224648.04 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1220713.80 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1166313.10 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1019904.00 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 1.96MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 6.46MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 20.1MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 50.0MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.35MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   5%|4         | 21.0M/440M [00:00<00:02, 145MB/s]pytorch_model.bin:  12%|#1        | 52.4M/440M [00:00<00:01, 199MB/s]pytorch_model.bin:  21%|##1       | 94.4M/440M [00:00<00:01, 255MB/s]pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:01, 275MB/s] pytorch_model.bin:  36%|###5      | 157M/440M [00:00<00:00, 283MB/s]pytorch_model.bin:  43%|####2     | 189M/440M [00:00<00:00, 290MB/s]pytorch_model.bin:  52%|#####2    | 231M/440M [00:00<00:00, 300MB/s]pytorch_model.bin:  60%|#####9    | 262M/440M [00:00<00:00, 302MB/s]pytorch_model.bin:  69%|######9   | 304M/440M [00:01<00:00, 310MB/s]pytorch_model.bin:  79%|#######8  | 346M/440M [00:01<00:00, 312MB/s]pytorch_model.bin:  86%|########5 | 377M/440M [00:01<00:00, 311MB/s]pytorch_model.bin:  95%|#########5| 419M/440M [00:01<00:00, 315MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 290MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 7
}
]. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {
}
, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, retry_delay {
  seconds: 55
}
]. Retrying after 60 seconds...
['1\n', '1\n', '1\n', 'La respuesta es 2.\n\nLa premisa establece que el hablante creía que era el único 922 ex-o con el campo de carrera affc de la fuerza laboral ese día. La hipótesis establece que el hablante sabía que no era la única persona contra el campo ese día. Estas dos afirmaciones se contradicen entre sí.  La creencia del hablante (premisa) es incompatible con su conocimiento (hipótesis).\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa indica que no había manera de lanzar una bomba militar desde un C-124, por lo que salvar ese tipo de avión era lo menos importante.  La hipótesis dice que no les importó guardar nada.  No se puede decir que una implique a la otra. La premisa ofrece una razón específica por la que *algo* no fue salvado (un tipo específico de avión), mientras que la hipótesis es una afirmación mucho más general.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '2\n', '1\n', '0\n', '2\n', '1\n', None, '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', None, '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '1\n']
Saved predictions to: predicted_3.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 8
Accuracy es: 0.4791666666666667
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  57%|#####6    | 31.5M/55.4M [00:00<00:00, 245MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 269MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 424MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 346MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  30%|###       | 118000/392702 [00:00<00:00, 1169232.36 examples/s]Generating train split:  61%|######1   | 240000/392702 [00:00<00:00, 1192571.92 examples/s]Generating train split:  92%|#########1| 360000/392702 [00:00<00:00, 1190970.08 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1187073.22 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1110296.05 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 936077.53 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 242kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.15MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 11.9MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 22.4MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   9%|9         | 41.9M/445M [00:00<00:01, 341MB/s]model.safetensors:  19%|#8        | 83.9M/445M [00:00<00:01, 342MB/s]model.safetensors:  28%|##8       | 126M/445M [00:00<00:00, 325MB/s] model.safetensors:  38%|###7      | 168M/445M [00:00<00:00, 324MB/s]model.safetensors:  47%|####7     | 210M/445M [00:00<00:00, 325MB/s]model.safetensors:  57%|#####6    | 252M/445M [00:00<00:00, 333MB/s]model.safetensors:  66%|######5   | 294M/445M [00:00<00:00, 334MB/s]model.safetensors:  75%|#######5  | 336M/445M [00:01<00:00, 337MB/s]model.safetensors:  85%|########4 | 377M/445M [00:01<00:00, 340MB/s]model.safetensors:  94%|#########4| 419M/445M [00:01<00:00, 343MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 335MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '0\n', '1\n', '0\n', '0\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '0\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '2\n', '0\n', '1\n', '0\n', '1\n', '1\n', None, '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '2\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, None, '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '2\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '0\n']
Saved predictions to: predicted_4.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 14
Accuracy fr: 0.46236559139784944
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  27%|##7       | 21.0M/76.5M [00:00<00:00, 198MB/s]train-00000-of-00001.parquet:  82%|########2 | 62.9M/76.5M [00:00<00:00, 277MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 274MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 299MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 423MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  21%|##1       | 84000/392702 [00:00<00:00, 828268.82 examples/s]Generating train split:  43%|####3     | 170000/392702 [00:00<00:00, 841344.51 examples/s]Generating train split:  75%|#######5  | 295000/392702 [00:00<00:00, 831365.52 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 825201.16 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 827760.39 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 917298.02 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 832441.97 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.09MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 4.65MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 34.9MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/423M [00:00<00:01, 305MB/s]model.safetensors:  17%|#7        | 73.4M/423M [00:00<00:01, 317MB/s]model.safetensors:  27%|##7       | 115M/423M [00:00<00:00, 327MB/s] model.safetensors:  37%|###7      | 157M/423M [00:00<00:00, 318MB/s]model.safetensors:  47%|####7     | 199M/423M [00:00<00:00, 311MB/s]model.safetensors:  54%|#####4    | 231M/423M [00:00<00:00, 305MB/s]model.safetensors:  64%|######4   | 273M/423M [00:00<00:00, 315MB/s]model.safetensors:  72%|#######1  | 304M/423M [00:00<00:00, 300MB/s]model.safetensors:  79%|#######9  | 336M/423M [00:01<00:00, 302MB/s]model.safetensors:  89%|########9 | 377M/423M [00:01<00:00, 310MB/s]model.safetensors:  99%|#########9| 419M/423M [00:01<00:00, 317MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 313MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าผู้พูดผิดหวังที่ไม่ได้พูดคุยกับบุคคลอีกต่อไป  นี่เป็นการสนับสนุนสมมติฐานที่ว่ามีการขาดการสื่อสารหรือความสัมพันธ์ระหว่างผู้พูดกับบุคคลนั้น  ดังนั้น หลักฐานจึงสนับสนุนสมมติฐานอย่างเต็มที่\n', 'คำตอบคือ 1\n', '2\n', 'หลักฐานนั้นไม่เกี่ยวข้องกับสมมติฐานเลย  หลักฐานดูเหมือนจะเป็นข้อความที่ไม่สมบูรณ์และไม่เกี่ยวข้องกับสถานการณ์ในไร่  ดังนั้นคำตอบคือ **0**\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงประสบการณ์ส่วนตัวของผู้เขียนที่สนับสนุนสมมติฐานว่าทุกสิ่งเป็นเรื่องโกหก  แม้ว่าหลักฐานจะไม่ครอบคลุมหรือเป็นตัวแทนของทุกสถานการณ์ แต่ก็ยังสนับสนุนสมมติฐานโดยตรง\n', '2\n', '0\n', '2\nหลักฐานบอกเราว่าบุคคลนั้นมาช้าเกินไป  ซึ่งขัดแย้งกับสมมติฐานที่ว่าเขาเข้ามาช้าเกินไป  ไม่มีความสัมพันธ์ใดๆ ระหว่างข้อความทั้งสอง\n', '2\n', 'คำตอบคือ 1\n', '0\nหลักฐานแสดงให้เห็นว่าผู้พูดเลือกที่จะไม่พูดคุยเกี่ยวกับหัวข้อหนึ่ง  สมมติฐานระบุว่าผู้พูดจะไม่พูดคุยเกี่ยวกับหัวข้อนั้นเช่นกัน  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานกล่าวถึงการเก็บรักษาสิ่งของเนื่องจากไม่สามารถคำนวณไฮโดรเจนได้  ในขณะที่สมมติฐานพูดถึงการปกป้องสิ่งหนึ่งมากกว่าสิ่งอื่น  ไม่มีความสัมพันธ์ที่ชัดเจนระหว่างสองประเด็นนี้  จึงถือว่าขัดแย้งกัน\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความยากลำบากในการกำจัดระเบิดไฮโดรเจน ซึ่งสนับสนุนสมมติฐานที่ว่าเราควรหลีกเลี่ยงการใช้มัน  หลักฐานไม่ขัดแย้งกับสมมติฐานแต่ก็ไม่ได้พิสูจน์มันโดยตรง  มันเป็นหลักฐานสนับสนุนโดยอ้อม\n', '2\n', '0\n', '0\n', '2\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดได้ห้าและได้สองออกมา  สมมติฐานระบุว่าผู้พูดได้จัดการกับ 2  สิ่งนี้ขัดแย้งกันเพราะหลักฐานระบุว่ามีการได้สองออกมา  แต่สมมติฐานแสดงให้เห็นว่าได้มีการจัดการกับสองแล้ว  ดังนั้นคำตอบจึงเป็น 2 (ความขัดแย้ง)\n', '2\n', 'ฉันต้องการข้อมูลเพิ่มเติมเกี่ยวกับสมมติฐานเพื่อที่จะบอกได้ว่าหลักฐานนี้สนับสนุน ขัดแย้ง หรือไม่เกี่ยวข้องกับสมมติฐานนั้น  โปรดให้สมมติฐานแก่ฉัน\n', '2\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐานระบุว่าผู้พูดเสียชีวิตคนเดียวในขณะที่ทดสอบหน่วยควบคุม ซึ่งชี้ให้เห็นว่าไม่มีใครอยู่ด้วยในระหว่างการทดสอบ  ในทางกลับกัน สมมติฐานกล่าวถึงการจัดทำแบบทดสอบโดยห้องประชุมขนาดเล็ก ซึ่งแสดงถึงการมีผู้คนร่วมกัน  ทั้งสองส่วนนี้จึงไม่สอดคล้องกัน\n', '2\n', '2\n', 'คำตอบคือ **2** (ความขัดแย้ง)\n\nหลักฐานระบุว่าบุคคลนั้นเกษียณเร็วตามที่ริคกล่าว ซึ่งไม่ระบุปีที่เกษียณ สมมติฐานระบุปีเกษียณเป็น 2002 ข้อมูลทั้งสองจึงไม่ตรงกัน  จึงถือว่าขัดแย้งกัน\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่ามีกระแสเงินสดและลูกค้าคนหนึ่ง (ชื่อ Utty) ทำรายได้ 10,000 ดอลลาร์  นี่สนับสนุนสมมติฐานทั่วไปเกี่ยวกับธุรกิจที่มีกระแสเงินสดและลูกค้าที่สร้างรายได้  แม้ว่าจะไม่ครอบคลุมทุกแง่มุมของธุรกิจ แต่ก็เข้ากับสมมติฐานโดยทั่วไป\n', '0\n', '1\n', 'คำตอบคือ 0\n', '2\n', '2\n', '1\n', '0\n', '0\n', '0\n', '2\nหลักฐานและสมมติฐานไม่มีความเกี่ยวข้องกัน  หลักฐานกล่าวถึงสิ่งที่ดูเหมือนว่าจะเป็นชื่อของเกมหรือแอปพลิเคชัน  ในขณะที่สมมติฐานพูดถึงแม่และสัตว์น้ำ  ไม่มีอะไรที่เชื่อมโยงทั้งสองอย่างเข้าด้วยกัน\n', '1\n', '0\n', '2\n', '2\n', '0\n', '2\nหลักฐานกล่าวถึงภาพยนตร์เรื่องที่สองและข้อมูลที่ขาดหายไป  สมมติฐานกล่าวถึงการถ่ายทำหนัง  ทั้งสองไม่ได้เกี่ยวข้องกันโดยตรง  ดังนั้นจึงเป็นความขัดแย้ง\n', '1\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐานทั้งสองส่วน:\n\n* **"เธอพูดว่าน้ำตาไหลออกมาจากดวงตาของเธอ"** สนับสนุนส่วนของสมมติฐานที่ว่า "เธอกำลังร้องไห้อยู่"\n* **"และบอกฉันว่าวิญญาณมาปรากฏตัวที่ระเบียง"** สนับสนุนส่วนของสมมติฐานที่ว่า "เธอขอให้เขากลับมาที่ระเบียง"  แม้ว่าจะไม่ใช่คำขอตรงๆ แต่ก็บ่งชี้ว่าวิญญาณนั้นมีความเกี่ยวข้องกับระเบียง และการที่เธอร้องไห้เพราะวิญญาณนั้นอาจเป็นเหตุผลที่เธอบอกให้เขากลับมาที่ระเบียง\n\nดังนั้น หลักฐานจึงสนับสนุนสมมติฐาน  คำตอบจึงเป็น 1\n', '0\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานกล่าวถึงความเป็นไปได้ของการรั่วไหลของรังสีจากส่วนประกอบตะกั่วที่หลอมละลายหลังจากไฟไหม้เครื่องบิน สมมติฐานกล่าวถึงความเป็นไปได้ของการรั่วไหลของรังสีจากส่วนประกอบหลักหลังจากที่เครื่องบินไหม้  แม้ว่ารายละเอียดจะแตกต่างกันเล็กน้อย (ส่วนประกอบตะกั่ว vs. ส่วนประกอบหลัก)  แต่ทั้งสองกล่าวถึงความเป็นไปได้ของการรั่วไหลของรังสีจากส่วนประกอบของเครื่องบินหลังจากเกิดไฟไหม้ จึงมีความเกี่ยวข้องกัน\n', '2\n', '1\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าเครื่องบินหลายลำบินไปดวงจันทร์ทุกสัปดาห์ สมมติฐานระบุว่ามีเครื่องบินโดยสาร 6 ลำลงจอดทุกสัปดาห์ หลักฐานไม่ได้ระบุว่าเครื่องบินเหล่านั้นลงจอดที่ไหน และไม่ขัดแย้งกับสมมติฐาน', 'คำตอบคือ 0\nหลักฐานอธิบายถึงความถี่ของเที่ยวบินไปยังสถานที่เฉพาะเจาะจง ในขณะที่สมมติฐานเกี่ยวกับการอนุญาตของเครื่องบินทางอากาศ  หลักฐานไม่ได้ให้ข้อมูลใดๆเกี่ยวกับการอนุญาต  จึงไม่เกี่ยวข้องกัน', '2\n', '0\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีการฝึกอบรมเกี่ยวกับชุดสูทความดันอากาศระดับสูง สมมติฐานกล่าวถึงการฝึกอบรมในอนาคตเกี่ยวกับชุดสูทความดันอากาศระดับสูง  แม้ว่าหลักฐานจะไม่ได้ระบุถึงการฝึกอบรมในอนาคตโดยตรง แต่ก็ไม่ขัดแย้งกับสมมติฐาน  หลักฐานแสดงให้เห็นว่าการฝึกอบรมประเภทนี้เป็นไปได้ และสมมติฐานตั้งอยู่บนความเป็นไปได้นั้น\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าระเบิดปลอดภัยและจะไม่ระเบิดไม่ว่าจะตกกระแทกพื้นแรงแค่ไหน  สมมติฐานกล่าวถึงการใช้งานโดยนักบิน  ไม่มีอะไรในหลักฐานที่เกี่ยวข้องกับการใช้งานโดยนักบิน ดังนั้น หลักฐานจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าหิมะไม่ระเบิดไม่ว่าจะกระแทกพื้นแรงแค่ไหน  นี่ขัดแย้งกับสมมติฐานที่ว่าหิมะจะระเบิดได้\n', '2\n', '0\n', '1\n', '1\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้เขียนพยายามคำนวณผลรวมทางคณิตศาสตร์ แต่ไม่ประสบความสำเร็จ  คำถามแสดงให้เห็นถึงความไม่เข้าใจและขอความช่วยเหลือ  ดังนั้นหลักฐานและคำถามจึงขัดแย้งกัน  ผู้เขียนพยายามทำบางอย่างแต่ไม่สามารถทำได้  แสดงว่าไม่มีความเข้าใจร่วมกัน  จึงเป็นความขัดแย้ง\n', 'คำตอบคือ 0\n\nหลักฐานไม่มีข้อมูลที่เพียงพอที่จะสนับสนุนหรือหักล้างสมมติฐาน หลักฐานกล่าวถึงการคำนวณผลรวม แต่ไม่ได้ระบุว่าผลรวมใด หรือความเกี่ยวข้องกับสมมติฐานโดยตรง  สมมติฐานระบุถึงการคำนวณยอดรวมโดยไม่มีรายละเอียดเพิ่มเติม  ดังนั้นจึงไม่มีความเกี่ยวข้องหรือความขัดแย้งกัน', '2\n', '1\n', '0\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ **1**\n\nหลักฐาน "ได้รับการช่วยเหลือทั้งด้านอาหารและเครื่องแต่งกาย" สนับสนุนสมมติฐานที่ว่า "เขาไม่เคยทำอะไรเพื่อตัวเอง"  เพราะการได้รับการช่วยเหลือในเรื่องพื้นฐานอย่างอาหารและเครื่องแต่งกายแสดงให้เห็นว่าเขาพึ่งพาผู้อื่นและไม่ได้ดูแลตนเอง\n', '2\n', '2\n', '2\n', '0\n', '2\n', '2\n', '2\n', 'คำตอบคือ 2\n', 'คำตอบคือ 2\n\nหลักฐานที่ขาดหายไปหมายความว่าไม่มีข้อมูลที่จะสนับสนุนหรือหักล้างสมมติฐานว่าเขายังคงอาศัยอยู่ในออร์กัสตาต่อไป  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐานเนื่องจากมันไม่มีประโยชน์ในการตัดสินความจริงของสมมติฐาน\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดไม่ได้เปิดเผยข้อมูลตำแหน่งใดๆ สมมติฐานระบุว่าผู้พูดไม่เคยถามถึงสถานที่ปลายทาง ดังนั้น หลักฐานจึงไม่ขัดแย้งกับสมมติฐาน และไม่สนับสนุนหรือขัดแย้งโดยตรง  หลักฐานและสมมติฐานเป็นอิสระต่อกัน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ากลุ่มคนไม่เคยออกจากสถานที่ใด ๆ โดยไม่ได้แจ้งให้ทราบถึงที่อยู่ปัจจุบันและที่อยู่ปลายทาง  ซึ่งขัดแย้งกับสมมติฐานที่ว่าพวกเขาออกจากสถานที่ไปโดยไม่แจ้งให้ทราบ\n', '0\n', '2\n', '0\n', '0\n', 'คำตอบคือ 1', '2\n', '0\n', '0\n', '0\n', '2\n', '0\n', '1\n', '2\n', '0\n', '2\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานกล่าวถึงการฝึกฝนการติดตั้งร่มชูชีพกับอาวุธนิวเคลียร์ ซึ่งเป็นกระบวนการที่เกี่ยวข้องกับการใช้งานอาวุธนิวเคลียร์  นี่ขัดแย้งกับสมมติฐานที่ว่า "ระเบิดปรมาณูไม่มีตัวเหนี่ยวนำ"  เพราะการกระทำดังกล่าวบ่งชี้ถึงการมีอยู่ของกระบวนการและขั้นตอนการควบคุมการทำงานของอาวุธนิวเคลียร์ ซึ่งตรงข้ามกับข้อความในสมมติฐาน\n', '0\n', '2\n', '0\n', '0\n', '1\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าชุดนั้นเหมือนกับชุดของนักบินอวกาศ ยกเว้นการสะท้อนความร้อนและพลังงาน ซึ่งสนับสนุนสมมติฐาน\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานทั้งสองชิ้นนั้นไม่เกี่ยวข้องกันและดูเหมือนจะขัดแย้งกัน  ประโยคแรกอธิบายถึงความสัมพันธ์ที่ดีในขณะที่ประโยคที่สองอธิบายถึงความสัมพันธ์ที่ไม่ดี\n', '2\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่ามีการฝึกนักบินชาวจีนและอังกฤษ ซึ่งขัดแย้งกับสมมติฐานที่ว่าไม่มีการฝึกฝนกับใครเลย\n', '2\n', '1\n', '0\n', "ไม่สามารถระบุได้ว่าหลักฐานนั้นเกี่ยวข้องหรือขัดแย้งกับสมมติฐานอย่างไร เนื่องจากไม่มีการระบุทั้งสมมติฐานและหลักฐาน  ข้อความที่ให้มานั้นไม่สมบูรณ์และไม่สามารถวิเคราะห์ได้  ดังนั้น จึงไม่สามารถให้คำตอบเป็น '0', '1' หรือ '2' ได้\n", '2\n', '0\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานที่ระบุว่า "ฉันไม่เคยทบทวนหนังสือใด ๆ ที่ฉันควรจะอ่าน" สนับสนุนสมมติฐานที่ว่า "ยังไม่ได้อ่านข้อความใด ๆ ที่ยาวกว่าร้อยหน้า" เนื่องจากการทบทวนหนังสือโดยทั่วไปจะเกิดขึ้นหลังจากที่อ่านหนังสือจบแล้ว  การที่ไม่เคยทบทวนเลย แสดงให้เห็นว่ามีโอกาสสูงที่จะไม่ได้อ่านหนังสือยาวๆ  ดังนั้นจึงสนับสนุนสมมติฐาน\n', 'คำตอบคือ 1\n', '0\n', '0\n', '2\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ามีปฏิกิริยาหรือความรวดเร็ว นี่ขัดแย้งกับสมมติฐานที่ว่าอารมณ์ของเธอคงอยู่อย่างต่อเนื่องอย่างสิ้นเชิง เพราะปฏิกิริยาบ่งชี้ถึงการเปลี่ยนแปลงทางอารมณ์\n', '0\n', '2\n', '2\n', '1\n', '2\n', "คำตอบคือ 2\n\nหลักฐานอธิบายถึงกระบวนการทดสอบที่สุนัขต้องผ่านก่อนที่จะบิน (อย่างน้อยก็ด้วยเครื่องบินหรืออุปกรณ์บินอื่นๆ)  สมมติฐานกล่าวว่าส่วนใหญ่ไม่ผ่านการทดสอบและสุนัขบินได้อยู่แล้วหรือข้อที่ 2  หลักฐานไม่สนับสนุนหรือขัดแย้งโดยตรงกับสมมติฐาน  สมมติฐานแสดงถึงความเป็นไปได้สองทางที่แตกต่างกันโดยสิ้นเชิง  จึงไม่สามารถระบุได้ว่าหลักฐานนั้นสอดคล้องหรือขัดแย้งกับสมมติฐานใด  ดังนั้นจึงเป็น '2' (ความขัดแย้ง)\n", '2\n', '2\n', '2\n', 'คำตอบคือ 1\n', '1\n', '0\n', '0\n', '2\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n\nเหตุผล: ข้อความระบุว่า "ถ้ามีอะไรที่รูปร่างทำได้" ซึ่งเป็นเงื่อนไขสำหรับความเป็นไปได้ของการกระทำบางอย่าง สมมติฐานที่ว่า "ฉันสามารถทำอะไรบางอย่างได้" เป็นผลลัพธ์ที่อาจเกิดขึ้นได้จากเงื่อนไขนี้  ดังนั้นหลักฐานจึงเกี่ยวข้องกับสมมติฐาน  ไม่ได้พิสูจน์หรือหักล้างสมมติฐาน แต่บ่งชี้ถึงความเป็นไปได้  ซึ่งทำให้มันมีความเกี่ยวข้องกัน\n', '1\n', '0\n', '2\n', 'คำตอบคือ 1\n', '1\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานและสมมติฐานมีความเกี่ยวข้องกัน  หลักฐานอธิบายถึงการกระทำของผู้เขียน  ซึ่งเป็นไปตามสมมติฐานที่ว่าผู้เขียนโทรหาเบอร์นั้นหลังจากไปถึงบ้าน', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้พูดบันทึกหมายเลขโทรศัพท์และวางแผนที่จะโทรไปหาหมายเลขนั้น สมมติฐานคือมีการโทร แต่ผู้พูดไม่ได้โทร  นี่คือความขัดแย้งกัน\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานกล่าวถึงสถานที่ที่แตกต่างกัน (นิวยอร์ก) และสถานการณ์ที่ไม่ชัดเจนในขณะที่สมมติฐานพูดถึงเหตุการณ์เฉพาะที่ยิม  ไม่มีข้อมูลใดๆ ในหลักฐานที่สนับสนุนหรือขัดแย้งกับสมมติฐาน', 'คำตอบคือ 0', '2\n', '0\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นถึงความผิดหวังและความต้องการให้เลิกสมมติฐาน  ซึ่งขัดแย้งกับสมมติฐานที่อาจมีความหวังหรือการสนับสนุนต่อการดำเนินต่อไป\n', 'คำตอบคือ 0', 'คำตอบคือ 2\n\nหลักฐานบ่งชี้ถึงความล้มเหลวในบางแง่มุม ในขณะที่สมมติฐานระบุว่าไม่มีความคิดที่จะเลิก ความล้มเหลวอาจเป็นสาเหตุที่ทำให้พิจารณาเลิก ดังนั้น จึงมีความขัดแย้งกัน', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1867 และ 1889 (หรือ 1889 เป็นปีที่คิดว่าเป็นปีเกิด) ในขณะที่สมมติฐานกล่าวถึงปีที่แตกต่างกันอย่างสิ้นเชิงคือ 2562, 2005 และ 1880  ปีเหล่านี้ขัดแย้งกันอย่างมาก  ดังนั้น จึงเป็นความขัดแย้ง (2)\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1980  แต่หลังจากนั้นก็ระบุว่าบุคคลนั้นเกิดในปี 1986 และไม่ได้เกิดก่อนปี 1984 ข้อมูลเหล่านี้ขัดแย้งกันเอง\n', '2\n', '2\nหลักฐานแนะนำให้ระมัดระวังเมื่อขันสกรูเพราะอาจทำให้เสียหายได้  สมมติฐานบอกว่าสกรูไม่มีประโยชน์แล้ว  ดังนั้นจึงควรขันให้แน่นที่สุดเท่าที่ต้องการ  นี่คือความขัดแย้งกัน\n', '1\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดได้รับคำสั่งไปยังสถานที่ที่ไม่รู้จัก และพบว่าต้องไปยังฐานทัพอากาศที่ไม่รู้จักอีกแห่งหนึ่ง สมมติฐานระบุว่าผู้พูดไม่เคยไปยังสถานที่เหล่านั้นมาก่อน  หลักฐานจึงขัดแย้งกับสมมติฐาน เพราะถ้าผู้พูดไม่เคยไปสถานที่เหล่านั้นมาก่อน  เขาจะไม่รู้ว่าต้องไปที่ฐานทัพอากาศแห่งนั้นหลังจากไปถึงสถานที่แรก\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าผู้เขียนได้รับคำสั่งให้ไปที่สถานที่ซึ่งดูเหมือนจะเป็นฐานทัพ Laughlin  แม้ว่ารายละเอียดจะไม่ชัดเจนเนื่องจากมีตัวอักษรที่ไม่รู้จักอยู่ แต่ก็ดูเหมือนว่าจะสอดคล้องกับสมมติฐานที่ว่ากองทัพอากาศส่งผู้เขียนไปยังเดล ริโอในปี 2001  หลักฐานไม่ขัดแย้งกับสมมติฐาน  จึงจัดว่าเป็นการสนับสนุนหรือสอดคล้องกัน\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าเด็กๆ ดื่มแชมเปญ  ซึ่งสนับสนุนสมมติฐานที่ว่าเด็กๆ ดื่มแชมเปญบางส่วน', 'คำตอบคือ 2\n\nหลักฐานระบุว่าเด็กๆ กำลังดื่มแชมเปญ ซึ่งเป็นเครื่องดื่มแอลกอฮอล์ สมมติฐานระบุว่าไม่มีการเสิร์ฟเครื่องดื่มแอลกอฮอล์ ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '0\n', '0\n', '2\n', '0\n', '0\n', '0\n', '0\n', '0\n', '2\n', '1\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy th: 0.44221105527638194
'XNLI' object has no attribute 'evaluate_results'
