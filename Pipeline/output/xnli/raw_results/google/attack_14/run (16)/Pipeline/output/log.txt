README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 120MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  42%|####1     | 21.0M/50.2M [00:00<00:00, 133MB/s]train-00000-of-00001.parquet:  84%|########3 | 41.9M/50.2M [00:00<00:00, 148MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 157MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 124MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 284MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  33%|###2      | 128000/392702 [00:00<00:00, 1263713.32 examples/s]Generating train split:  66%|######6   | 260000/392702 [00:00<00:00, 1290558.30 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1300557.27 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1187402.56 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1047209.16 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 376kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 5.12MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 20.5MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 23.6MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/440M [00:00<00:05, 73.6MB/s]model.safetensors:  10%|9         | 41.9M/440M [00:00<00:02, 161MB/s] model.safetensors:  14%|#4        | 62.9M/440M [00:00<00:02, 167MB/s]model.safetensors:  21%|##1       | 94.4M/440M [00:00<00:01, 187MB/s]model.safetensors:  29%|##8       | 126M/440M [00:00<00:01, 200MB/s] model.safetensors:  36%|###5      | 157M/440M [00:00<00:01, 206MB/s]model.safetensors:  43%|####2     | 189M/440M [00:00<00:01, 211MB/s]model.safetensors:  50%|####9     | 220M/440M [00:01<00:01, 214MB/s]model.safetensors:  57%|#####7    | 252M/440M [00:01<00:00, 216MB/s]model.safetensors:  64%|######4   | 283M/440M [00:01<00:00, 218MB/s]model.safetensors:  71%|#######1  | 315M/440M [00:01<00:00, 219MB/s]model.safetensors:  79%|#######8  | 346M/440M [00:01<00:00, 220MB/s]model.safetensors:  86%|########5 | 377M/440M [00:01<00:00, 221MB/s]model.safetensors:  93%|#########2| 409M/440M [00:01<00:00, 222MB/s]model.safetensors: 100%|#########9| 440M/440M [00:02<00:00, 222MB/s]model.safetensors: 100%|##########| 440M/440M [00:02<00:00, 208MB/s]
Attack entry stored in: output/attacks/attack.txt
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', None, '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '0\n', '0\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', None, '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 20
Accuracy en: 0.4722222222222222
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  14%|#4        | 10.5M/73.8M [00:00<00:00, 73.3MB/s]train-00000-of-00001.parquet:  57%|#####6    | 41.9M/73.8M [00:00<00:00, 158MB/s] train-00000-of-00001.parquet:  99%|#########9| 73.4M/73.8M [00:00<00:00, 182MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 165MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 98.9MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 228MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  23%|##3       | 91000/392702 [00:00<00:00, 902971.80 examples/s]Generating train split:  47%|####6     | 184000/392702 [00:00<00:00, 911322.89 examples/s]Generating train split:  71%|#######   | 277000/392702 [00:00<00:00, 916585.82 examples/s]Generating train split:  95%|#########4| 372000/392702 [00:00<00:00, 926856.48 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 920413.16 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 955157.41 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 819187.15 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 14.6kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 3.16MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 19.5MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 928kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   5%|4         | 21.0M/454M [00:00<00:02, 174MB/s]pytorch_model.bin:   9%|9         | 41.9M/454M [00:00<00:02, 172MB/s]pytorch_model.bin:  16%|#6        | 73.4M/454M [00:00<00:01, 192MB/s]pytorch_model.bin:  21%|##        | 94.4M/454M [00:00<00:01, 198MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:01, 204MB/s] pytorch_model.bin:  32%|###2      | 147M/454M [00:00<00:01, 206MB/s]pytorch_model.bin:  37%|###6      | 168M/454M [00:00<00:01, 206MB/s]pytorch_model.bin:  42%|####1     | 189M/454M [00:00<00:01, 207MB/s]pytorch_model.bin:  46%|####6     | 210M/454M [00:01<00:01, 207MB/s]pytorch_model.bin:  53%|#####3    | 241M/454M [00:01<00:01, 210MB/s]pytorch_model.bin:  60%|######    | 273M/454M [00:01<00:00, 209MB/s]pytorch_model.bin:  65%|######4   | 294M/454M [00:01<00:00, 209MB/s]pytorch_model.bin:  72%|#######1  | 325M/454M [00:01<00:00, 211MB/s]pytorch_model.bin:  78%|#######8  | 357M/454M [00:01<00:00, 211MB/s]pytorch_model.bin:  85%|########5 | 388M/454M [00:01<00:00, 211MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:02<00:00, 211MB/s]pytorch_model.bin:  99%|#########9| 451M/454M [00:02<00:00, 212MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:02<00:00, 207MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', 'Η απάντηση είναι **1**.\n\nΗ υπόθεση δηλώνει την επιθυμία να κατανοήσει τα σύνολα.  Η περιγραφή δηλώνει αβεβαιότητα και απουσία γνώσης σχετικά με τα σύνολα.  Δεν υπάρχει αντίφαση, ούτε και άμεση συνέπεια μεταξύ τους.  Η περιγραφή απλά περιγράφει μια κατάσταση έλλειψης γνώσης, ενώ η υπόθεση εκφράζει μια επιθυμία για μάθηση.\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, 'Η απάντηση είναι **1**.\n\nΔεν υπάρχει καμία αντίφαση ή συνέντευξη μεταξύ των δύο προτάσεων.  Η πρώτη πρόταση περιγράφει επαναλαμβανόμενη ενέργεια, ενώ η δεύτερη πρόταση περιγράφει μια εντολή. Δεν υπάρχει σχέση αιτιότητας ή αντίθεσης μεταξύ τους.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy el: 0.4824120603015075
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  48%|####8     | 31.5M/65.4M [00:00<00:00, 300MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 322MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 87.1MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 420MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##4       | 96000/392702 [00:00<00:00, 948839.17 examples/s]Generating train split:  50%|#####     | 198000/392702 [00:00<00:00, 983830.70 examples/s]Generating train split:  77%|#######6  | 302000/392702 [00:00<00:00, 1001757.81 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 997955.49 examples/s] 
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 978280.40 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 886120.56 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 566kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 8.80MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 12.8MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 24.5MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   2%|1         | 10.5M/672M [00:00<00:09, 71.2MB/s]model.safetensors:   5%|4         | 31.5M/672M [00:00<00:04, 138MB/s] model.safetensors:   8%|7         | 52.4M/672M [00:00<00:03, 165MB/s]model.safetensors:  12%|#2        | 83.9M/672M [00:00<00:03, 186MB/s]model.safetensors:  17%|#7        | 115M/672M [00:00<00:02, 195MB/s] model.safetensors:  22%|##1       | 147M/672M [00:00<00:02, 201MB/s]model.safetensors:  25%|##4       | 168M/672M [00:00<00:02, 196MB/s]model.safetensors:  28%|##8       | 189M/672M [00:01<00:02, 198MB/s]model.safetensors:  31%|###1      | 210M/672M [00:01<00:02, 199MB/s]model.safetensors:  36%|###5      | 241M/672M [00:01<00:02, 204MB/s]model.safetensors:  39%|###8      | 262M/672M [00:01<00:02, 204MB/s]model.safetensors:  42%|####2     | 283M/672M [00:01<00:01, 205MB/s]model.safetensors:  45%|####5     | 304M/672M [00:01<00:01, 206MB/s]model.safetensors:  50%|####9     | 336M/672M [00:01<00:01, 209MB/s]model.safetensors:  53%|#####3    | 357M/672M [00:01<00:01, 194MB/s]model.safetensors:  58%|#####7    | 388M/672M [00:01<00:01, 201MB/s]model.safetensors:  62%|######2   | 419M/672M [00:02<00:01, 204MB/s]model.safetensors:  67%|######7   | 451M/672M [00:02<00:01, 208MB/s]model.safetensors:  70%|#######   | 472M/672M [00:02<00:00, 208MB/s]model.safetensors:  75%|#######4  | 503M/672M [00:02<00:00, 210MB/s]model.safetensors:  80%|#######9  | 535M/672M [00:02<00:00, 210MB/s]model.safetensors:  84%|########4 | 566M/672M [00:02<00:00, 211MB/s]model.safetensors:  89%|########8 | 598M/672M [00:02<00:00, 210MB/s]model.safetensors:  94%|#########3| 629M/672M [00:03<00:00, 208MB/s]model.safetensors:  97%|#########6| 650M/672M [00:03<00:00, 208MB/s]model.safetensors: 100%|##########| 672M/672M [00:03<00:00, 208MB/s]model.safetensors: 100%|##########| 672M/672M [00:03<00:00, 201MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', None, '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', None, '0\n', '1\n', None, None, '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', None, '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', None, '1\n', '0\n', '2\n', '0\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', None, '1\n', '2\n', '0\n', '2\n', '2\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n']
Saved predictions to: predicted_2.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 20
Accuracy bg: 0.46111111111111114
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  59%|#####9    | 31.5M/53.2M [00:00<00:00, 311MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 314MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 294MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 304MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###2      | 126000/392702 [00:00<00:00, 1251245.50 examples/s]Generating train split:  65%|######4   | 255000/392702 [00:00<00:00, 1271018.06 examples/s]Generating train split:  98%|#########8| 385000/392702 [00:00<00:00, 1276718.13 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1270277.42 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1193404.31 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1058351.94 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.94MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 5.85MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 36.4MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 115MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.28MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   7%|7         | 31.5M/440M [00:00<00:01, 313MB/s]pytorch_model.bin:  17%|#6        | 73.4M/440M [00:00<00:01, 340MB/s]pytorch_model.bin:  26%|##6       | 115M/440M [00:00<00:00, 347MB/s] pytorch_model.bin:  36%|###5      | 157M/440M [00:00<00:00, 334MB/s]pytorch_model.bin:  45%|####5     | 199M/440M [00:00<00:00, 314MB/s]pytorch_model.bin:  55%|#####4    | 241M/440M [00:00<00:00, 326MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:00<00:00, 330MB/s]pytorch_model.bin:  74%|#######3  | 325M/440M [00:00<00:00, 336MB/s]pytorch_model.bin:  83%|########3 | 367M/440M [00:01<00:00, 340MB/s]pytorch_model.bin:  93%|#########3| 409M/440M [00:01<00:00, 343MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 334MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa establece que el hablante era uno de los cuatro ex combatientes en el campo de carrera de la fuerza aérea AFFC, y cree que todavía es un privilegio.  Luego, dice que no cree ser la tercera persona en el campo en ese día.  Esto no implica ni contradice la afirmación inicial sobre ser uno de cuatro ex combatientes.  Podría haber habido más de cuatro ex combatientes en el campo en días diferentes.  Simplemente hay información incompleta para hacer una comparación.\n', '1\n', 'La respuesta es 2.\n\nLa premisa establece que el narrador era el único con un número específico de identificación (922 ex-o) en su nivel de carrera, lo que indica privilegio.  La hipótesis afirma que, a pesar de las promesas de privilegios, el hecho de que todos recibieron el mismo número anula cualquier privilegio.  Esto contradice directamente la experiencia del narrador, quien afirmaba tener privilegio debido a su número único.\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa establece que Fannie Flono iba a contar historias, pero tuvo que reprogramar y no pudo hacerlo.  Esto no implica ni contradice ninguna hipótesis específica.  No hay una hipótesis presente para comparar.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '0\n', '0\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '2\n', '1\n', '0\n', '2\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '2\n', 'La respuesta es 0.\n\nLa premisa indica que Lil odiaba que su hermana recibiera críticas constantes.  La hipótesis sugiere que Lil odiaba que su hermana aparentemente no hiciera nada bien. La premisa apoya la hipótesis; el constante reproche implica una percepción de que la hermana hacía las cosas mal.\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n']
Saved predictions to: predicted_3.json
Accuracy es: 0.465
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  19%|#8        | 10.5M/55.4M [00:00<00:01, 44.7MB/s]train-00000-of-00001.parquet:  57%|#####6    | 31.5M/55.4M [00:00<00:00, 92.0MB/s]train-00000-of-00001.parquet:  95%|#########4| 52.4M/55.4M [00:00<00:00, 114MB/s] train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 102MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 230MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 146MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###1      | 123000/392702 [00:00<00:00, 1216652.03 examples/s]Generating train split:  78%|#######7  | 306000/392702 [00:00<00:00, 1210989.18 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1210065.10 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1089006.17 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1003634.15 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 161kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.08MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 958kB/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 957kB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 17.3MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   5%|4         | 21.0M/445M [00:00<00:02, 146MB/s]model.safetensors:   9%|9         | 41.9M/445M [00:00<00:02, 145MB/s]model.safetensors:  14%|#4        | 62.9M/445M [00:00<00:02, 143MB/s]model.safetensors:  19%|#8        | 83.9M/445M [00:00<00:02, 142MB/s]model.safetensors:  24%|##3       | 105M/445M [00:00<00:02, 141MB/s] model.safetensors:  28%|##8       | 126M/445M [00:00<00:02, 141MB/s]model.safetensors:  33%|###2      | 147M/445M [00:01<00:02, 142MB/s]model.safetensors:  38%|###7      | 168M/445M [00:01<00:01, 143MB/s]model.safetensors:  42%|####2     | 189M/445M [00:01<00:01, 144MB/s]model.safetensors:  47%|####7     | 210M/445M [00:01<00:01, 145MB/s]model.safetensors:  52%|#####1    | 231M/445M [00:01<00:01, 146MB/s]model.safetensors:  57%|#####6    | 252M/445M [00:01<00:01, 146MB/s]model.safetensors:  61%|######1   | 273M/445M [00:01<00:01, 146MB/s]model.safetensors:  66%|######5   | 294M/445M [00:02<00:01, 146MB/s]model.safetensors:  71%|#######   | 315M/445M [00:02<00:00, 146MB/s]model.safetensors:  75%|#######5  | 336M/445M [00:02<00:00, 145MB/s]model.safetensors:  80%|########  | 357M/445M [00:02<00:00, 146MB/s]model.safetensors:  85%|########4 | 377M/445M [00:02<00:00, 146MB/s]model.safetensors:  90%|########9 | 398M/445M [00:02<00:00, 147MB/s]model.safetensors:  94%|#########4| 419M/445M [00:02<00:00, 146MB/s]model.safetensors:  99%|#########8| 440M/445M [00:03<00:00, 146MB/s]model.safetensors: 100%|##########| 445M/445M [00:03<00:00, 145MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.455
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  41%|####1     | 31.5M/76.5M [00:00<00:00, 275MB/s]train-00000-of-00001.parquet:  96%|#########5| 73.4M/76.5M [00:00<00:00, 333MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 321MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 176MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 324MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  22%|##2       | 87000/392702 [00:00<00:00, 853128.64 examples/s]Generating train split:  45%|####4     | 175000/392702 [00:00<00:00, 864647.50 examples/s]Generating train split:  67%|######7   | 265000/392702 [00:00<00:00, 873542.97 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 871982.40 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 869625.50 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 940915.37 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 838591.37 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 1.70MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 4.13MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 20.7MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:  10%|9         | 41.9M/423M [00:00<00:01, 325MB/s]model.safetensors:  20%|#9        | 83.9M/423M [00:00<00:01, 303MB/s]model.safetensors:  27%|##7       | 115M/423M [00:00<00:01, 306MB/s] model.safetensors:  37%|###7      | 157M/423M [00:00<00:00, 310MB/s]model.safetensors:  47%|####7     | 199M/423M [00:00<00:00, 268MB/s]model.safetensors:  54%|#####4    | 231M/423M [00:00<00:00, 275MB/s]model.safetensors:  64%|######4   | 273M/423M [00:00<00:00, 300MB/s]model.safetensors:  74%|#######4  | 315M/423M [00:01<00:00, 317MB/s]model.safetensors:  84%|########4 | 357M/423M [00:01<00:00, 335MB/s]model.safetensors:  94%|#########4| 398M/423M [00:01<00:00, 340MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 316MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '2\n', '2\n', 'คำตอบคือ 0 (ไม่เกี่ยวข้อง)\n\nหลักฐานบอกเล่าเรื่องราวส่วนตัวของผู้พูด แต่ไม่ได้ให้ข้อมูลใดๆ เกี่ยวกับว่ามีคนอื่นอยู่ที่ไร่ในวันนั้นหรือไม่  ดังนั้นจึงไม่สนับสนุนหรือขัดแย้งกับสมมติฐาน\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีคนจะมาพบผู้พูดในภายหลัง หลักฐานนี้สนับสนุนสมมติฐานที่ว่ามีคนจะมาที่นี่เพื่อพบผู้พูด  แม้ว่าหลักฐานจะไม่ระบุรายละเอียดทั้งหมด แต่ก็ไม่ได้ขัดแย้งกับสมมติฐาน\n', '0\n', 'คำตอบคือ 2\n', 'คำตอบคือ 1\nหลักฐานระบุว่ามีข้อมูลมากมายที่จะต้องพูดคุยเกี่ยวกับเรื่องนี้ แต่เลือกที่จะข้ามไป สมมติฐานนั้นกล่าวถึงเรื่องนั้น ถึงแม้ว่าจะมีหลายสิ่งหลายอย่างที่ต้องบอก ทั้งสองประโยคมีข้อมูลที่สัมพันธ์กัน', '0\n', '2\n', '2\n', 'คำตอบคือ **1**\n\nหลักฐานแสดงให้เห็นถึงเหตุผลที่สนับสนุนการเก็บรักษาสิ่งของ (ระเบิดไฮโดรเจน)  ทั้งเหตุผลด้านความสามารถ (ไม่มีฝีมือที่จะกำจัด) และด้านความเสี่ยง (จัดการยาก)  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐานที่ว่าจะเก็บสิ่งของนั้นไว้\n', 'คำตอบคือ 2\n', 'คำตอบคือ 0\n\nหลักฐาน ("ฉันก็เลยไม่แน่ใจว่าทำไม") ไม่สนับสนุนหรือขัดแย้งกับสมมติฐาน ("ฉันไม่รู้สาเหตุที่ย้ายโรงเรียนทำไม")  ทั้งสองประโยคแสดงถึงความไม่รู้สาเหตุเดียวกัน\n', '0\n', '2\nหลักฐานกล่าวถึง Annie Lono ที่เติบโตในร้านค้า  ส่วนสมมติฐานกล่าวถึงการจัดตารางบริษัทใหม่และทีมที่ไม่สามารถพูดคุยได้  ไม่มีความเกี่ยวข้องกันเลย\n', '1\n', '0\n', '2\n', '2\n', '0\n', 'คำตอบคือ 2\nหลักฐานระบุว่าผู้พูดเป็นคนเดียวที่ใช้หน่วยควบคุมการทดสอบในหอสูง  สมมติฐานแสดงความปรารถนาที่ไม่ต้องการเป็นคนเดียว  นี่คือความขัดแย้งกัน', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดเป็นเพียงผู้ดูแลระบบควบคุมสำหรับหอพักในหอสูงขนาดเล็ก  สมมติฐานระบุว่า "พวกเราไม่กี่คนไม่ได้ดำเนินนโยบายกับการควบคุมนี้"  หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานโดยตรง  มันเป็นข้อมูลที่เป็นกลาง  ดังนั้นจึงเป็นความขัดแย้ง (2)\n', '2\n', '2\n', '1\n', '2\nหลักฐานกล่าวถึงกระแสเงินสดบนโต๊ะ และรายได้ของลูกค้าคัตตี้ ซึ่งไม่เกี่ยวข้องกับสมมติฐานที่ระบุรายได้ของคัตตี้โดยตรง  จึงถือว่าขัดแย้งกัน\n', '0\n', 'คำตอบคือ 1\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้หญิงที่ช่วยเหลือผู้พูดนั้นมีอยู่ทั่วไป ในขณะที่สมมติฐานระบุว่ามีผู้หญิงจำนวนน้อยมากที่ช่วยเหลือเขา  นี่คือความขัดแย้งกัน\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ **0**\n\nหลักฐานสนับสนุนสมมติฐาน นักวิจัยไม่สามารถระบุได้ว่าใครควรทำงานในไร่ฝ้ายและใครควรทำความสะอาดบ้าน เนื่องจากมีการปลอมตัวว่าใครเป็นคนรับจ้างทำงานในไร่และใครเป็นคนรับใช้ในบ้าน  หลักฐานจึงสอดคล้องกับความไม่แน่นอนที่ระบุไว้ในสมมติฐาน\n', '0\n', '2\n', '2\n', '2\n', '0\n', '1\n', '0\n', '2\n', '2\n', '0\n', '2\n', '2\n', '2\n', '1\n', '2\nหลักฐานอธิบายถึงความเป็นไปได้ที่รังสีจะรั่วออกมาจากเครื่องบินเนื่องจากความร้อน ซึ่งขัดแย้งกับสมมติฐานที่ว่ารังสีจะไม่เกิดขึ้นในระหว่างการยิง\n', '0\n', '0\n', '0\n', '2\nหลักฐานระบุว่ามีเครื่องบินเพียงไม่กี่ลำบินไปยังดวงอาทิตย์ต่อสัปดาห์ ในขณะที่สมมติฐานคาดการณ์ว่าจะมีเครื่องบินลงจอดมากกว่า 4-5 ลำต่อสัปดาห์ นี่เป็นความขัดแย้งกัน\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงจำนวนเที่ยวบินที่สูงซึ่งเกี่ยวข้องกับสมมติฐานว่าการเพิ่มขึ้นของเครื่องบินทางอากาศทำให้เกิดปัญหา  หลักฐานไม่ได้ขัดแย้งกับสมมติฐาน แต่เป็นการสนับสนุนสมมติฐานโดยการให้ข้อมูลที่เกี่ยวข้องกับจำนวนเที่ยวบิน\n', '2\n', "คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐานระบุว่าการใช้กล้ามเนื้อในชุดสูทความดันอากาศนั้นใช้เวลา 'สักพัก' ในการเรียนรู้  สมมติฐานระบุว่าการฝึกอบรมใช้เวลาเพียงสามเดือน  ทั้งสองข้อความขัดแย้งกันเนื่องจากระยะเวลาที่ใช้ในการฝึกฝนนั้นแตกต่างกันอย่างมีนัยสำคัญ\n", '0\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าระเบิดจะไม่ระเบิดไม่ว่าจะโดนแรงกระแทกแค่ไหน  ซึ่งสนับสนุนสมมติฐานที่ว่าระเบิดถูกยกเลิกการใช้งานแล้ว  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', '0\n', '2\nหลักฐานระบุว่าระเบิดจะไม่ระเบิดไม่ว่าจะตกกระแทกแรงแค่ไหน ขัดแย้งกับสมมติฐานที่ระบุว่าระเบิดมีความสามารถสูงในการระเบิด\n', '0\n', '2\n', '0\n', 'คำตอบคือ 1\n', '0\n', '2\n', '2\n', '2\n', '1\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานและสมมติฐานนั้นสัมพันธ์กัน  หลักฐานแสดงให้เห็นถึงความตั้งใจที่จะทำการคำนวณจากผลรวม ซึ่งสอดคล้องกับสมมติฐานที่บอกว่าการคำนวณจะเกิดขึ้นจากยอดรวม\n', '2\n', '0\n', '0\n', '2\n', '2\nหลักฐานระบุว่า "ฉันไม่มีเรื่องใดเรื่องเลย" ซึ่งขัดแย้งกับสมมติฐานที่ว่า "ฉันมีร้านค้าเฉพาะอยู่ 1 แห่ง"  การมีร้านค้าหมายถึงมีเรื่องต้องรับผิดชอบ  ดังนั้นคำตอบคือ 2\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', '1\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานที่ว่า "จิตเป็นความสว่าง" บ่งบอกถึงคุณลักษณะที่ไม่ใช่ของมนุษย์  โดยสมมติฐานว่า "เธอไม่ได้เป็นมนุษย์เลย"  หลักฐานนี้สนับสนุนสมมติฐานนี้\n', '0\n', '2\n', 'คำตอบคือ 0\n', '0\n', '0\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่ามีการจ่ายเงินเพื่อที่อยู่อาศัยสำหรับครอบครัว  สมมติฐานระบุว่ามีการจ่ายค่าเช่าประจำปีสำหรับผู้พูดและญาติของเขา ซึ่งเป็นส่วนหนึ่งของการจ่ายเงินเพื่อที่อยู่อาศัยสำหรับครอบครัว  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', 'คำตอบคือ 1\nหลักฐานแสดงให้เห็นว่ามีการจ่ายเงินเพื่อให้ได้ที่อยู่อาศัย  ซึ่งสอดคล้องกับสมมติฐานว่ามีการจ่ายเงินเพื่อทำบางสิ่งบางอย่าง\n', '2\n', '2\n', '0\n', '0\n', '0\n', 'คำตอบคือ 2.\n\nหลักฐานระบุว่าไม่ว่าจะอย่างไรก็ตาม ผู้ชายคนนั้นเป็นแพทย์  สมมติฐานระบุว่าผู้ชายพิจารณาทางเลือกอื่นๆ  สองข้อความนี้ไม่เกี่ยวข้องกัน  ดังนั้น จึงเป็นความขัดแย้ง\n', 'คำตอบคือ 0\n\n\nหลักฐานระบุว่าผู้พูดมีญาติจำนวนมากที่อาศัยอยู่ไกลออกไป  นี้สอดคล้องกับสมมติฐานที่ว่ามีครอบครัวใหญ่แต่ไม่ได้ให้การสนับสนุนโดยตรงหรือขัดแย้งกับสมมติฐานใดๆโดยเฉพาะ', 'คำตอบคือ 0', 'คำตอบคือ 2\n\nหลักฐานกล่าวว่าบรรพบุรุษของผู้พูดนั้นโรแมนติกและมีบรรยากาศที่ดีในบ้านของพวกเขา สมมติฐานระบุว่าพวกเขาบ้าและครอบครัวไม่เคยพูดคุยกับพวกเขาในบ้านของพวกเขา สิ่งเหล่านี้มีความขัดแย้งกันอย่างมาก', '2\n', '2\n', '0\n', '2\n', '2\n', '1\n', '0\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าชุดนั้นทำจากเงินทั้งหมดและสะท้อนความร้อนได้ดี  แต่ก็ระบุด้วยว่าชุดนั้นไม่มีอุปกรณ์เหมือนที่นักบินอวกาศใช้  นี่เป็นความขัดแย้งกับสมมติฐานเริ่มต้นที่เปรียบเทียบชุดกับชุดนักบินอวกาศ  จึงตอบ 2\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐาน  ชุดปรับพิเศษมีลักษณะเหมือนกับชุดนักบินอวกาศ ยกเว้นวัสดุและสี  ซึ่งเป็นไปตามสมมติฐานที่ระบุไว้\n', '2\n', '2\n', '2\n', '2\n', '1\n', '1\n', 'ฉันไม่สามารถระบุได้ว่าหลักฐานที่ให้มานั้นสนับสนุน สมมติฐานหรือขัดแย้งกับสมมติฐาน เนื่องจากไม่มีการระบุสมมติฐาน  ฉันต้องการข้อมูลเพิ่มเติมเพื่อตอบคำถามของคุณได้  โปรดให้สมมติฐานด้วย\n', '2\n', '2\n', '0\n', '0\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐาน ("ฉันไม่ได้อ่านหนังสือใด ๆ ที่คุณอ่าน") ขัดแย้งกับสมมติฐาน ("ค่อนข้างได้อ่านหนังสือที่ยาวกว่าร้อยหน้า")  เพราะหลักฐานบอกเป็นนัยว่าคนพูดไม่ได้อ่านหนังสือใดๆ เลย  ขณะที่สมมติฐานบอกว่าคนๆ นั้นได้อ่านหนังสือยาวเล่มหนึ่ง\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐาน ("ฉันไม่ได้อ่าน ฉันขอโทษมากมาย") ขัดแย้งกับสมมติฐาน ("ฉันไม่ได้อ่านหนังสือใด ๆ")  เพราะมันยืนยันว่าคนนั้นไม่ได้อ่านหนังสือใด ๆ เลย  ซึ่งเป็นการยืนยันสมมติฐาน ไม่ใช่การขัดแย้ง\n', '2\n', '2\n', '2\n', '0\n', '2\n', '0\n', '1\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าผู้เขียนได้รับเลือกจากผู้สมัครมากกว่า 15 คน  นี่ขัดแย้งกับสมมติฐานที่ว่าพวกเขาไม่ได้รับเลือกเข้าเรียนในเขตนั้น\n', 'คำตอบคือ 0\n\nหลักฐานที่ให้มานั้นไม่สนับสนุนหรือขัดแย้งกับสมมติฐาน  มันแค่บอกเล่าเหตุการณ์ที่เกิดขึ้นโดยไม่เกี่ยวข้องกับการถูกเลือกเข้าโรงเรียน  หลักฐานไม่เกี่ยวข้องกับสมมติฐาน\n', 'คำตอบคือ 1\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานแสดงให้เห็นว่าจำเป็นต้องมีขั้นตอนการขึ้นเครื่องบิน (ไปห้องชั้น 7, ใส่ชุดอวกาศ)  สิ่งนี้สนับสนุนสมมติฐานที่ว่าจำเป็นต้องมีการฝึกอบรมจำนวนมากก่อนที่จะบินได้  การเข้าถึงกระบวนการที่ซับซ้อนเช่นนี้บ่งชี้ถึงการฝึกฝนล่วงหน้า\n', '2\n', '2\n', '2\n', '2\n', '0\n', '1\n', '0\n', '2\n', '2\n', '2\n', '2\n', "คำตอบคือ 2\n\nหลักฐานระบุว่าน้องสาวเกลียดพี่ชายและต่อสู้กับเขาเป็นประจำ ซึ่งแสดงให้เห็นถึงความสัมพันธ์ที่ไม่ลงรอยกัน สมมติฐานระบุว่าน้องสาวไม่สามารถทำทุกอย่างได้  ทั้งสองข้อความไม่ได้เกี่ยวข้องกันโดยตรง และไม่ขัดแย้งกันโดยตรง  ดังนั้นจึงไม่มีความสัมพันธ์ที่ชัดเจนระหว่างกัน  แต่เนื่องจากไม่มีความเกี่ยวข้องกัน  จึงเลือก '2' แทน '0'\n", '0\n', '0\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความไม่แน่นอนและความทรงจำที่ไม่ชัดเจนของผู้พูดเกี่ยวกับการอยู่ที่สถานที่นั้นในตอนเช้า และไม่เจอคนคนนั้น  สมมติฐานระบุว่าผู้พูดไม่ได้ไปที่นั่นและจึงไม่เจอคนนั้น  แม้ว่าหลักฐานจะไม่ชัดเจน แต่ก็สอดคล้องกับสมมติฐานได้  ความไม่แน่นอนในหลักฐานไม่ได้ทำให้มันขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 1', '2\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าสามีไม่รู้ว่าพวกเขากำลังไปที่ไหน  สมมติฐานระบุว่าทุกคนรู้ว่าพวกเขากำลังไปที่ไหน  นี่คือความขัดแย้งกัน', '0\n', '0\n', '2\n', 'คำตอบคือ 2\n\nประโยค "ฉันเกือบจะพลาดแล้วในตอนท้าย" บ่งบอกว่ามีบางสิ่งที่เกือบจะไม่เกิดขึ้น นั่นคือความขัดแย้งกับสมมติฐานเดิม', 'การตอบสนองนั้นแสดงให้เห็นถึงความเศร้าโศกและความเหนื่อยล้าจากความสัมพันธ์ ดังนั้นจึงสนับสนุนสมมติฐานที่ว่าบุคคลนั้นกำลังจะเลิกกับความสัมพันธ์ คำตอบคือ **0**\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 2006 ซึ่งขัดแย้งกับสมมติฐานที่ว่าเขาเกิดก่อนปี ค.ศ. 1900\n', 'คำตอบคือ 2\n\nหลักฐานที่ว่าเขาเกิดในปี 1880 หรือ 1889 ขัดแย้งกับสมมติฐานที่ว่าเขาเกิดในเดือนธันวาคม ปี 1897\n', '2\n', '1\n', '2\n', 'คำตอบคือ 1\n\nทั้งสองประโยคแสดงความกังวลว่าการขันสกรูอาจทำให้เกิดความเสียหายต่อปอด  ประโยคแรกแสดงให้เห็นว่าการขันสกรูแน่นเกินไปอาจทำให้เกิดความเสียหายได้ในขณะที่ประโยคที่สองอธิบายกลไกที่เป็นไปได้  ดังนั้นทั้งสองประโยคจึงสนับสนุนแนวคิดเดียวกัน\n', '1\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานกล่าวถึงว่ามีคนดื่มแชมเปญและมีคนไม่ดื่ม  แต่ไม่ระบุจำนวน  สมมติฐานระบุจำนวนขวดที่เฉพาะเจาะจง  ดังนั้นหลักฐานและสมมติฐานจึงไม่เกี่ยวข้องกัน  จึงตอบ 0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าเด็กบางคนไม่ได้ดื่มแชมเปญ ในขณะที่สมมติฐานระบุว่าเด็กบางคนดื่มแชมเปญ  นี่คือข้อมูลที่ขัดแย้งกัน\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความล้มเหลวในการควบคุมการบริโภคแอลกอฮอล์ (เด็กๆ ดื่มแชมเปญ) ซึ่งสนับสนุนส่วนหนึ่งของสมมติฐาน (การควบคุมเครื่องดื่มแอลกอฮอล์ไม่ดี)  แม้ว่าหลักฐานจะไม่ได้พูดถึงความสนุกของงานเลี้ยงโดยตรง แต่ความจริงที่ว่ามีการดื่มแชมเปญอย่างไม่ระมัดระวังก็อาจบ่งบอกถึงการขาดความสนุกหรือการจัดการงานเลี้ยงที่ไม่ดีได้เช่นกัน  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐานโดยรวม\n', '2\n', '2\n', '0\n', '2\n', '2\n', '0\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานแสดงให้เห็นว่าบุคคลหนึ่งเข้าใจประเด็นในขณะที่อีกคนไม่เข้าใจ  ซึ่งขัดแย้งกัน\n', '0\n', '0\n', '2\n', '2\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy th: 0.4723618090452261
'XNLI' object has no attribute 'evaluate_results'
