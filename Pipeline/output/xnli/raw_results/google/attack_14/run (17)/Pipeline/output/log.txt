README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 112MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  63%|######2   | 31.5M/50.2M [00:00<00:00, 251MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 265MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 74.3MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 330MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###       | 120000/392702 [00:00<00:00, 1184658.74 examples/s]Generating train split:  64%|######4   | 253000/392702 [00:00<00:00, 1264525.13 examples/s]Generating train split:  98%|#########8| 385000/392702 [00:00<00:00, 1286124.98 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1270276.44 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1232244.36 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1081364.36 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 388kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 5.30MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 58.0MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 40.8MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:01, 285MB/s]model.safetensors:  14%|#4        | 62.9M/440M [00:00<00:01, 296MB/s]model.safetensors:  24%|##3       | 105M/440M [00:00<00:01, 308MB/s] model.safetensors:  31%|###       | 136M/440M [00:00<00:01, 284MB/s]model.safetensors:  38%|###8      | 168M/440M [00:00<00:00, 294MB/s]model.safetensors:  48%|####7     | 210M/440M [00:00<00:00, 302MB/s]model.safetensors:  57%|#####7    | 252M/440M [00:00<00:00, 304MB/s]model.safetensors:  64%|######4   | 283M/440M [00:00<00:00, 294MB/s]model.safetensors:  74%|#######3  | 325M/440M [00:01<00:00, 306MB/s]model.safetensors:  81%|########  | 357M/440M [00:01<00:00, 302MB/s]model.safetensors:  88%|########8 | 388M/440M [00:01<00:00, 278MB/s]model.safetensors:  95%|#########5| 419M/440M [00:01<00:00, 285MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 292MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', None, '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 15
Accuracy en: 0.4540540540540541
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  14%|#4        | 10.5M/73.8M [00:00<00:00, 80.8MB/s]train-00000-of-00001.parquet:  43%|####2     | 31.5M/73.8M [00:00<00:00, 131MB/s] train-00000-of-00001.parquet:  71%|#######1  | 52.4M/73.8M [00:00<00:00, 148MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 161MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 63.4MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 271MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##4       | 95000/392702 [00:00<00:00, 941509.07 examples/s]Generating train split:  49%|####8     | 191000/392702 [00:00<00:00, 944217.98 examples/s]Generating train split:  74%|#######3  | 289000/392702 [00:00<00:00, 954355.05 examples/s]Generating train split:  99%|#########8| 387000/392702 [00:00<00:00, 957949.23 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 951617.30 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 916737.76 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 860565.01 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 14.7kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 3.63MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 48.6MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 1.06MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   7%|6         | 31.5M/454M [00:00<00:01, 223MB/s]pytorch_model.bin:  14%|#3        | 62.9M/454M [00:00<00:01, 262MB/s]pytorch_model.bin:  21%|##        | 94.4M/454M [00:00<00:01, 245MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:01, 247MB/s] pytorch_model.bin:  35%|###4      | 157M/454M [00:00<00:01, 254MB/s]pytorch_model.bin:  42%|####1     | 189M/454M [00:00<00:01, 243MB/s]pytorch_model.bin:  48%|####8     | 220M/454M [00:00<00:00, 251MB/s]pytorch_model.bin:  55%|#####5    | 252M/454M [00:01<00:00, 241MB/s]pytorch_model.bin:  62%|######2   | 283M/454M [00:01<00:00, 246MB/s]pytorch_model.bin:  69%|######9   | 315M/454M [00:01<00:00, 245MB/s]pytorch_model.bin:  76%|#######6  | 346M/454M [00:01<00:00, 244MB/s]pytorch_model.bin:  83%|########3 | 377M/454M [00:01<00:00, 236MB/s]pytorch_model.bin:  90%|######### | 409M/454M [00:01<00:00, 245MB/s]pytorch_model.bin:  97%|#########6| 440M/454M [00:01<00:00, 231MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 238MB/s]
Attack entry stored in: output/attacks/attack.txt
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
[None, None, '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', 'Η απάντηση είναι 0.\n\nΗ προϋπόθεση δηλώνει ότι η διάσωση ενός αντικειμένου ήταν η μοναδική προτεραιότητα, ακόμη και αν υπήρχε αδυναμία διάσωσης μιας μεγάλης ποσότητας υδρογόνου.  Αυτό υποδηλώνει αδιαφορία για άλλες δράσεις, υποστηρίζοντας το συμπέρασμα ότι δεν τους ενδιέφερε τι άλλο θα γινόταν. Η προϋπόθεση υποστηρίζει το συμπέρασμα.\n', '1\n', '0\n', '2\n', None, '1\n', '1\n', None, '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', 'Η απάντηση είναι 0.\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', 'Η απάντηση είναι 2.\n\nΗ προϋπόθεση δηλώνει ότι τα δάκρυα έπεσαν μόνο μέχρι τα μάτια της και μετά κάλεσε την Τζον στην βεράντα.  Η δεύτερη πρόταση δηλώνει ότι σκούπισε γρήγορα τα μάτια της και έδιωξε την Τζον από την βεράντα.  Αυτές οι δύο προτάσεις είναι αντίθετες.\n', None, '2\n', '2\n', '2\n', '1\n', '1\n', None, None, '1\n', '2\n', '1\n', '0\n', '1\n', None, '1\n', '2\n', '1\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '2\n', '0\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', None, '0\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '2\n', '0\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '1\n', None, '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '0\n', '0\n', '1\n', '0\n', '2\n', '0\n', '2\n', '2\n', None, '2\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 26
Accuracy el: 0.43103448275862066
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  48%|####8     | 31.5M/65.4M [00:00<00:00, 236MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 276MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 267MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 352MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 313MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  26%|##5       | 102000/392702 [00:00<00:00, 1006647.17 examples/s]Generating train split:  53%|#####2    | 207000/392702 [00:00<00:00, 1029051.15 examples/s]Generating train split:  79%|#######9  | 311000/392702 [00:00<00:00, 1030294.63 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1027391.87 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1026800.05 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 933650.72 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 503kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 6.79MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 11.7MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 27.5MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   5%|4         | 31.5M/672M [00:00<00:02, 255MB/s]model.safetensors:   9%|9         | 62.9M/672M [00:00<00:02, 263MB/s]model.safetensors:  14%|#4        | 94.4M/672M [00:00<00:02, 283MB/s]model.safetensors:  19%|#8        | 126M/672M [00:00<00:01, 281MB/s] model.safetensors:  23%|##3       | 157M/672M [00:00<00:01, 285MB/s]model.safetensors:  28%|##8       | 189M/672M [00:00<00:01, 280MB/s]model.safetensors:  34%|###4      | 231M/672M [00:00<00:01, 292MB/s]model.safetensors:  39%|###8      | 262M/672M [00:00<00:01, 295MB/s]model.safetensors:  44%|####3     | 294M/672M [00:01<00:01, 290MB/s]model.safetensors:  48%|####8     | 325M/672M [00:01<00:01, 287MB/s]model.safetensors:  53%|#####3    | 357M/672M [00:01<00:01, 286MB/s]model.safetensors:  58%|#####7    | 388M/672M [00:01<00:00, 289MB/s]model.safetensors:  62%|######2   | 419M/672M [00:01<00:00, 294MB/s]model.safetensors:  67%|######7   | 451M/672M [00:01<00:00, 293MB/s]model.safetensors:  72%|#######1  | 482M/672M [00:01<00:00, 298MB/s]model.safetensors:  76%|#######6  | 514M/672M [00:01<00:00, 297MB/s]model.safetensors:  81%|########1 | 545M/672M [00:01<00:00, 291MB/s]model.safetensors:  86%|########5 | 577M/672M [00:01<00:00, 291MB/s]model.safetensors:  90%|######### | 608M/672M [00:02<00:00, 287MB/s]model.safetensors:  95%|#########5| 640M/672M [00:02<00:00, 290MB/s]model.safetensors: 100%|#########9| 671M/672M [00:02<00:00, 281MB/s]model.safetensors: 100%|##########| 672M/672M [00:02<00:00, 286MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'Отговорът е 1.\n\nПредположението казва, че те са имали пет деца и едно от тях е умряло. Хипотезата гласи, че едно от петте деца не е умряло.  Те не си противоречат, нито предположението е включено в хипотезата.\n', '0\n', '1\n', '0\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '2\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '2\n', '2\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '2\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_2.json
Accuracy bg: 0.445
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  59%|#####9    | 31.5M/53.2M [00:00<00:00, 264MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 267MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 256MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 119MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###2      | 127000/392702 [00:00<00:00, 1258955.37 examples/s]Generating train split:  66%|######5   | 258000/392702 [00:00<00:00, 1280553.26 examples/s]Generating train split:  99%|#########9| 390000/392702 [00:00<00:00, 1291694.33 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1283068.98 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1189284.23 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1063308.59 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.70MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 5.37MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 59.4MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 79.0MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.22MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   5%|4         | 21.0M/440M [00:00<00:02, 156MB/s]pytorch_model.bin:  12%|#1        | 52.4M/440M [00:00<00:01, 200MB/s]pytorch_model.bin:  19%|#9        | 83.9M/440M [00:00<00:01, 238MB/s]pytorch_model.bin:  26%|##6       | 115M/440M [00:00<00:01, 260MB/s] pytorch_model.bin:  33%|###3      | 147M/440M [00:00<00:01, 273MB/s]pytorch_model.bin:  41%|####      | 178M/440M [00:00<00:00, 280MB/s]pytorch_model.bin:  50%|#####     | 220M/440M [00:00<00:00, 294MB/s]pytorch_model.bin:  57%|#####7    | 252M/440M [00:00<00:00, 298MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:01<00:00, 299MB/s]pytorch_model.bin:  74%|#######3  | 325M/440M [00:01<00:00, 307MB/s]pytorch_model.bin:  83%|########3 | 367M/440M [00:01<00:00, 312MB/s]pytorch_model.bin:  91%|######### | 398M/440M [00:01<00:00, 309MB/s]pytorch_model.bin:  98%|#########7| 430M/440M [00:01<00:00, 305MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 285MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '2\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '2\n', '0\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n']
Saved predictions to: predicted_3.json
Accuracy es: 0.515
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  19%|#8        | 10.5M/55.4M [00:00<00:00, 67.3MB/s]train-00000-of-00001.parquet:  76%|#######5  | 41.9M/55.4M [00:00<00:00, 169MB/s] train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 169MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 160MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 310MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###       | 120000/392702 [00:00<00:00, 1192772.22 examples/s]Generating train split:  77%|#######6  | 302000/392702 [00:00<00:00, 1200838.22 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1211465.09 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1176565.68 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1070831.23 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 280kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.70MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 21.6MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 57.5MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   2%|2         | 10.5M/445M [00:00<00:06, 64.1MB/s]model.safetensors:   5%|4         | 21.0M/445M [00:00<00:07, 56.7MB/s]model.safetensors:   7%|7         | 31.5M/445M [00:00<00:08, 50.2MB/s]model.safetensors:   9%|9         | 41.9M/445M [00:00<00:07, 52.6MB/s]model.safetensors:  12%|#1        | 52.4M/445M [00:01<00:07, 49.4MB/s]model.safetensors:  14%|#4        | 62.9M/445M [00:01<00:07, 52.4MB/s]model.safetensors:  16%|#6        | 73.4M/445M [00:01<00:06, 55.2MB/s]model.safetensors:  19%|#8        | 83.9M/445M [00:01<00:06, 53.7MB/s]model.safetensors:  21%|##1       | 94.4M/445M [00:01<00:06, 53.1MB/s]model.safetensors:  24%|##3       | 105M/445M [00:01<00:06, 55.8MB/s] model.safetensors:  26%|##5       | 115M/445M [00:02<00:06, 48.4MB/s]model.safetensors:  28%|##8       | 126M/445M [00:02<00:06, 50.0MB/s]model.safetensors:  31%|###       | 136M/445M [00:02<00:05, 52.2MB/s]model.safetensors:  33%|###2      | 147M/445M [00:02<00:05, 54.6MB/s]model.safetensors:  35%|###5      | 157M/445M [00:02<00:05, 56.6MB/s]model.safetensors:  38%|###7      | 168M/445M [00:03<00:04, 58.6MB/s]model.safetensors:  40%|####      | 178M/445M [00:03<00:05, 51.1MB/s]model.safetensors:  42%|####2     | 189M/445M [00:03<00:04, 53.6MB/s]model.safetensors:  45%|####4     | 199M/445M [00:03<00:04, 53.6MB/s]model.safetensors:  47%|####7     | 210M/445M [00:03<00:04, 55.5MB/s]model.safetensors:  49%|####9     | 220M/445M [00:04<00:03, 56.8MB/s]model.safetensors:  52%|#####1    | 231M/445M [00:04<00:04, 49.7MB/s]model.safetensors:  54%|#####4    | 241M/445M [00:04<00:03, 51.0MB/s]model.safetensors:  57%|#####6    | 252M/445M [00:04<00:03, 52.4MB/s]model.safetensors:  59%|#####8    | 262M/445M [00:04<00:03, 51.6MB/s]model.safetensors:  61%|######1   | 273M/445M [00:05<00:03, 50.7MB/s]model.safetensors:  64%|######3   | 283M/445M [00:05<00:04, 37.0MB/s]model.safetensors:  66%|######5   | 294M/445M [00:05<00:03, 41.7MB/s]model.safetensors:  68%|######8   | 304M/445M [00:05<00:03, 44.9MB/s]model.safetensors:  71%|#######   | 315M/445M [00:06<00:02, 48.9MB/s]model.safetensors:  73%|#######3  | 325M/445M [00:06<00:02, 49.2MB/s]model.safetensors:  75%|#######5  | 336M/445M [00:06<00:02, 51.7MB/s]model.safetensors:  78%|#######7  | 346M/445M [00:06<00:01, 51.1MB/s]model.safetensors:  80%|########  | 357M/445M [00:07<00:01, 44.8MB/s]model.safetensors:  82%|########2 | 367M/445M [00:07<00:01, 47.0MB/s]model.safetensors:  85%|########4 | 377M/445M [00:07<00:01, 50.6MB/s]model.safetensors:  87%|########7 | 388M/445M [00:07<00:01, 51.0MB/s]model.safetensors:  90%|########9 | 398M/445M [00:07<00:01, 46.4MB/s]model.safetensors:  92%|#########1| 409M/445M [00:08<00:00, 42.5MB/s]model.safetensors:  94%|#########4| 419M/445M [00:08<00:00, 47.7MB/s]model.safetensors:  97%|#########6| 430M/445M [00:08<00:00, 50.9MB/s]model.safetensors:  99%|#########8| 440M/445M [00:08<00:00, 54.2MB/s]model.safetensors: 100%|##########| 445M/445M [00:08<00:00, 50.7MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '0\n', '0\n', '1\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.49
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  41%|####1     | 31.5M/76.5M [00:00<00:00, 251MB/s]train-00000-of-00001.parquet:  82%|########2 | 62.9M/76.5M [00:00<00:00, 244MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 251MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 101MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 145MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  22%|##2       | 87000/392702 [00:00<00:00, 859310.41 examples/s]Generating train split:  44%|####4     | 174000/392702 [00:00<00:00, 858314.06 examples/s]Generating train split:  66%|######6   | 260000/392702 [00:00<00:00, 856045.19 examples/s]Generating train split:  89%|########8 | 349000/392702 [00:00<00:00, 865145.06 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 863707.38 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 928033.52 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 840007.80 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.52MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 6.24MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 49.5MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   5%|4         | 21.0M/423M [00:00<00:03, 111MB/s]model.safetensors:  12%|#2        | 52.4M/423M [00:00<00:02, 173MB/s]model.safetensors:  17%|#7        | 73.4M/423M [00:00<00:02, 162MB/s]model.safetensors:  22%|##2       | 94.4M/423M [00:00<00:02, 154MB/s]model.safetensors:  30%|##9       | 126M/423M [00:00<00:01, 182MB/s] model.safetensors:  37%|###7      | 157M/423M [00:00<00:01, 208MB/s]model.safetensors:  45%|####4     | 189M/423M [00:00<00:01, 223MB/s]model.safetensors:  52%|#####1    | 220M/423M [00:01<00:00, 219MB/s]model.safetensors:  59%|#####9    | 252M/423M [00:01<00:00, 238MB/s]model.safetensors:  67%|######6   | 283M/423M [00:01<00:00, 237MB/s]model.safetensors:  74%|#######4  | 315M/423M [00:01<00:00, 220MB/s]model.safetensors:  82%|########1 | 346M/423M [00:01<00:00, 229MB/s]model.safetensors:  89%|########9 | 377M/423M [00:01<00:00, 245MB/s]model.safetensors:  97%|#########6| 409M/423M [00:01<00:00, 237MB/s]model.safetensors: 100%|##########| 423M/423M [00:02<00:00, 211MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\n', '2\n', 'หลักฐานนั้นไม่เกี่ยวข้องกับสมมติฐาน  คำตอบคือ 0\n', '2\n', '2\n', '1\n', '0\n', '1\n', '2\n', '2\n', '1\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุถึงความยากลำบากในการกำจัดระเบิดไฮโดรเจน ซึ่งสนับสนุนสมมติฐานที่ว่าการหลีกเลี่ยงระเบิดไฮโดรเจนนั้นเกิดจากความยากลำบากในการจัดการ\n', '2\n', '0\n', '0\n', '0\n', '0\n', '0\n', 'ไม่สามารถระบุความสัมพันธ์ระหว่างหลักฐานและสมมติฐานได้เนื่องจากหลักฐานไม่สมบูรณ์ ("<unk>2") และสมมติฐานไม่ชัดเจน  จึงไม่สามารถให้คำตอบได้ว่าเป็น 0, 1 หรือ 2\n\nคำตอบ: ไม่สามารถระบุได้\n', '2\n', '2\nหลักฐานอธิบายการกระทำทางกายภาพที่เกี่ยวข้องกับวัตถุสองชิ้น ในขณะที่สมมติฐานพูดถึงการทำงานกับสิ่งที่ไม่ระบุชื่ออย่างต่อเนื่อง  ไม่มีความเกี่ยวข้องกันระหว่างทั้งสอง  ดังนั้นจึงขัดแย้งกัน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดเป็นเพียงคนเดียวที่ใช้เกณฑ์ควบคุมสำหรับการทดสอบในอุณหภูมิสูง ซึ่งขัดแย้งกับสมมติฐานที่ว่าผู้พูดไม่ต้องการเป็นเพียงคนเดียวที่ดำเนินนโยบายเกี่ยวกับข้อสอบ  หลักฐานแสดงให้เห็นว่าผู้พูด *เป็น* คนเดียว  ดังนั้นจึงเป็นความขัดแย้ง\n', '2\n', '0\n', '2\nหลักฐานระบุว่าบุคคลนั้นเกษียณแล้ว สมมติฐานระบุว่าบุคคลนั้นยังคงทำงานอยู่  สิ่งเหล่านี้ขัดแย้งกัน\n', '2\n', '2\n', '0\n', '0\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐานแสดงให้เห็นว่ามีลูกค้าที่ชื่อไม่รู้จัก (แทนด้วย <unk><unk>ty) ในการประมาณกระแสเงินสด ในขณะที่สมมติฐานระบุว่าไม่มีลูกค้าที่ชื่อเช่นนั้น นี่คือความขัดแย้งโดยตรง\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความขัดแย้งเกี่ยวกับการแบ่งงานระหว่างผู้ที่ทำงานในท้องที่และผู้ที่ทำงานนอกบ้าน  ซึ่งสอดคล้องกับสมมติฐานที่ว่าพวกเขาไม่สามารถตกลงกันได้ว่าใครควรทำงานใช้แรงงานหรือใครควรอยู่บ้าน\n', '1\n', '2\nหลักฐานไม่สนับสนุนหรือขัดแย้งกับสมมติฐาน  ข้อความในหลักฐานนั้นไม่เกี่ยวข้องกับการตัดสินใจของเขาว่าจะพูดอะไรต่อไป\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ **1**\n\nหลักฐานสนับสนุนสมมติฐาน  หลักฐานระบุว่ามีข้อมูลเพียงพอจากภาพยนตร์เรื่องเดียว (1.to"")  ซึ่งสอดคล้องกับสมมติฐานที่ว่าไม่มีข้อมูลจากแหล่งที่สอง (2)  ดังนั้นจึงต้องเดา\n', '0\n', '2\n', '2\n', '2\nหลักฐานอธิบายว่าการไหม้ของสิ่งของอาจทำให้รังสีรั่วไหลออกมา ซึ่งขัดแย้งกับสมมติฐานที่ว่ารังสีสามารถควบคุมได้ทั้งหมดในระหว่างการยิง\n', '0\n', '2\n', '2\n', '0\n', '2\n', '2\n', '0\n', '2\n', '0\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', '1\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1.  หลักฐานระบุว่าการคำนวณต้องใช้ข้อมูลรวม และสมมติฐานระบุว่าต้องมีข้อมูลรวมเพื่อดำเนินการดังกล่าว  ดังนั้น หลักฐานจึงสนับสนุนสมมติฐาน\n', 'คำตอบคือ 2\n', '0\nหลักฐานกล่าวถึงการคำนวณผลรวมและสมมติฐานก็กล่าวถึงการคำนวณจากผลรวมเช่นกัน ดังนั้นหลักฐานและสมมติฐานจึงมีความเกี่ยวข้องกัน\n', '2\nหลักฐานแสดงให้เห็นว่าบุคคลนั้นรู้สึกผิดหวัง  ซึ่งขัดแย้งกับสมมติฐานที่ว่าเขามีความหวังและมีความสุขมาก\n', '0\n', '0\n', '2\n', '2\n', '0\n', '1\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่า Ramon ช่วยเหลือผู้พูด แต่ไม่ได้บอกว่า Ramon ตัดสินผู้พูดหรือไม่  ดังนั้น หลักฐานจึงไม่สนับสนุนหรือขัดแย้งกับสมมติฐานที่ว่า Ramon ตัดสินผู้พูดเงียบๆ  หลักฐานจึงไม่เกี่ยวข้องกับสมมติฐานนี้\n', 'คำตอบคือ 0  ข้อความระบุว่าราโมนอยู่ที่นั่นในขณะที่ผู้พูดรู้สึกประหลาดใจ  สิ่งนี้สนับสนุนสมมติฐานที่ว่าราโมนอยู่ที่นั่น  แต่ไม่ได้ยืนยันหรือปฏิเสธอย่างสมบูรณ์\n', '2\n', '2\n', '0\n', '0\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานไม่ได้สนับสนุนหรือหักล้างสมมติฐาน หลักฐานระบุว่าผู้เขียนไม่รู้ว่าบุคคลนั้นย้ายไปจากธนาคารกันตาหลังจากนั้นหรือไม่  สมมติฐานเสนอสถานที่เฉพาะที่บุคคลนั้นอาจย้ายไปโดยไม่คำนึงถึงว่าพวกเขาเคยอยู่ที่ธนาคารกันตาหรือไม่  ดังนั้นหลักฐานจึงไม่เกี่ยวข้องกับสมมติฐาน\n', 'คำตอบคือ **1**\n\nหลักฐานแสดงให้เห็นว่ากลุ่มบุคคลไม่เปิดเผยข้อมูลเกี่ยวกับการเดินทางของพวกเขา  นี่สนับสนุนสมมติฐานที่ว่าพวกเขากำลังปกปิดอะไรบางอย่าง (เช่น สมมติฐานที่ว่าพวกเขาทำกิจกรรมผิดกฎหมายหรือลับๆ)  หลักฐานไม่ได้ขัดแย้งกับสมมติฐานแต่อย่างใด  มันเป็นหลักฐานสนับสนุนสมมติฐานอย่างชัดเจน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่า "ทั้งหมดที่มันทำ ไม่เคยบอกสถานที่ใด ๆ ที่พวกเขาไป แม้กระทั่งเมื่อพวกเขาออกจากสถานที่เพื่อไปยังที่อื่นเพื่ออยู่สักพักหนึ่ง" ซึ่งขัดแย้งกับสมมติฐานที่ถามว่า "หรือมักจะแจ้งให้เราทราบว่าเราอยู่ที่ไหนหรือจะไปที่ไหน"\n', 'คำตอบคือ 1\nหลักฐานแสดงให้เห็นว่าพวกเขาพยายามอย่างหนักที่จะไม่เปิดเผยสถานที่ที่พวกเขาไปซึ่งสอดคล้องกับสมมติฐานที่พวกเขาไม่เคยเปิดเผยว่าพวกเขาจะไปที่ไหน\n', '2\n', 'คำตอบคือ 1\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าเรือของสหรัฐฯ ได้หยุดเรือของรัสเซียที่กำลังมุ่งหน้าสู่คิวบา ซึ่งพบขีปนาวุธอยู่บนเรือ  และเหตุผลที่ไม่ใช่การสร้างความไม่ปลอดภัย\n\nสมมติฐานไม่ได้ระบุไว้อย่างชัดเจน แต่ดูเหมือนจะบอกเป็นนัยว่าสหรัฐฯ หยุดเรือของรัสเซียเพื่อเหตุผลด้านความปลอดภัย  หลักฐานแสดงให้เห็นว่าเหตุผลนั้นไม่ถูกต้อง  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '0\n', '0\n', '0\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานที่ว่า "ปู่ย่าตายายของเรามักจะบ้าบอสุดๆ เสมอ และเราไม่เคยชอบไปที่บ้านของพวกเขา" ขัดแย้งกับสมมติฐานที่ว่า "ปู่ย่าตายายของเรามักจะโรแมนติกเสมอ และพ่อแม่ของเราก็เช่นกัน"  ทั้งสองส่วนไม่สอดคล้องกัน\n', '0\n', 'คำตอบคือ 2\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ามีการสอนวิธีติดร่มชูชีพและอาวุธสำคัญ (อาจเป็นอาวุธนิวเคลียร์)  ซึ่งหมายความว่าอาวุธนั้นมีกลไกการทำงานที่ซับซ้อนมากกว่าแค่การดึงตัวเหนี่ยวไก\n\nสมมติฐานกล่าวว่าตัวเหนี่ยวไกเป็นตัวทำให้ระเบิดทำงาน แต่ไม่ได้ถูกดึงขึ้นมา  นี่คือคำอธิบายที่ง่ายเกินไปสำหรับอาวุธนิวเคลียร์  หลักฐานบ่งบอกถึงขั้นตอนการใช้งานที่ซับซ้อนกว่า  ดังนั้นจึงมีความขัดแย้งกัน\n', '1\n', '0\n', '2\n', '0\n', 'ไม่สามารถระบุได้ว่าหลักฐานมีความเกี่ยวข้องหรือขัดแย้งกับสมมติฐานได้ เนื่องจากสมมติฐานไม่ครบถ้วน  หลักฐานอธิบายชุดอวกาศที่ทำจากเงิน แต่ไม่มีการระบุสมมติฐานที่เกี่ยวข้องกับชุดอวกาศหรือวัสดุที่ใช้  ดังนั้นจึงไม่สามารถให้คำตอบ 0, 1 หรือ 2 ได้\n\nเพื่อให้สามารถประเมินความสัมพันธ์ระหว่างหลักฐานและสมมติฐานได้ ต้องมีสมมติฐานที่ชัดเจนและสมบูรณ์\n', 'คำตอบคือ 1\n', 'คำตอบคือ 0\n\nหลักฐานระบุคุณสมบัติเฉพาะของชุดสูท (ทำจากเงินทั้งหมด สะท้อนความร้อน)  แต่ไม่ขัดแย้งกับสมมติฐานที่ว่าคุณสามารถเลือกทิศทางได้อย่างอิสระ หลักฐานกล่าวถึงคุณสมบัติของชุดสูท  แต่ไม่ได้กล่าวถึงอิสระในการเลือกทิศทาง  ดังนั้นจึงไม่ขัดแย้งกัน แต่ก็ไม่สนับสนุนสมมติฐานด้วย  จึงเป็นความเกี่ยวข้องที่อ่อน\n', '0\n', '2\n', '2\n', 'ฉันไม่สามารถระบุได้ว่าหลักฐานนั้นเกี่ยวข้องหรือขัดแย้งกับสมมติฐานใดๆ เนื่องจากฉันไม่มีข้อมูลเกี่ยวกับสมมติฐานที่กำลังพูดถึง ดังนั้น ฉันจึงไม่สามารถตอบคำถามได้', '0\n', 'คำตอบคือ 1\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุเพียงว่าพวกเขา "ไป"  สมมติฐานเสริมรายละเอียดว่าพวกเขา "หยุดพักที่สถานีระหว่างทาง"  หลักฐานไม่ได้หักล้างสมมติฐาน  แต่ก็ไม่ได้สนับสนุนโดยตรงเช่นกัน  ดังนั้นจึงเป็นไปได้ทั้งสองอย่าง\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าพวกเขาเดินทางไปทางเหนือ  สมมติฐานระบุว่าพวกเขาเดินทางคนเดียว  ทั้งสองข้อความไม่เกี่ยวข้องกัน  จึงถือว่าขัดแย้งกัน\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดไม่เคยอ่านหนังสือเล่มใดเลย  สมมติฐานระบุว่าผู้พูดไม่เคยอ่านหนังสือที่ยาวกว่าร้อยหน้า  หลักฐานเป็นกรณีพิเศษของสมมติฐาน  หากผู้พูดไม่เคยอ่านหนังสือเล่มใดเลย  นั่นหมายความว่าพวกเขาไม่เคยอ่านหนังสือเล่มใดที่ยาวกว่าร้อยหน้าเช่นกัน\n', '0\n', '2\n', '2\n', '0\n', '0\n', '2\n', '1\n', '0\n', '1\n', '2\n', '2\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าผู้คนส่วนใหญ่ *ไม่* ผ่านการทดสอบและไม่เคยได้บินด้วยชุดแรงดัน  นี่ขัดแย้งกับสมมติฐานที่ว่าพวกเขา *ต้อง* ผ่านการทดสอบก่อนบิน\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานอธิบายถึงขั้นตอนการเตรียมตัวสำหรับการบิน (ไปยังห้องชั้นสูง ขี่ก่อนบิน ฯลฯ)  ในขณะที่สมมติฐานกล่าวถึงการบินที่เกิดขึ้นในภายหลัง (ปล่อยให้บินหลังจาก 2 วัน)  ทั้งสองส่วนไม่เกี่ยวข้องกันโดยตรงและไม่สนับสนุนหรือขัดแย้งกันอย่างชัดเจน  ดังนั้น จึงเป็นการขัดแย้ง (2)\n', '2\n', '2\n', '2\n', '2\n', '0\n', '2\n', '0\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐานว่าน้องสาวของผู้พูดไม่สามารถทำอะไรได้ถูกต้อง  การที่ผู้พูดเกลียดและตำหนิติเตียนน้องสาวอย่างต่อเนื่องบ่งชี้ถึงความไม่พอใจอย่างรุนแรงที่อาจเกิดจากความเชื่อที่ว่าน้องสาวของเธอล้มเหลวเสมอ\n', '0\n', '2\n', '0\n', '1\n', '2\n', '2\n', 'การตอบสนองคือ 1\nหลักฐานบ่งชี้ว่ามีคนอยู่ที่นั่น แต่ไม่ชัดเจนว่ามันสนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ โดยเฉพาะอย่างยิ่งโดยไม่รู้ว่าสมมติฐานคืออะไร\n', 'คำตอบคือ 0\n', '0\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n\nหลักฐานระบุว่าเราไม่รู้ว่าพวกเขากำลังไปที่ไหน ซึ่งแสดงให้เห็นถึงความไม่แน่นอน  สมมติฐานแสดงความหวังว่าพวกเขากำลังมุ่งหน้าไปยังสถานที่ใดสถานที่หนึ่ง  ทั้งสองประโยคนี้เกี่ยวข้องกันเนื่องจากทั้งคู่พูดถึงจุดหมายปลายทางที่ไม่แน่นอน  ความหวังในสมมติฐานเป็นการตอบสนองต่อความไม่แน่นอนที่ระบุไว้ในหลักฐาน\n', '2\n', '0\n', '0\n', '0\n', 'คำตอบคือ **1**\n\nหลักฐานที่ให้ไว้นั้นสนับสนุนสมมติฐาน  เธอพูดว่าเธอ "ถึงจุดที่...ฉันได้รับความเศร้าโศกจากพวกมันเหล่านั้น ฉันรับไม่ได้อีกแล้ว" ซึ่งบ่งชี้ว่าสมมติฐานที่ว่าเธอได้รับความเศร้าโศกจากบางสิ่งและไม่สามารถรับมันได้อีกต่อไปนั้นเป็นความจริง\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี ค.ศ. 1880 ซึ่งขัดแย้งกับสมมติฐานที่ว่าบุคคลนั้นเริ่มต้นก่อน ค.ศ. 1900\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าเขาเกิดในปี 1880 (ธันวาคม) แต่สมมติฐานระบุว่าเขาเกิดในปี 1889 (กันยายน)  ทั้งสองปีต่างกันอย่างมาก ดังนั้นจึงขัดแย้งกัน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 18587 ซึ่งเป็นไปไม่ได้ เนื่องจากปีปัจจุบันคือ 2023 หลักฐานขัดแย้งกับสมมติฐานที่ว่าบุคคลนั้นเกิดหลังปี 1984\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าการขันสกรูไม่เพียงพออาจทำให้ปอดเสียหายได้  สมมติฐานกล่าวถึงความเป็นไปได้ที่สกรูจะทำลายปอดไม่ได้  หลักฐานสนับสนุนส่วนหนึ่งของสมมติฐาน (ว่าสกรู *สามารถ* ทำลายปอดได้ถ้าขันไม่ดี) ดังนั้นจึงมีส่วนเกี่ยวข้องกัน', 'คำตอบคือ **1**\n\nหลักฐานที่ให้มาสนับสนุนสมมติฐานที่ว่าการขันสกรูแรงเกินไปอาจทำลายพลาสติกได้  ประโยคแรกเตือนถึงความเสี่ยงของการทำลายพลาสติกหากขันสกรูแรงเกินไป ในขณะที่ประโยคที่สองเสนอแนะให้ขันให้แน่นเท่าที่จำเป็น ซึ่งสอดคล้องกับความระมัดระวังที่จำเป็นในการป้องกันความเสียหาย\n', '1\n', '1\n', '2\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าเด็กดื่มแชมเปญที่เหลืออยู่ แต่ไม่ได้ระบุจำนวน  สมมติฐานระบุว่าเด็กดื่มแชมเปญสามขวด  หลักฐานไม่ได้ยืนยันหรือหักล้างสมมติฐานนี้  ดังนั้นจึงเป็นการเข้าร่วมกัน\n', 'คำตอบคือ 1\n', '2\n', 'คำตอบคือ 2\n', '2\n', '1\n', '2\n', 'คำตอบคือ **1**\n\nหลักฐานบ่งบอกว่าการทดสอบทำให้เกิดการเรียนรู้ ("คุณมีชีวิตและเรียนรู้...") ซึ่งสนับสนุนสมมติฐานที่ว่าการทดสอบช่วยสอน ("การทดสอบ...สอนคุณเหรอ")  แม้ว่าจะไม่ใช่การพิสูจน์โดยตรง แต่ก็เป็นหลักฐานที่เกี่ยวข้องและสนับสนุนสมมติฐาน\n', '2\n', 'คำตอบคือ 2. หลักฐานแสดงความไม่เห็นด้วยและความเข้าใจผิด ดังนั้นจึงขัดแย้งกับสมมติฐาน', 'คำตอบคือ 0', '0\n', '2\n', '1\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy th: 0.46733668341708545
'XNLI' object has no attribute 'evaluate_results'
