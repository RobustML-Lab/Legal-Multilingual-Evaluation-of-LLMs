README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 101MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  42%|####1     | 21.0M/50.2M [00:00<00:00, 205MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 245MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 233MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 262MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 336MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  30%|###       | 119000/392702 [00:00<00:00, 1182216.09 examples/s]Generating train split:  63%|######2   | 246000/392702 [00:00<00:00, 1226008.52 examples/s]Generating train split:  95%|#########5| 375000/392702 [00:00<00:00, 1250442.65 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1238851.71 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1155030.12 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 971879.49 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 369kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 4.55MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 186MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 20.2MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   5%|4         | 21.0M/440M [00:00<00:02, 175MB/s]model.safetensors:  12%|#1        | 52.4M/440M [00:00<00:01, 206MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:01, 203MB/s]model.safetensors:  24%|##3       | 105M/440M [00:00<00:01, 211MB/s] model.safetensors:  29%|##8       | 126M/440M [00:00<00:01, 206MB/s]model.safetensors:  33%|###3      | 147M/440M [00:00<00:01, 206MB/s]model.safetensors:  40%|####      | 178M/440M [00:00<00:01, 220MB/s]model.safetensors:  48%|####7     | 210M/440M [00:01<00:01, 207MB/s]model.safetensors:  52%|#####2    | 231M/440M [00:01<00:01, 206MB/s]model.safetensors:  57%|#####7    | 252M/440M [00:01<00:00, 203MB/s]model.safetensors:  62%|######1   | 273M/440M [00:01<00:00, 197MB/s]model.safetensors:  69%|######9   | 304M/440M [00:01<00:00, 211MB/s]model.safetensors:  76%|#######6  | 336M/440M [00:01<00:00, 218MB/s]model.safetensors:  83%|########3 | 367M/440M [00:01<00:00, 233MB/s]model.safetensors:  90%|######### | 398M/440M [00:01<00:00, 238MB/s]model.safetensors:  98%|#########7| 430M/440M [00:02<00:00, 211MB/s]model.safetensors: 100%|##########| 440M/440M [00:02<00:00, 211MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 8
Accuracy en: 0.4010416666666667
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  14%|#4        | 10.5M/73.8M [00:00<00:00, 99.4MB/s]train-00000-of-00001.parquet:  57%|#####6    | 41.9M/73.8M [00:00<00:00, 186MB/s] train-00000-of-00001.parquet:  99%|#########9| 73.4M/73.8M [00:00<00:00, 210MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 194MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 177MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 209MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  23%|##2       | 90000/392702 [00:00<00:00, 891423.07 examples/s]Generating train split:  46%|####6     | 181000/392702 [00:00<00:00, 897720.73 examples/s]Generating train split:  70%|######9   | 273000/392702 [00:00<00:00, 905794.44 examples/s]Generating train split:  93%|#########3| 367000/392702 [00:00<00:00, 914266.26 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 907692.03 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 877498.77 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 747535.39 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 13.9kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 4.22MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 30.5MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 780kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   5%|4         | 21.0M/454M [00:00<00:02, 146MB/s]pytorch_model.bin:  12%|#1        | 52.4M/454M [00:00<00:01, 202MB/s]pytorch_model.bin:  16%|#6        | 73.4M/454M [00:00<00:02, 187MB/s]pytorch_model.bin:  23%|##3       | 105M/454M [00:00<00:01, 200MB/s] pytorch_model.bin:  30%|###       | 136M/454M [00:00<00:01, 214MB/s]pytorch_model.bin:  37%|###6      | 168M/454M [00:00<00:01, 224MB/s]pytorch_model.bin:  44%|####3     | 199M/454M [00:00<00:01, 236MB/s]pytorch_model.bin:  51%|#####     | 231M/454M [00:01<00:00, 245MB/s]pytorch_model.bin:  58%|#####7    | 262M/454M [00:01<00:00, 211MB/s]pytorch_model.bin:  65%|######4   | 294M/454M [00:01<00:00, 220MB/s]pytorch_model.bin:  72%|#######1  | 325M/454M [00:01<00:00, 216MB/s]pytorch_model.bin:  78%|#######8  | 357M/454M [00:01<00:00, 223MB/s]pytorch_model.bin:  85%|########5 | 388M/454M [00:01<00:00, 225MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:01<00:00, 229MB/s]pytorch_model.bin:  99%|#########9| 451M/454M [00:02<00:00, 239MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:02<00:00, 222MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '2\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '2\n', '0\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '2\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '0\n', None, '0\n', '2\n', '2\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 4
Accuracy el: 0.4336734693877551
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  32%|###2      | 21.0M/65.4M [00:00<00:00, 195MB/s]train-00000-of-00001.parquet:  80%|########  | 52.4M/65.4M [00:00<00:00, 213MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 211MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 186MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 269MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  25%|##4       | 97000/392702 [00:00<00:00, 956898.69 examples/s]Generating train split:  50%|#####     | 198000/392702 [00:00<00:00, 982158.07 examples/s]Generating train split:  76%|#######5  | 298000/392702 [00:00<00:00, 988695.04 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 984537.51 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 787995.01 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 870826.06 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 265kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 6.03MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 30.4MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 46.9MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   3%|3         | 21.0M/672M [00:00<00:03, 204MB/s]model.safetensors:   8%|7         | 52.4M/672M [00:00<00:02, 214MB/s]model.safetensors:  12%|#2        | 83.9M/672M [00:00<00:02, 225MB/s]model.safetensors:  17%|#7        | 115M/672M [00:00<00:02, 225MB/s] model.safetensors:  22%|##1       | 147M/672M [00:00<00:02, 237MB/s]model.safetensors:  27%|##6       | 178M/672M [00:00<00:01, 248MB/s]model.safetensors:  31%|###1      | 210M/672M [00:00<00:01, 251MB/s]model.safetensors:  36%|###5      | 241M/672M [00:01<00:02, 213MB/s]model.safetensors:  41%|####      | 273M/672M [00:01<00:01, 217MB/s]model.safetensors:  45%|####5     | 304M/672M [00:01<00:01, 216MB/s]model.safetensors:  50%|####9     | 336M/672M [00:01<00:01, 222MB/s]model.safetensors:  55%|#####4    | 367M/672M [00:01<00:01, 224MB/s]model.safetensors:  59%|#####9    | 398M/672M [00:01<00:01, 223MB/s]model.safetensors:  64%|######3   | 430M/672M [00:01<00:01, 239MB/s]model.safetensors:  69%|######8   | 461M/672M [00:02<00:01, 204MB/s]model.safetensors:  73%|#######3  | 493M/672M [00:02<00:00, 211MB/s]model.safetensors:  78%|#######7  | 524M/672M [00:02<00:00, 213MB/s]model.safetensors:  83%|########2 | 556M/672M [00:02<00:00, 226MB/s]model.safetensors:  87%|########7 | 587M/672M [00:02<00:00, 233MB/s]model.safetensors:  92%|#########2| 619M/672M [00:02<00:00, 243MB/s]model.safetensors:  97%|#########6| 650M/672M [00:02<00:00, 253MB/s]model.safetensors: 100%|##########| 672M/672M [00:02<00:00, 225MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'Отговор: 1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n']
Saved predictions to: predicted_2.json
Accuracy bg: 0.43
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  39%|###9      | 21.0M/53.2M [00:00<00:00, 203MB/s]train-00000-of-00001.parquet:  79%|#######8  | 41.9M/53.2M [00:00<00:00, 188MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 189MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 226MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 305MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  30%|##9       | 117000/392702 [00:00<00:00, 1162291.85 examples/s]Generating train split:  61%|######    | 238000/392702 [00:00<00:00, 1185080.12 examples/s]Generating train split:  92%|#########1| 360000/392702 [00:00<00:00, 1197095.58 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1185734.98 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1106903.87 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 873667.14 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 1.65MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 4.49MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 26.3MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 29.3MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.16MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   7%|7         | 31.5M/440M [00:00<00:01, 215MB/s]pytorch_model.bin:  14%|#4        | 62.9M/440M [00:00<00:01, 213MB/s]pytorch_model.bin:  21%|##1       | 94.4M/440M [00:00<00:01, 219MB/s]pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:01, 216MB/s] pytorch_model.bin:  36%|###5      | 157M/440M [00:00<00:01, 216MB/s]pytorch_model.bin:  43%|####2     | 189M/440M [00:00<00:01, 203MB/s]pytorch_model.bin:  48%|####7     | 210M/440M [00:01<00:01, 203MB/s]pytorch_model.bin:  55%|#####4    | 241M/440M [00:01<00:00, 206MB/s]pytorch_model.bin:  60%|#####9    | 262M/440M [00:01<00:00, 204MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:01<00:00, 199MB/s]pytorch_model.bin:  69%|######9   | 304M/440M [00:01<00:00, 198MB/s]pytorch_model.bin:  76%|#######6  | 336M/440M [00:01<00:00, 208MB/s]pytorch_model.bin:  83%|########3 | 367M/440M [00:01<00:00, 219MB/s]pytorch_model.bin:  91%|######### | 398M/440M [00:01<00:00, 191MB/s]pytorch_model.bin:  98%|#########7| 430M/440M [00:02<00:00, 201MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:02<00:00, 205MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa "mejor: me estés diciendo lo mismo" expresa una preferencia por que la persona deje de repetir la misma información.  La hipótesis "estoy hablando todas las mismas cosas que ellos" describe una situación en la que la persona *está* repitiendo la misma información.  Mientras que la premisa indica un deseo de que la situación cambie, no implica ni contradice la hipótesis en sí.  La hipótesis describe un estado de cosas, y la premisa expresa una preferencia o un deseo.  No hay una relación lógica de implicación o contradicción.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '2\n', '2\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_3.json
Accuracy es: 0.445
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  38%|###7      | 21.0M/55.4M [00:00<00:00, 173MB/s]train-00000-of-00001.parquet:  95%|#########4| 52.4M/55.4M [00:00<00:00, 205MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 201MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 138MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 191MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  28%|##7       | 108000/392702 [00:00<00:00, 1072679.00 examples/s]Generating train split:  58%|#####7    | 226000/392702 [00:00<00:00, 1127953.55 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1124113.21 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1119328.94 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1090022.98 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 953686.14 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 214kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 2.83MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 23.0MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 22.5MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/445M [00:00<00:01, 254MB/s]model.safetensors:  14%|#4        | 62.9M/445M [00:00<00:01, 264MB/s]model.safetensors:  21%|##1       | 94.4M/445M [00:00<00:01, 261MB/s]model.safetensors:  28%|##8       | 126M/445M [00:00<00:01, 258MB/s] model.safetensors:  35%|###5      | 157M/445M [00:00<00:01, 217MB/s]model.safetensors:  42%|####2     | 189M/445M [00:00<00:01, 222MB/s]model.safetensors:  49%|####9     | 220M/445M [00:00<00:01, 224MB/s]model.safetensors:  57%|#####6    | 252M/445M [00:01<00:00, 231MB/s]model.safetensors:  64%|######3   | 283M/445M [00:01<00:00, 240MB/s]model.safetensors:  71%|#######   | 315M/445M [00:01<00:00, 245MB/s]model.safetensors:  78%|#######7  | 346M/445M [00:01<00:00, 259MB/s]model.safetensors:  85%|########4 | 377M/445M [00:01<00:00, 265MB/s]model.safetensors:  92%|#########1| 409M/445M [00:01<00:00, 231MB/s]model.safetensors:  99%|#########8| 440M/445M [00:01<00:00, 232MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 238MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '0\n', '1\n', '2\n', '0\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '2\n', '0\n', '1\n', '2\n', '0\n', '1\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.5
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  41%|####1     | 31.5M/76.5M [00:00<00:00, 228MB/s]train-00000-of-00001.parquet:  82%|########2 | 62.9M/76.5M [00:00<00:00, 217MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 224MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 302MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 317MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  20%|##        | 80000/392702 [00:00<00:00, 793226.48 examples/s]Generating train split:  50%|#####     | 198000/392702 [00:00<00:00, 785065.41 examples/s]Generating train split:  72%|#######1  | 281000/392702 [00:00<00:00, 800644.28 examples/s]Generating train split:  92%|#########2| 362000/392702 [00:00<00:00, 800129.32 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 799409.23 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 849028.81 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 706618.20 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.18MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 3.93MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 41.3MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/423M [00:00<00:01, 232MB/s]model.safetensors:  15%|#4        | 62.9M/423M [00:00<00:01, 251MB/s]model.safetensors:  22%|##2       | 94.4M/423M [00:00<00:01, 215MB/s]model.safetensors:  30%|##9       | 126M/423M [00:00<00:01, 224MB/s] model.safetensors:  37%|###7      | 157M/423M [00:00<00:01, 233MB/s]model.safetensors:  45%|####4     | 189M/423M [00:00<00:00, 237MB/s]model.safetensors:  52%|#####1    | 220M/423M [00:00<00:00, 243MB/s]model.safetensors:  59%|#####9    | 252M/423M [00:01<00:00, 254MB/s]model.safetensors:  67%|######6   | 283M/423M [00:01<00:00, 249MB/s]model.safetensors:  74%|#######4  | 315M/423M [00:01<00:00, 260MB/s]model.safetensors:  82%|########1 | 346M/423M [00:01<00:00, 223MB/s]model.safetensors:  89%|########9 | 377M/423M [00:01<00:00, 225MB/s]model.safetensors:  97%|#########6| 409M/423M [00:01<00:00, 229MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 236MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความเชื่อของบุคคลนั้นว่าพวกเขาพิเศษ ซึ่งสนับสนุนสมมติฐานที่ว่าพวกเขาอาจไม่ใช่คนเดียวที่มีความคิดเช่นนั้น  หลักฐานไม่ได้ขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าผู้เขียนเชื่อว่าตนมีอาชีพเฉพาะตัวในกองทัพอากาศ ซึ่งสนับสนุนสมมติฐานที่ว่าผู้เขียนอาจเชื่อว่าตนมีความสำคัญหรือมีเอกลักษณ์', '2\n', 'คำตอบคือ 2\n', '1\n', '0\n', '2\n', 'หลักฐานและสมมติฐานมีความสอดคล้องกัน ดังนั้นคำตอบคือ **1**\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความตั้งใจที่จะทำลายล้างในระดับมหาศาล  ซึ่งสอดคล้องกับสมมติฐานที่ว่า "พวกเราไม่ได้สนใจที่จะปกป้องอะไรเลย"  ความตั้งใจที่จะใช้ระเบิดไฮโดรเจน 20 ล้านตันแสดงถึงการไม่คำนึงถึงผลกระทบและความเสียหายต่อสิ่งใดๆ  ดังนั้นจึงสนับสนุนสมมติฐาน\n', 'คำตอบคือ **1**\n\nหลักฐานระบุว่ามีความจำเป็นที่จะต้องเก็บไฮโดรเจน 20 ล้านตันเนื่องจากไม่มีวิธีที่จะละทิ้งมันได้  นี่สนับสนุนสมมติฐานที่ว่าภารกิจคือการปกป้องสิ่งหนึ่ง (ไฮโดรเจน) มากกว่าสิ่งอื่นๆ  หลักฐานแสดงให้เห็นถึงการเลือกที่จะปกป้องไฮโดรเจนแม้ว่าจะมีความยากลำบากก็ตาม\n', '2\n', '0\n', '0\n', '0\n', '2\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่า Annie Lolono เติบโตขึ้นที่ Augusta และกำลังจะพูดถึงเรื่องราวจากประเทศของเธอ สมมติฐานระบุว่า Annie Lolono จะพูดคุยเกี่ยวกับตารางที่ยุ่งเหยิง หลักฐานไม่ได้ขัดแย้งกับสมมติฐาน แต่ก็ไม่ได้สนับสนุนโดยตรงเช่นกัน  ทั้งสองข้อความมีข้อมูลเกี่ยวกับ Annie Lolono แต่ไม่เกี่ยวข้องกันโดยตรง  ดังนั้น จึงเป็นไปได้ทั้งสองอย่าง\n', 'คำตอบคือ 0 เพราะหลักฐานนั้นสนับสนุนสมมติฐาน (สมมติฐาน U2) เนื่องจากผู้พูดสามารถแก้ไขปัญหาได้เองหลังจากกำจัดห้าปัจจัยที่เกี่ยวข้องกับสมมติฐาน U2', 'คำตอบคือ **2** (ขัดแย้ง)\n\nหลักฐานระบุว่ามีการติดต่อกับ “<unk>2”  แต่สมมติฐานระบุว่าไม่มีการติดต่อกับ "<unk>2"  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', 'คำตอบคือ 1\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่ามีการประมาณกระแสเงินสดบนโต๊ะ และมีการระบุชื่อลูกค้าสมมุติว่า "คัตตี้" ซึ่งทำรายได้ 100,000 เหรียญสหรัฐต่อเดือน  สิ่งนี้สนับสนุนสมมติฐานที่ว่ามีลูกค้ารายหนึ่งชื่อคัตตี้  แม้ว่าจะไม่ระบุว่าเป็นลูกค้าเดียวกันที่ทำรายได้ 100,000 เหรียญสหรัฐต่อเดือนก็ตาม  แต่มันก็เกี่ยวข้องและสนับสนุนสมมติฐานอย่างน้อยส่วนหนึ่ง.\n', '0\n', '2\n', 'คำตอบคือ 0\n', '0\n', '2\n', '2\n', '0\n', '1\n', '0\nหลักฐานไม่มีข้อมูลเพียงพอที่จะสนับสนุนหรือหักล้างสมมติฐาน หลักฐานแสดงให้เห็นถึงหัวข้อการสนทนาเพียงบางส่วน  และไม่ได้บอกอะไรเกี่ยวกับการตัดสินใจของเขาที่จะพูดอะไรต่อไป\n', '2\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าครอบครัวมีลูกห้าคนและมีสี่คนเสียชีวิต สมมติฐานระบุว่าทุกคนรอดชีวิต ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน', '0\n', 'คำตอบคือ 0\n\nหลักฐานที่ให้มาไม่ได้เกี่ยวข้องกับสมมติฐานที่ว่าเด็กที่เสียชีวิตมักมีสุขภาพไม่ดี  หลักฐานกล่าวถึงความสัมพันธ์ครอบครัวและจำนวนบุตร แต่ไม่ได้กล่าวถึงสุขภาพของเด็กหรือการเสียชีวิตของเด็ก\n', '2\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าไม่มีวิดีโอ  ซึ่งสนับสนุนสมมติฐานที่ว่า "พวกเราไม่มีวีดีโอ เพราะงั้นพวกเราจึงทำได้แค่เดา"  หลักฐานจึงเข้ากับสมมติฐาน\n', '0\n', "คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงความสอดคล้องกันในแง่ที่ว่ามีรายงานว่ามีน้ำตาไหลและมีการปัดน้ำตาออกไป  ทั้งสองส่วนสนับสนุนสมมุติฐานที่มีอารมณ์รุนแรงเกิดขึ้น (เช่นความเศร้าโศกหรือความผิดหวัง)  แม้ว่ารายละเอียดบางอย่างจะไม่ชัดเจน (เช่น 'โจ' คือใคร 'ชานบ้าน' หมายถึงอะไร และ 'á <unk>oe' คืออะไร) แต่โดยรวมแล้วหลักฐานสนับสนุนสมมุติฐานที่มีเหตุการณ์ทางอารมณ์เกิดขึ้น\n", 'คำตอบคือ 0\n\nหลักฐานระบุว่าเธอร้องไห้  ซึ่งสนับสนุนสมมติฐานที่ว่าเธอร้องไห้  ส่วนที่เหลือของหลักฐาน (เกี่ยวกับโจมาปรากฏตัว) ไม่ได้ขัดแย้งกับสมมติฐาน  มันอาจจะเกี่ยวข้องกับ *สาเหตุ* ที่เธอร้องไห้  แต่ไม่ใช่กับตัวการกระทำของการร้องไห้เอง\n', '2\nหลักฐานกล่าวถึงการละลายของส่วนประกอบตะกั่วในเครื่องบินที่ถูกไฟไหม้และการรั่วไหลของรังสีที่อาจเกิดขึ้น  สมมติฐานกล่าวถึงการควบคุมและการโจมตีด้วยรังสี  ทั้งสองไม่เกี่ยวข้องกันโดยตรง  หลักฐานพูดถึงผลที่ตามมาจากเหตุการณ์ (ไฟไหม้เครื่องบิน) ในขณะที่สมมติฐานพูดถึงความสามารถในการควบคุมและใช้งานรังสี  จึงเป็นความขัดแย้ง\n', '1\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีเครื่องบินหลายลำบินมาลงจอดเป็นประจำ สมมติฐานระบุว่าเครื่องบินหลายลำใช้เวลาในการลงจอดมากกว่า 55 ชั่วโมง หลักฐานสนับสนุนสมมติฐานได้เนื่องจากเครื่องบินหลายลำที่ลงจอดบ่อยๆ  อาจใช้เวลารวมกันมากกว่า 55 ชั่วโมง\n', '2\nหลักฐานระบุว่าเครื่องบินจำนวนน้อยบินโดยเฉลี่ยต่อสัปดาห์ ซึ่งไม่เกี่ยวข้องกับสมมติฐานที่ว่าการเพิ่มขึ้นของการจราจร EV เป็นปัญหา  ทั้งสองอย่างนั้นไม่เกี่ยวข้องกันอย่างชัดเจน  ดังนั้น คำตอบจึงคือ 2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าชุดสูทถูกใช้ในช่วงเวลาหนึ่ง แต่ไม่ได้ระบุระยะเวลาที่เฉพาะเจาะจง  สมมติฐานระบุว่าการทดลองใช้เวลาสามเดือน  หลักฐานไม่สนับสนุนหรือขัดแย้งกับความยาวของการทดลองโดยเฉพาะ', 'คำตอบคือ 1\n', '0\n', 'คำตอบคือ 1\n', '2\nหลักฐานระบุว่าระเบิดจะไม่ระเบิดไม่ว่าจะตกกระแทกเล็กน้อยแค่ไหน  ซึ่งขัดแย้งกับสมมติฐานที่บอกว่ามีโอกาสที่ระเบิดจะเกิดการกระแทกเสมอไป\n', '2\n', '0\n', '1\n', '0\n', '2\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าแพะเก็บของอย่างปลอดภัยและไร้กังวล ซึ่งขัดแย้งกับสมมติฐานที่ว่าสัตว์เสียเวลากับการเก็บของโดยเฉพาะแพะ\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าผู้เขียนกำลังพยายามคำนวณผลรวมเพื่อแก้ปัญหาบางอย่าง  แสดงให้เห็นถึงความเกี่ยวข้องโดยตรงกับภารกิจหรือสมมติฐานที่ต้องการการคำนวณผลรวมเพื่อไปถึงคำตอบ\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้พูดพยายามคำนวณผลรวมบางอย่างและเคารพพวกมัน ในขณะที่สมมติฐานระบุว่าผู้พูดไม่รู้จักผลรวมเหล่านั้นและขอข้อมูลเพิ่มเติม นี่คือความขัดแย้ง', '2\n', '2\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานทั้งสองชิ้นสนับสนุนสมมติฐานเดียวกันที่ว่าบุคคลนั้นรู้สึกผิดหวังหรือไม่พอใจกับสิ่งที่เขาพบเมื่อเขามาถึงที่หมายปลายทาง  ทั้งสองชิ้นแสดงให้เห็นถึงการแสดงออกทางสีหน้าและพฤติกรรมของเขาที่บ่งบอกถึงความรู้สึกเชิงลบ\n', '2\n', '2\n', '0\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าเธอกินอาหารเป็นจำนวนมาก แต่ยังคงลดน้ำหนักอยู่  นี่ขัดแย้งกับสมมติฐานที่คาดหวังว่าการกินอาหารมากจะทำให้เพิ่มน้ำหนัก  ดังนั้นคำตอบจึงเป็น 2 (ความขัดแย้ง)\n', 'คำตอบคือ 2\n\nหลักฐาน ("ความจริงก็คือคุณสว่างไสว!") ไม่เกี่ยวข้องกับสมมติฐาน ("เธอไม่ได้หนักเลย")  ไม่มีความสัมพันธ์ระหว่างน้ำหนักและความสว่าง  ดังนั้นจึงเป็นความขัดแย้ง\n', '0\n', '0\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดไม่เคยถามว่าพวกเขาไปที่ไหน  นี่ไม่สนับสนุนหรือคัดค้านสมมติฐานว่าพวกเขาไม่เคยบอกสถานที่ที่พวกเขาไป', '2\nหลักฐานแสดงให้เห็นว่าพวกเขาไม่ได้แจ้งให้ทราบว่าพวกเขาอยู่ที่ไหน ขัดแย้งกับสมมติฐานที่ว่าพวกเขาบอกคุณว่าพวกเขาอยู่ที่ไหนและจะไปที่ไหน\n', '0\n', 'คำตอบคือ 2\n', '0\n', '2\n', '0\n', '2\n', '0\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าชายผู้นั้นเข้ามาทางร่างกาย ซึ่งไม่ขัดแย้งกับสมมติฐานใดๆ ที่มีอยู่', 'คำตอบคือ 0 (เกี่ยวข้อง)\n\nหลักฐานกล่าวถึงประสบการณ์ในอดีตที่บ่งบอกถึงความสำคัญของสถานที่แห่งนั้นสำหรับครอบครัว  สมมติฐานกล่าวถึงการวางแผนที่จะใช้เวลานานที่สถานที่เดียวกัน  หลักฐานจึงสนับสนุนหรือเกี่ยวข้องกับสมมติฐาน  ไม่ใช่การขัดแย้งโดยตรง\n', '0\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุถึงข้อจำกัดด้านเวลาของผู้พูด ซึ่งสอดคล้องกับสมมติฐานที่ว่าผู้พูดไม่มีเวลาเพียงพอที่จะจัดการกับสิ่งของของตน\n', '2\n', '0\n', '1\n', '0\n', '1\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', '2\n', '2\nหลักฐานกล่าวถึงการฝึกฝนกับนักบินจีนและอังกฤษ  ซึ่งขัดแย้งกับสมมติฐานที่ว่าปีที่แล้วไม่ได้มีการฝึกฝนกับใคร\n', '0\nหลักฐานระบุว่ามีการฝึกนักบินชาวจีนและอังกฤษในเครื่องบินรุ่น 40 <unk> 2  สมมติฐานระบุถึงการฝึก 5 สัปดาห์กับชาวอังกฤษ  หลักฐานไม่ได้ระบุระยะเวลาการฝึก  ดังนั้นจึงไม่ขัดแย้งกัน แต่ก็ไม่สนับสนุนสมมติฐานโดยตรง  จึงเป็นการเกี่ยวข้องกันเพียงเล็กน้อย\n', 'หลักฐานบ่งชี้ว่ามีการฝึกอบรมร่วมกับนักบินต่างชาติ (จีนและอังกฤษ)  ซึ่งสนับสนุนสมมติฐานที่ว่ามีการฝึกอบรมร่วมกับทหารชาติอื่นๆ  ดังนั้นคำตอบจึงเป็น **1**\n', '2\n', '2\n', '2\nหลักฐานกล่าวถึงการตรวจสอบบริษัท โดยไม่ได้กล่าวถึงการปรับปรุงกฎหมายทางการเงิน  ดังนั้นจึงไม่เกี่ยวข้องกับสมมติฐาน\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\nหลักฐานระบุว่าผู้พูดไม่เคยอ่านหนังสือเลย  สมมติฐานระบุว่าผู้พูดไม่ได้อ่านหนังสือจำนวนมาก หลักฐานสนับสนุนสมมติฐานอย่างสมบูรณ์ เพราะถ้าผู้พูดไม่ได้อ่านหนังสือเลย  นั่นหมายความว่าผู้พูดไม่ได้อ่านหนังสือจำนวนมากด้วย\n', '2\n', '2\n', '0\n', '0\n', '2\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', 'หลักฐานไม่เกี่ยวข้องโดยตรงกับสมมติฐาน  หลักฐานพูดถึงการเตรียมตัวก่อนการบิน (ขึ้นห้องสูง, ขี่ก่อนบิน)  แต่ไม่ได้ระบุถึง *จำนวน* การฝึกอบรม  ดังนั้นคำตอบคือ **0**\n', 'คำตอบคือ **2** (ความขัดแย้ง)\n\nข้อความนั้นไม่เกี่ยวข้องและขัดแย้งกับสมมติฐานใดๆ  ไม่มีสมมติฐานที่ระบุไว้ และข้อความนั้นเป็นเพียงคำอธิบายที่สับสนและไม่สมบูรณ์เกี่ยวกับการเดินทางไปยังห้องหมายเลข n  ไม่มีความสัมพันธ์ที่ชัดเจนระหว่างการบิน ชุดแรงดัน และจำนวนห้อง\n', '2\n', '0\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าหน่วยทหารได้รับการโหวตให้เป็นเอกอัครราชทูตของเท็กซัส  ซึ่งขัดแย้งกับสมมติฐานที่ว่าหน่วยทหารไม่ได้รับความนิยมเป็นเอกอัครราชทูตของเท็กซัส\n', '2\n', '0\n', 'คำถามไม่สมบูรณ์  ฉันต้องการข้อมูลเพิ่มเติมเกี่ยวกับสมมติฐานและหลักฐานเพื่อตอบคำถามได้  โปรดระบุสมมติฐานและหลักฐานที่เกี่ยวข้อง\n', '2\n', '1\n', '2\n', '2\n', '0\n', '2\n', '0\n', '0\n', '2\n', '0\n', '1\n', '0\n', '0\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\n', 'คำตอบคือ 2\nหลักฐานแสดงให้เห็นว่าบุคคลนั้นประสบความทุกข์ทรมานจากความเศร้าโศกมากมายจากสมมติฐานของพวกเขา ซึ่งขัดแย้งกับความคิดที่ว่าสมมติฐานนั้นเป็นจริงหรือเป็นประโยชน์', '0\n', 'คำตอบคือ **2** (ขัดแย้ง)\n\nหลักฐานระบุว่าเขาเกิดในปี 199110080 ซึ่งเป็นไปไม่ได้  ปี ค.ศ. ไม่มีตัวเลขที่ยาวขนาดนั้น สมมติฐานระบุว่าเขาเกิดก่อนปี ค.ศ. 2000  แต่หลักฐาน (แม้จะผิดพลาด) บ่งบอกถึงวันที่เกิดหลังปี ค.ศ. 2000  ดังนั้น หลักฐานจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าบุคคลนั้นก่อตั้งในปี 1889 หรือ 1996 ซึ่งขัดแย้งกับสมมติฐานที่ว่าเขาเกิดในเดือนธันวาคม ปัจจุบันอายุมากกว่า 80 ปี  ไม่มีทางที่บุคคลจะก่อตั้งอะไรได้ในปี 1889 หรือ 1996 แล้วมีอายุมากกว่า 80 ปีในปัจจุบัน\n', '2\n', '2\n', '2\n', '1\n', '0\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าผู้เขียนได้รับการส่งไปยัง Del Rio ซึ่งสอดคล้องกับสมมติฐาน  แม้ว่าจะมีตัวอักษรที่ไม่รู้จักอยู่บ้าง แต่บริบทก็ชัดเจนพอที่จะสนับสนุนสมมติฐาน\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าเด็กๆ ดื่มเบียร์  แต่ไม่ได้ระบุว่าพวกเขาดื่มแชมเปญไปกี่ขวด สมมติฐานกล่าวว่าเด็กๆ ดื่มแชมเปญไปสามขวด  หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานนี้  หลักฐานและสมมติฐานจึงไม่เกี่ยวข้องกัน\n', '2\n', '2\n', '0\n', '0\n', '1\n', '2\n', '0\n', '2\n', 'คำตอบคือ 2\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐาน  หลักฐานระบุจุดประสงค์ของข้อความคือการบอกรายละเอียดว่าอันตรายนั้นร้ายแรงแค่ไหน  ซึ่งสอดคล้องกับสมมติฐานโดยตรง\n', 'ฉันไม่สามารถให้คำตอบได้ เนื่องจากไม่มีหลักฐานหรือสมมติฐานที่ระบุไว้ในคำถาม', '2\n', '2\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 2
Accuracy th: 0.47474747474747475
'XNLI' object has no attribute 'evaluate_results'
