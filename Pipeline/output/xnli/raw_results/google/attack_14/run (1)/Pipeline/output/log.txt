README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 111MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  63%|######2   | 31.5M/50.2M [00:00<00:00, 238MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 247MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 96.8MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 110MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  33%|###2      | 128000/392702 [00:00<00:00, 1267969.37 examples/s]Generating train split:  81%|########1 | 320000/392702 [00:00<00:00, 1269677.27 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1274540.45 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1248200.95 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1060285.99 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 427kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 6.08MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 52.7MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 53.4MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:01, 294MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:01, 343MB/s]model.safetensors:  26%|##6       | 115M/440M [00:00<00:00, 355MB/s] model.safetensors:  36%|###5      | 157M/440M [00:00<00:00, 358MB/s]model.safetensors:  45%|####5     | 199M/440M [00:00<00:00, 353MB/s]model.safetensors:  55%|#####4    | 241M/440M [00:00<00:00, 359MB/s]model.safetensors:  64%|######4   | 283M/440M [00:00<00:00, 356MB/s]model.safetensors:  74%|#######3  | 325M/440M [00:00<00:00, 362MB/s]model.safetensors:  83%|########3 | 367M/440M [00:01<00:00, 368MB/s]model.safetensors:  93%|#########2| 409M/440M [00:01<00:00, 359MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 356MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '0\n', None, '0\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 2
Accuracy en: 0.47474747474747475
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  28%|##8       | 21.0M/73.8M [00:00<00:00, 160MB/s]train-00000-of-00001.parquet:  57%|#####6    | 41.9M/73.8M [00:00<00:00, 183MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 235MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 217MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 245MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 285MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##3       | 93000/392702 [00:00<00:00, 922485.61 examples/s]Generating train split:  49%|####8     | 191000/392702 [00:00<00:00, 948638.98 examples/s]Generating train split:  73%|#######3  | 288000/392702 [00:00<00:00, 953875.88 examples/s]Generating train split:  98%|#########8| 386000/392702 [00:00<00:00, 959149.03 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 952254.39 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1001117.82 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 889971.62 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 20.9kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 5.26MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 47.9MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 1.33MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   7%|6         | 31.5M/454M [00:00<00:01, 268MB/s]pytorch_model.bin:  14%|#3        | 62.9M/454M [00:00<00:01, 278MB/s]pytorch_model.bin:  21%|##        | 94.4M/454M [00:00<00:01, 280MB/s]pytorch_model.bin:  30%|###       | 136M/454M [00:00<00:01, 296MB/s] pytorch_model.bin:  37%|###6      | 168M/454M [00:00<00:00, 288MB/s]pytorch_model.bin:  46%|####6     | 210M/454M [00:00<00:00, 299MB/s]pytorch_model.bin:  53%|#####3    | 241M/454M [00:00<00:00, 295MB/s]pytorch_model.bin:  60%|######    | 273M/454M [00:00<00:00, 295MB/s]pytorch_model.bin:  69%|######9   | 315M/454M [00:01<00:00, 298MB/s]pytorch_model.bin:  78%|#######8  | 357M/454M [00:01<00:00, 307MB/s]pytorch_model.bin:  85%|########5 | 388M/454M [00:01<00:00, 298MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:01<00:00, 295MB/s]pytorch_model.bin:  99%|#########9| 451M/454M [00:01<00:00, 294MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 293MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '2\n', 'Η απάντηση είναι 1.\n\nΗ προϋπόθεση δηλώνει ότι το λάθος ήταν η μη ενημέρωση για τον προορισμό.  Η υπόθεση δηλώνει ότι ο ερωτών δεν ρώτησε ποτέ.  Δεν υπάρχει καμία λογική σχέση συνέπειας ή αντίφασης μεταξύ των δύο προτάσεων.  Και οι δύο προτάσεις μπορούν να είναι αληθείς ταυτόχρονα.\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'Η απάντηση είναι 1.\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '2\n', '2\n', '1\n', '2\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 3
Accuracy el: 0.467005076142132
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  48%|####8     | 31.5M/65.4M [00:00<00:00, 244MB/s]train-00000-of-00001.parquet:  96%|#########6| 62.9M/65.4M [00:00<00:00, 262MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 255MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 264MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 376MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  26%|##5       | 102000/392702 [00:00<00:00, 1012747.57 examples/s]Generating train split:  53%|#####2    | 208000/392702 [00:00<00:00, 1034729.35 examples/s]Generating train split:  80%|#######9  | 314000/392702 [00:00<00:00, 1039905.16 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1032581.84 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 844185.40 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 879849.79 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 515kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 5.79MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 29.3MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 41.4MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   5%|4         | 31.5M/672M [00:00<00:02, 296MB/s]model.safetensors:  11%|#         | 73.4M/672M [00:00<00:01, 335MB/s]model.safetensors:  17%|#7        | 115M/672M [00:00<00:01, 353MB/s] model.safetensors:  23%|##3       | 157M/672M [00:00<00:01, 345MB/s]model.safetensors:  30%|##9       | 199M/672M [00:00<00:01, 350MB/s]model.safetensors:  36%|###5      | 241M/672M [00:00<00:01, 351MB/s]model.safetensors:  42%|####2     | 283M/672M [00:00<00:01, 351MB/s]model.safetensors:  48%|####8     | 325M/672M [00:00<00:00, 351MB/s]model.safetensors:  55%|#####4    | 367M/672M [00:01<00:01, 294MB/s]model.safetensors:  59%|#####9    | 398M/672M [00:01<00:01, 242MB/s]model.safetensors:  64%|######3   | 430M/672M [00:01<00:00, 252MB/s]model.safetensors:  69%|######8   | 461M/672M [00:01<00:00, 263MB/s]model.safetensors:  73%|#######3  | 493M/672M [00:01<00:00, 273MB/s]model.safetensors:  78%|#######7  | 524M/672M [00:01<00:00, 273MB/s]model.safetensors:  83%|########2 | 556M/672M [00:01<00:00, 277MB/s]model.safetensors:  87%|########7 | 587M/672M [00:01<00:00, 273MB/s]model.safetensors:  94%|#########3| 629M/672M [00:02<00:00, 290MB/s]model.safetensors: 100%|#########9| 671M/672M [00:02<00:00, 301MB/s]model.safetensors: 100%|##########| 672M/672M [00:02<00:00, 298MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '2\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, None, '0\n', '2\n', '1\n', '1\n', None, '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '2\n', '1\n', '0\n', None, '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', None, '1\n', '1\n', '2\n', '0\n', '1\n', None, '1\n', '2\n', '1\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '2\n', None, '2\n', '1\n', '0\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', None, '2\n', '0\n', '1\n', '0\n', None, '1\n', '0\n', '1\n', None, '2\n', '2\n', '1\n', '0\n', None, '1\n', '0\n', '1\n', '1\n', None, '1\n', '1\n']
Saved predictions to: predicted_2.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 25
Accuracy bg: 0.44571428571428573
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  59%|#####9    | 31.5M/53.2M [00:00<00:00, 243MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 248MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 309MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 242MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###1      | 124000/392702 [00:00<00:00, 1229245.32 examples/s]Generating train split:  65%|######4   | 254000/392702 [00:00<00:00, 1266233.19 examples/s]Generating train split:  98%|#########7| 383000/392702 [00:00<00:00, 1268923.84 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1262288.91 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1212618.33 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1038875.66 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.73MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 5.91MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 62.6MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 54.0MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.31MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   5%|4         | 21.0M/440M [00:00<00:02, 147MB/s]pytorch_model.bin:  10%|9         | 41.9M/440M [00:00<00:02, 170MB/s]pytorch_model.bin:  19%|#9        | 83.9M/440M [00:00<00:01, 245MB/s]pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:01, 286MB/s] pytorch_model.bin:  38%|###8      | 168M/440M [00:00<00:00, 301MB/s]pytorch_model.bin:  48%|####7     | 210M/440M [00:00<00:00, 313MB/s]pytorch_model.bin:  57%|#####7    | 252M/440M [00:00<00:00, 311MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:00<00:00, 312MB/s]pytorch_model.bin:  74%|#######3  | 325M/440M [00:01<00:00, 321MB/s]pytorch_model.bin:  83%|########3 | 367M/440M [00:01<00:00, 324MB/s]pytorch_model.bin:  93%|#########3| 409M/440M [00:01<00:00, 329MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 300MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', 'La respuesta es 0.\n\nLa premisa describe a alguien que estaba tan frustrado que habló de nuevo con Kevin. La hipótesis describe a Kevin estando tan frustrado que empezó a hablar de nuevo con alguien.  Aunque los sujetos son diferentes, la estructura de las frases es similar y se describe una situación donde la frustración lleva a una nueva conversación.  La premisa implica que la frustración puede llevar a una nueva conversación, lo que es consistente con la hipótesis.\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', 'La respuesta es 0.\n\nLa premisa indica que la hermana escuchaba las quejas diarias, lo que implica que la hermana no hacía nada para solucionar la situación que causaba la infelicidad del narrador.  Sin embargo, esto no implica necesariamente que la hermana nunca hizo nada bien en general.  La premisa se enfoca en un aspecto específico de la relación, no en la totalidad de sus interacciones.\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '1\n', '2\n', '2\n', '2\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_3.json
Accuracy es: 0.44
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  38%|###7      | 21.0M/55.4M [00:00<00:00, 146MB/s]train-00000-of-00001.parquet:  76%|#######5  | 41.9M/55.4M [00:00<00:00, 173MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 185MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 223MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 416MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###1      | 124000/392702 [00:00<00:00, 1223824.74 examples/s]Generating train split:  64%|######3   | 251000/392702 [00:00<00:00, 1243994.92 examples/s]Generating train split:  97%|#########6| 379000/392702 [00:00<00:00, 1252633.34 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1245913.66 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1159235.56 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1036504.26 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 171kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.17MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 85.8MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 9.15MB/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 9.08MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/445M [00:00<00:01, 282MB/s]model.safetensors:  14%|#4        | 62.9M/445M [00:00<00:01, 292MB/s]model.safetensors:  24%|##3       | 105M/445M [00:00<00:01, 311MB/s] model.safetensors:  33%|###2      | 147M/445M [00:00<00:00, 327MB/s]model.safetensors:  42%|####2     | 189M/445M [00:00<00:00, 335MB/s]model.safetensors:  52%|#####1    | 231M/445M [00:00<00:00, 339MB/s]model.safetensors:  61%|######1   | 273M/445M [00:00<00:00, 329MB/s]model.safetensors:  71%|#######   | 315M/445M [00:00<00:00, 335MB/s]model.safetensors:  80%|########  | 357M/445M [00:01<00:00, 330MB/s]model.safetensors:  90%|########9 | 398M/445M [00:01<00:00, 329MB/s]model.safetensors:  99%|#########8| 440M/445M [00:01<00:00, 312MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 320MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '2\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '0\n', '0\n', '0\n', '0\n', '2\n', '1\n', '2\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.435
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  27%|##7       | 21.0M/76.5M [00:00<00:00, 136MB/s]train-00000-of-00001.parquet:  55%|#####4    | 41.9M/76.5M [00:00<00:00, 169MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 240MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 213MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 120MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 376MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  22%|##2       | 88000/392702 [00:00<00:00, 870848.65 examples/s]Generating train split:  56%|#####5    | 218000/392702 [00:00<00:00, 860078.52 examples/s]Generating train split:  78%|#######8  | 308000/392702 [00:00<00:00, 870301.78 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 868562.98 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 860643.15 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 786491.22 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.47MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 4.82MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 27.2MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:  10%|9         | 41.9M/423M [00:00<00:01, 327MB/s]model.safetensors:  20%|#9        | 83.9M/423M [00:00<00:01, 332MB/s]model.safetensors:  30%|##9       | 126M/423M [00:00<00:00, 320MB/s] model.safetensors:  40%|###9      | 168M/423M [00:00<00:00, 323MB/s]model.safetensors:  50%|####9     | 210M/423M [00:00<00:00, 302MB/s]model.safetensors:  57%|#####6    | 241M/423M [00:00<00:00, 287MB/s]model.safetensors:  64%|######4   | 273M/423M [00:00<00:00, 289MB/s]model.safetensors:  72%|#######1  | 304M/423M [00:01<00:00, 291MB/s]model.safetensors:  79%|#######9  | 336M/423M [00:01<00:00, 267MB/s]model.safetensors:  87%|########6 | 367M/423M [00:01<00:00, 278MB/s]model.safetensors:  94%|#########4| 398M/423M [00:01<00:00, 287MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 295MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '0\n', '1\n', 'คำตอบคือ 0 หลักฐานไม่เกี่ยวข้องกับสมมติฐาน เนื่องจากหลักฐานเป็นข้อความที่ดูเหมือนจะไม่ต่อเนื่องกัน และไม่มีความเกี่ยวข้องกับสมมติฐานที่ระบุไว้\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดมีเลขประจำตัวเฉพาะในกองทัพอากาศ แต่ไม่ได้ระบุว่าเป็นคนเดียวที่มีเลขประจำตัวนั้น  สมมติฐานกล่าวว่าผู้พูดเป็นคนเดียวที่มีเลขนั้น  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '2\n', '0\n', 'คำตอบคือ 1.\n\nหลักฐานระบุว่ามีการคาดหวังการมาถึงของบุคคล แต่ไม่ได้ระบุว่าเป็นการมาช้าหรือไม่  สมมติฐานระบุว่าบุคคลนั้นมาช้าเล็กน้อย.  หลักฐานไม่หักล้างสมมติฐาน แต่ก็ไม่ได้สนับสนุนมันอย่างเต็มที่เช่นกัน.  ดังนั้นจึงเป็นการเกี่ยวข้องกัน  แต่ไม่ใช่การยืนยันหรือการปฏิเสธโดยตรง\n', '0\n', '0\n', '1\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นถึงความกังวลเกี่ยวกับการจัดการไฮโดรเจนจำนวนมหาศาล ซึ่งบ่งชี้ว่ามีสิ่งที่ต้องได้รับการปกป้อง (ในกรณีนี้คือสิ่งแวดล้อมหรือโครงสร้างพื้นฐาน)  สมมติฐานระบุว่าไม่มีสิ่งใดที่ต้องได้รับการปกป้อง ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 1\n\nหลักฐานกล่าวถึงความต้องการปกป้องบางสิ่งบางอย่างมากกว่าสิ่งอื่นๆ ซึ่งสอดคล้องกับสมมติฐานที่แสดงออกในส่วนของภารกิจ  แม้ว่าหลักฐานจะไม่ให้รายละเอียดเกี่ยวกับสิ่งที่กำลังได้รับการปกป้อง แต่ก็ยังคงเป็นหลักฐานที่สนับสนุนสมมติฐานโดยทั่วไป\n', 'หลักฐานระบุว่ามีปัญหาในการกำจัดระเบิดไฮโดรเจน สมมติฐานกล่าวว่าระเบิดไฮโดรเจนจัดการยากมาก  ทั้งสองข้อความสนับสนุนซึ่งกันและกัน ดังนั้นคำตอบคือ **0**\n', '0\n', '0\n', '2\n', '2\n', '0\n', '0\n', '2\n', 'ฉันไม่สามารถระบุได้ว่าหลักฐานเกี่ยวข้องหรือขัดแย้งกับสมมติฐานอย่างไรเนื่องจากไม่มีการระบุสมมติฐาน  ฉันต้องการสมมติฐานเพื่อที่จะประเมินความเกี่ยวข้องของหลักฐานได้  หลักฐานที่ให้มานั้นบ่งชี้ว่าผู้เขียนไม่ได้ติดต่อกับบุคคลที่ระบุว่าเป็น <unk>2 แต่ฉันไม่สามารถตีความได้ว่าสิ่งนี้เกี่ยวข้องหรือขัดแย้งกับสมมติฐานใดๆโดยไม่มีสมมติฐานนั้น', '2\n', 'คำตอบคือ 1\n', '0\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีกระแสเงินสดอยู่บนโต๊ะ และสำหรับ "คัตตี้" ซึ่งเป็นชื่อสมมุติ สมมติฐานระบุว่า คัตตี้มีเงิน $10 ต่อเดือน หลักฐานไม่ได้ยืนยันหรือปฏิเสธสมมติฐานโดยตรง  หลักฐานพูดถึงเงินสดที่มีอยู่ แต่ไม่ได้ระบุว่าเป็นของคัตตี้หรือเกี่ยวข้องกับรายได้ $10 ต่อเดือนของคัตตี้  ดังนั้นจึงไม่เกี่ยวข้องหรือขัดแย้งกัน\n', '2\n', '2\n', '2\n', '2\n', '2\n', '0\n', '1\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานบอกเล่าถึงบทสนทนาเกี่ยวกับประเทศญี่ปุ่นและสิ่งที่ดูเหมือนจะเป็นคำศัพท์ทางเทคนิคหรือรหัส (IHIrd, <unk>, <unk>2 <unk>, "ick และ <unk>lackbird) สมมติฐานพูดถึง "พวกเขา" และตัวเลข "สาม" และ "สอง"  หลักฐานไม่มีข้อมูลพอที่จะยืนยันหรือปฏิเสธสมมติฐานได้  ดังนั้นจึงไม่เกี่ยวข้องกันหรือขัดแย้งกัน', 'คำตอบคือ 0\n\nหลักฐาน (พวกเขา:6 หมายความว่าพวกเขามีลูกประมาณห้าคน หนึ่งในนั้นเสียชีวิต) ไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐาน (ลูกคนอื่นๆ ของเขาทุกคนรอดชีวิต)  หลักฐานระบุว่ามีลูกห้าคนและหนึ่งคนเสียชีวิต  แต่ไม่ได้บอกอะไรเกี่ยวกับสถานะของลูกอีกสี่คน  สมมติฐานเป็นไปได้ภายใต้หลักฐานนี้ แต่ก็ยังมีสมมติฐานอื่นๆ ที่เป็นไปได้เช่นกัน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าหนึ่งในห้าคนตาย ขณะที่สมมติฐานระบุว่าหนึ่งในสามคนตาย นี่เป็นความขัดแย้งกัน', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าไม่มีการตอบสนองและมีข้อมูลจำกัดจากภาพยนตร์  สมมติฐานระบุว่าขาดวิดีโอจึงมีข้อมูลจำกัด  ทั้งสองข้อความสนับสนุนกัน  ดังนั้นจึงเป็นการสนับสนุนซึ่งกันและกัน (1)\n', '0\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าเธอร้องไห้มีความสุขและอนุญาตให้โจปรากฏตัว ซึ่งบ่งชี้ว่าเธอมีความสุขที่ได้พบกับเขา  หลักฐานสนับสนุนสมมติฐานว่าเธอมีความสุขที่ได้พบกับโจ\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าการเผาไหม้ของเครื่องบินทำลายส่วนประกอบตะกั่วที่อาจรั่วไหลของรังสี  สมมติฐานระบุว่ารังสีสามารถรั่วไหลจากส่วนประกอบเหล่านี้หลังจากเครื่องบินไหม้  หลักฐานจึงสนับสนุนส่วนหนึ่งของสมมติฐาน (ว่าส่วนประกอบอาจรั่วรังสี) แต่ขัดแย้งกับอีกส่วนหนึ่ง (ว่าการเผาไหม้ทำให้รังสีรั่ว)  เนื่องจากหลักฐานแสดงให้เห็นถึงความเป็นไปได้ทั้งสอง  จึงไม่ใช่การสนับสนุนหรือการขัดแย้งโดยสมบูรณ์  แต่มีความเกี่ยวข้องบางส่วน  ดังนั้นคำตอบที่ดีที่สุดคือ 0\n', '2\n', 'คำตอบคือ 1\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'หลักฐานระบุว่ามีการใช้ชุดความดันอากาศเป็นระยะเวลาหนึ่ง  แต่ไม่ได้ระบุระยะเวลาที่แน่นอน  ดังนั้นจึงไม่สามารถยืนยันหรือปฏิเสธสมมติฐานได้อย่างชัดเจน\n\nคำตอบคือ **0**\n', '1\n', '2\n', 'คำตอบคือ 1\nหลักฐานระบุว่าวัตถุนั้นไม่ระเบิด ไม่ว่าจะชนพื้นแรงแค่ไหนก็ตาม  สมมติฐานระบุว่าระเบิดถูกยกเลิกโดยนักบิน  ทั้งสองข้อความสนับสนุนกัน  แม้ว่าจะไม่ได้บอกข้อมูลเดียวกันโดยตรง แต่ก็มีประเด็นที่สอดคล้องกัน  นั่นคือ ระเบิดไม่ทำงานแล้ว\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐานอย่างสมบูรณ์\n', '2\n', 'คำตอบคือ 0 (ไม่เกี่ยวข้อง)\n\nหลักฐานที่ให้มาไม่สนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ เพราะไม่มีสมมติฐานที่ระบุไว้  ทั้งสองฝ่ายแสดงความคิดเห็นที่ไม่เกี่ยวข้องกันโดยตรง\n', '0\n', '0\n', 'คำตอบคือ 1\n', '0\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานอธิบายกระบวนการคำนวณซึ่งหมายความว่ามีการรวบรวมข้อมูล (ยอดคงเหลือ) แล้ว เพื่อวิเคราะห์ ข้อสันนิษฐานยืนยันความเชื่อว่ามีข้อมูลเพียงพอสำหรับการวิเคราะห์  หลักฐานสนับสนุนข้อสันนิษฐานนี้', 'คำตอบคือ **1**\n\nหลักฐานแสดงให้เห็นว่าครูไม่แน่ใจว่าจะทำอย่างไรกับตัวเลขหรือผลรวม ซึ่งสอดคล้องกับสมมติฐานที่ว่าครูไม่รู้ว่าจะต้องทำอะไรกับหรือรวมผลลัพธ์  ครูขอข้อมูลเพิ่มเติมเพื่อจัดการกับสิ่งเหล่านี้  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าควรจะใช้ผลรวมปัจจุบันและ "ช่างมันไปแบบนั้น" ซึ่งแสดงถึงการละเว้นการคำนวณเพิ่มเติมจากยอดรวม สมมติฐานนั้นกล่าวถึงการคำนวณจากยอดรวม ซึ่งขัดแย้งกับหลักฐานโดยตรง\n', '2\n', '1\n', '0\n', '2\n', '0\n', '2\n', '2\n', '0\n', '2\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', '0\n', '0\n', 'คำตอบคือ 0 (ไม่เกี่ยวข้อง)\n\nข้อความอธิบายถึงความล้มเหลวในการสื่อสารของผู้พูดกับคนอื่นๆ  เกี่ยวกับการเดินทางของพวกเขา ไม่ได้มีการตั้งสมมติฐานใด ๆ  ดังนั้นจึงไม่มีหลักฐานใดที่สามารถสนับสนุนหรือขัดแย้งกับสมมติฐานได้\n', '0\n', '1\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่ามีการจ่ายค่าเช่าบ้านสำหรับผู้เขียนและอาสาสมัคร ซึ่งสนับสนุนสมมติฐานที่ว่ามีการพยายามหาที่อยู่อาศัยให้กับพวกเขา\n', '0\n', '1\n', '2\n', '0\n', '0\n', '2\n', '2\n', '0\n', '1\n', '2\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานอธิบายถึงการฝึกฝนการใช้ร่มชูชีพและอุปกรณ์ระเบิด  ในขณะที่สมมติฐานกล่าวถึงการทำงานของระเบิดโดยทั่วไป หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานโดยตรง  มันเป็นข้อมูลที่ไม่เกี่ยวข้องกับความถูกต้องของสมมติฐาน\n', '0\n', '0\n', '2\n', '0\n', 'คำตอบคือ 1\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าชุดปรับความดันของเครื่องบินนั้นคล้ายกับชุดนักบินอวกาศของบริษัท  สมมติฐานระบุว่าโทรศัพท์ของบริษัทคล้ายกับโทรศัพท์ของนักบินอวกาศ  ทั้งสองข้อความชี้ไปที่ความคล้ายคลึงกันระหว่างเทคโนโลยีของบริษัทกับเทคโนโลยีที่ใช้ในอวกาศ ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน', '2\n', 'คำตอบคือ 2\n\nหลักฐาน ("เขาเป็นปู่ของฉัน") ขัดแย้งกับสมมติฐาน ("ตาของฉันโง่").  ไม่มีความสัมพันธ์โดยตรงระหว่างความฉลาดของตาและความสัมพันธ์ของปู่กับหลาน.\n', '2\n', '2\n', '2\nหลักฐานกล่าวถึงการฝึกนักบินจีนและอังกฤษบนเครื่องบินโบอิ้ง  ซึ่งบ่งชี้ว่ามีการร่วมมือทางการเงินหรืออย่างน้อยก็ความร่วมมือบางอย่างกับประเทศเหล่านั้น  สมมติฐานระบุว่าไม่มีเงินดอลลาร์กับใคร ซึ่งขัดแย้งกับหลักฐาน\n', 'คำตอบคือ **2** (ความขัดแย้ง)\n\nข้อความนั้นไม่ชัดเจนและมีข้อมูลที่ขัดแย้งกัน ทำให้ไม่สามารถยืนยันหรือปฏิเสธสมมติฐานได้อย่างชัดเจน  ตัวเลขของเครื่องบิน ("30 หรือ 40") ไม่แน่นอน และคำว่า "<unk>" ทำให้ข้อความไม่สมบูรณ์และเข้าใจยาก  ดังนั้นจึงไม่สามารถระบุได้ว่าข้อความนั้นสนับสนุนสมมติฐานหรือไม่\n', '1\n', '2\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าเขาไปไม่ถึงหลายครั้งระหว่างทาง ซึ่งขัดแย้งกับคำกล่าวอ้างที่ว่าเขาเดินทางไปทางเหนือ', '0\n', '0\n', '0\n', '2\n', 'คำตอบคือ 2', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้พูดหยิบรองเท้าจากที่ใดที่หนึ่งและจากไป โดยบอกเป็นนัยๆว่าพวกเขาขโมยรองเท้ามา  สมมติฐานบอกว่าพวกเขาออกจากร้านโดยคิดว่าไม่ใช่ปัญหา ซึ่งบ่งบอกว่าพวกเขาไม่ได้คิดว่าการเอาของไปนั้นเป็นปัญหา  ทั้งสองอย่างนี้ขัดแย้งกัน', '0\n', '0\n', '0\n', '2\n', '1\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นถึงความขัดแย้ง เนื่องจากผู้พูดกล่าวว่ามีคนมากกว่า 15 คนที่โรงเรียนนั้นเพื่อที่จะผ่านไป แต่ในขณะเดียวกันก็กล่าวว่าพวกเขาไม่ได้เคารพและไม่ได้เป็นส่วนหนึ่งของกลุ่มนั้น  นี่คือความขัดแย้งที่ชัดเจน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้สมัครคนนั้นได้รับเลือกจากผู้สมัครมากกว่า 15 คน  นี่เป็นหลักฐานที่บ่งชี้ว่าเขาหรือเธอเป็นผู้สมัครที่เหมาะสมหรือมีคุณสมบัติมากกว่าคนอื่นๆ  ซึ่งขัดแย้งกับสมมติฐานที่ว่าเขาหรือเธอเป็น "ผู้สมัครที่น่าหงุดหงิดที่สุด"\n', 'ฉันไม่สามารถตอบคำถามได้เนื่องจากข้อความที่ให้มานั้นไม่สมบูรณ์  คำว่า "<unk>" ทำให้ฉันไม่สามารถเข้าใจความหมายหรือบริบทของข้อความได้อย่างถูกต้อง  ดังนั้นจึงไม่สามารถระบุได้ว่าหลักฐานนั้นสนับสนุน ขัดแย้ง หรือไม่เกี่ยวข้องกับสมมติฐานใดๆ\n', 'คำตอบคือ 0 (การเข้าร่วม)\n\nหลักฐานอธิบายขั้นตอนที่จำเป็นก่อนการบิน (ผ่านห้องชั้นช, ขี่ก่อนเริ่มบิน, ฯลฯ) ซึ่งสนับสนุนสมมติฐานที่ว่าต้องมีการฝึกอบรมเป็นจำนวนมากก่อนที่จะประสบความสำเร็จ  ขั้นตอนเหล่านี้บ่งชี้ถึงความจำเป็นของการเตรียมการและการฝึกฝนอย่างเข้มข้นก่อนปฏิบัติภารกิจ\n', 'คำตอบคือ 2 (ขัดแย้ง)\n\nหลักฐานระบุว่าพวกเขาบินได้เพียง 2 วินาทีในวันแรก ซึ่งขัดแย้งกับสมมติฐานที่ว่าพวกเขาปล่อยให้พบินไปนานกว่านั้น  ไม่มีการระบุระยะเวลาการบินที่แน่นอนในสมมติฐาน  การบิน 2 วินาทีสั้นเกินไปที่จะสนับสนุนสมมติฐาน  ดังนั้น จึงเป็นความขัดแย้ง\n', '1\n', 'คำตอบคือ 2\n', '2\n', 'คำตอบคือ 0.\n\nหลักฐานระบุว่ารัฐสภาเท็กซัสลงคะแนนเสียงให้หน่วยทหารเป็นทูตของจอร์เจีย  ซึ่งบ่งชี้ว่ามีประเพณีหรือความเป็นไปได้สำหรับหน่วยทหารที่จะทำหน้าที่เป็นทูต  นี่สนับสนุนสมมติฐานที่ว่าหน่วยทหารของสหรัฐฯอาจได้รับอนุญาตให้เป็นทูตของเท็กซัส  หลักฐานไม่ขัดแย้งกับสมมติฐาน  แต่ก็ไม่ได้พิสูจน์มันโดยตรง  ดังนั้นจึงเป็นการสนับสนุนบางส่วน (0)\n', '1\n', 'คำตอบคือ 2\n\nหลักฐานกล่าวถึงหน่วยทหารที่ได้รับการแต่งตั้งให้เป็น "เอกอัครราชทูตของเท็กซัส" ซึ่งบ่งชี้ถึงบทบาททางการทูต  สมมติฐานกล่าวถึงการแต่งตั้งหน่วยทหารให้เป็น "รัฐมนตรีเท็กซัส"  ซึ่งเป็นตำแหน่งทางการเมืองภายในรัฐ  ทั้งสองมีเรื่องราวที่แตกต่างกัน  ดังนั้นจึงขัดแย้งกัน', '2\n', 'คำตอบคือ 0\n', '0\n', '2\n', '1\n', '1\n', '0\n', 'คำตอบคือ 0\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้พูดเคยไปพบปะกับบุคคลนั้นในช่วงเช้า สมมติฐานคือผู้พูดไม่ได้ไปพบปะกับบุคคลนั้นในวันนั้น ดังนั้น หลักฐานจึงขัดแย้งกับสมมติฐาน', '0\n', 'คำตอบคือ 1', '0\n', '2\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ 1\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในวันที่ 18 กุมภาพันธ์ ปีใดปีหนึ่งในช่วงปี 1889  สมมติฐานระบุว่าบุคคลนั้นเกิดก่อนปี ค.ศ. 19767  เนื่องจากปี 1889 น้อยกว่าปี 19767  หลักฐานและสมมติฐานจึงไม่ขัดแย้งกัน แต่หลักฐานไม่ได้สนับสนุนสมมติฐานอย่างเต็มที่  ดังนั้นจึงไม่มีความสัมพันธ์ที่เข้ากันได้อย่างสมบูรณ์แบบ  ความสัมพันธ์ระหว่างหลักฐานและสมมติฐานจึงเป็นความไม่ลงรอยกัน\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าคนๆ นั้นเกิดในปี 1880 สมมติฐานระบุว่าเขาไม่ได้บันทึกสิ่งใดจนถึงวันที่ 1 มกราคม 1984 ซึ่งเป็นความขัดแย้งกันอย่างชัดเจน เพราะคนๆ นั้นเสียชีวิตไปนานแล้วก่อนวันที่ 1 มกราคม 1984\n', '2\n', '2\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงการเดินทางไปยังสถานที่ที่คล้ายกับที่กล่าวถึงในสมมติฐาน  แม้ว่าจะมีตัวอักษรที่ขาดหายไปและอักขระพิเศษ แต่ก็มีความเกี่ยวข้องกันพอที่จะระบุว่าหลักฐานสนับสนุนสมมติฐาน', 'คำตอบคือ 2\n\nหลักฐานระบุว่าทีมได้รับคำสั่งให้ไปยังสถานที่ที่ไม่รู้จักในเท็กซัส และผู้เขียนต้องไปยังฐานทัพอากาศที่ไม่รู้จักในเท็กซัส  สมมติฐานระบุว่าผู้เขียนไม่เคยไปเท็กซัสมาก่อน  หลักฐานนี้ขัดแย้งกับสมมติฐานเนื่องจากแสดงให้เห็นว่าผู้เขียนจะต้องไปเท็กซัส\n', '2\nหลักฐานระบุว่าผู้พูดได้รับคำสั่งไปยังสถานที่ที่ไม่รู้จักและหลังจากนั้นก็พบว่าพวกเขาต้องไปยังฐานทัพอากาศที่ไม่รู้จัก  สมมติฐานกล่าวว่าเครื่องบินแอร์ฟอร์สส่งผู้พูดไปยังเดล ริโอ ในฮาวาย หลักฐานไม่มีการกล่าวถึงเดล ริโอ หรือฮาวาย ดังนั้นจึงขัดแย้งกับสมมติฐาน\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่ามีแชมเปญเหลืออยู่หลังจากที่เด็กผู้ชายบางคนดื่มไปแล้ว  แต่ไม่ได้ระบุว่ามีแชมเปญกี่ขวดเหลืออยู่ หรือว่าเด็กผู้ชายดื่มไปทั้งหมดกี่ขวด  ดังนั้น หลักฐานจึงไม่สนับสนุนหรือขัดแย้งกับสมมติฐานที่ว่าเด็กผู้ชายดื่มแชมเปญไปสามขวด\n', '2\n', '2\n', '2\n', '0\n', '0\n', '2\n', '2\n', '0\n', 'คำตอบคือ 2\nหลักฐานและสมมติฐานขัดแย้งกัน', '0\n', '0\n', '2\n', '0\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 2
Accuracy th: 0.41919191919191917
'XNLI' object has no attribute 'evaluate_results'
