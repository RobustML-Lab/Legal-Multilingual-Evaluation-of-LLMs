README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 109MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  84%|########3 | 41.9M/50.2M [00:00<00:00, 354MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 338MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 283MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 381MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  34%|###3      | 132000/392702 [00:00<00:00, 1301660.15 examples/s]Generating train split:  68%|######8   | 269000/392702 [00:00<00:00, 1334959.42 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1343894.12 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1280137.86 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1062875.73 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 442kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 3.75MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 54.7MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 19.3MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:01, 240MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:01, 297MB/s]model.safetensors:  26%|##6       | 115M/440M [00:00<00:01, 312MB/s] model.safetensors:  36%|###5      | 157M/440M [00:00<00:00, 321MB/s]model.safetensors:  45%|####5     | 199M/440M [00:00<00:00, 323MB/s]model.safetensors:  55%|#####4    | 241M/440M [00:00<00:00, 311MB/s]model.safetensors:  64%|######4   | 283M/440M [00:00<00:00, 320MB/s]model.safetensors:  74%|#######3  | 325M/440M [00:01<00:00, 325MB/s]model.safetensors:  83%|########3 | 367M/440M [00:01<00:00, 332MB/s]model.safetensors:  93%|#########2| 409M/440M [00:01<00:00, 337MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 322MB/s]
Attack entry stored in: output/attacks/attack.txt
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['0\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', None, '1\n', '2\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '2\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', None]
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 24
Accuracy en: 0.4318181818181818
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  43%|####2     | 31.5M/73.8M [00:00<00:00, 244MB/s]train-00000-of-00001.parquet:  85%|########5 | 62.9M/73.8M [00:00<00:00, 276MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 273MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 271MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 292MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  26%|##6       | 103000/392702 [00:00<00:00, 1014735.08 examples/s]Generating train split:  62%|######2   | 245000/392702 [00:00<00:00, 955949.17 examples/s] Generating train split:  87%|########7 | 343000/392702 [00:00<00:00, 959651.62 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 965823.52 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 977506.77 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 858795.90 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 19.8kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 3.79MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 26.3MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 1.15MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   9%|9         | 41.9M/454M [00:00<00:01, 338MB/s]pytorch_model.bin:  18%|#8        | 83.9M/454M [00:00<00:01, 323MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:01, 326MB/s] pytorch_model.bin:  37%|###6      | 168M/454M [00:00<00:00, 331MB/s]pytorch_model.bin:  46%|####6     | 210M/454M [00:00<00:00, 334MB/s]pytorch_model.bin:  55%|#####5    | 252M/454M [00:00<00:00, 334MB/s]pytorch_model.bin:  65%|######4   | 294M/454M [00:00<00:00, 336MB/s]pytorch_model.bin:  74%|#######3  | 336M/454M [00:01<00:00, 336MB/s]pytorch_model.bin:  83%|########3 | 377M/454M [00:01<00:00, 335MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:01<00:00, 332MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 333MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 332MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', None, None, '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '2\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', None, '2\n', '1\n', '2\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '0\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', 'Η απάντηση είναι 0.  Η υπόθεση δηλώνει ότι ο ομιλητής δεν πήγε και άρα δεν είδε το άτομο. Αυτό είναι σύμφωνο με την ερώτηση, η οποία αφήνει ανοιχτό το ενδεχόμενο ο ομιλητής να μην έκανε τίποτα ή να μην συνέβη τίποτα.\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '2\n', '1\n', '0\n', None, '2\n', '2\n', '2\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 9
Accuracy el: 0.46596858638743455
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  48%|####8     | 31.5M/65.4M [00:00<00:00, 247MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 289MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 280MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 324MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 369MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  26%|##6       | 103000/392702 [00:00<00:00, 1017529.02 examples/s]Generating train split:  54%|#####3    | 212000/392702 [00:00<00:00, 1050314.88 examples/s]Generating train split:  81%|########  | 318000/392702 [00:00<00:00, 1050241.48 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1046010.26 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1014408.06 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 920322.26 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 458kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 5.47MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 38.6MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 31.8MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   2%|1         | 10.5M/672M [00:00<00:07, 83.2MB/s]model.safetensors:   6%|6         | 41.9M/672M [00:00<00:03, 194MB/s] model.safetensors:  11%|#         | 73.4M/672M [00:00<00:02, 240MB/s]model.safetensors:  16%|#5        | 105M/672M [00:00<00:02, 260MB/s] model.safetensors:  20%|##        | 136M/672M [00:00<00:01, 276MB/s]model.safetensors:  25%|##4       | 168M/672M [00:00<00:01, 282MB/s]model.safetensors:  30%|##9       | 199M/672M [00:00<00:01, 284MB/s]model.safetensors:  34%|###4      | 231M/672M [00:00<00:01, 277MB/s]model.safetensors:  39%|###8      | 262M/672M [00:00<00:01, 287MB/s]model.safetensors:  44%|####3     | 294M/672M [00:01<00:01, 293MB/s]model.safetensors:  48%|####8     | 325M/672M [00:01<00:01, 299MB/s]model.safetensors:  53%|#####3    | 357M/672M [00:01<00:01, 299MB/s]model.safetensors:  58%|#####7    | 388M/672M [00:01<00:00, 302MB/s]model.safetensors:  64%|######3   | 430M/672M [00:01<00:00, 309MB/s]model.safetensors:  69%|######8   | 461M/672M [00:01<00:00, 309MB/s]model.safetensors:  75%|#######4  | 503M/672M [00:01<00:00, 312MB/s]model.safetensors:  81%|########1 | 545M/672M [00:01<00:00, 315MB/s]model.safetensors:  87%|########7 | 587M/672M [00:02<00:00, 316MB/s]model.safetensors:  94%|#########3| 629M/672M [00:02<00:00, 315MB/s]model.safetensors:  98%|#########8| 661M/672M [00:02<00:00, 313MB/s]model.safetensors: 100%|##########| 672M/672M [00:02<00:00, 291MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '1\n', 'Отговорът е 2.\n\nПървото изказване предполага, че говорителят е бил единственият бивш радиооператор в  генерал сили affc. Второто изказване противоречи на това предположение, заявявайки, че е имало и други бивши радиооператори.\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '2\n', '1\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '0\n', '0\n', '0\n', '2\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '2\n', '2\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_2.json
Accuracy bg: 0.445
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  59%|#####9    | 31.5M/53.2M [00:00<00:00, 246MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 257MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 235MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 335MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  34%|###4      | 134000/392702 [00:00<00:00, 1332269.96 examples/s]Generating train split:  84%|########3 | 328000/392702 [00:00<00:00, 1296493.43 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1301031.88 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1195305.06 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 977062.12 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.15MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 5.22MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 19.0MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 53.6MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.04MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   7%|7         | 31.5M/440M [00:00<00:01, 309MB/s]pytorch_model.bin:  17%|#6        | 73.4M/440M [00:00<00:01, 323MB/s]pytorch_model.bin:  26%|##6       | 115M/440M [00:00<00:01, 324MB/s] pytorch_model.bin:  36%|###5      | 157M/440M [00:00<00:00, 327MB/s]pytorch_model.bin:  45%|####5     | 199M/440M [00:00<00:00, 325MB/s]pytorch_model.bin:  55%|#####4    | 241M/440M [00:00<00:00, 322MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:00<00:00, 322MB/s]pytorch_model.bin:  74%|#######3  | 325M/440M [00:01<00:00, 325MB/s]pytorch_model.bin:  83%|########3 | 367M/440M [00:01<00:00, 327MB/s]pytorch_model.bin:  93%|#########3| 409M/440M [00:01<00:00, 326MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 324MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '1\n', '1\n', '1\n', '0\n', 'La respuesta es 1.\n\nEl pasaje expresa resentimiento por la promesa incumplida de privilegios, pero no establece una hipótesis o premisa clara para evaluar una implicación o contradicción.  El escritor simplemente comparte una experiencia personal de decepción.\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', None, '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa indica que el hablante pudo resolver un problema usando totales. La hipótesis indica que el hablante no sabe cómo resolver el problema usando solo porcentajes.  Estos enunciados no se implican ni contradicen directamente.  Podría ser que el problema sea resoluble con totales o porcentajes, o solo con totales.  La información proporcionada no permite establecer una relación lógica definitiva de implicación o contradicción.\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', 'La respuesta es 1.\n\nLa premisa indica que la persona nunca aprendió por sí misma, lo que sugiere una dependencia de los demás. La hipótesis indica que recibe mucha ayuda de la gente. Si bien existe una correlación entre ambas afirmaciones, la premisa no implica ni contradice directamente la hipótesis. La persona podría recibir mucha ayuda sin aprender por sí misma, o podría no recibir mucha ayuda a pesar de no aprender por sí misma.  Por lo tanto, no hay una implicación o contradicción clara.\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '0\n', '0\n', '0\n', '1\n', '1\n', '0\n', None, '1\n', '0\n', '2\n', '0\n', '1\n', None, '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_3.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 5
Accuracy es: 0.4512820512820513
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  57%|#####6    | 31.5M/55.4M [00:00<00:00, 247MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 277MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 299MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 327MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###2      | 127000/392702 [00:00<00:00, 1257867.29 examples/s]Generating train split:  66%|######5   | 259000/392702 [00:00<00:00, 1291421.75 examples/s]Generating train split: 100%|#########9| 391000/392702 [00:00<00:00, 1302125.10 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1291895.78 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1088667.65 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 961766.00 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 182kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.30MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 34.6MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 40.7MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   5%|4         | 21.0M/445M [00:00<00:03, 126MB/s]model.safetensors:  12%|#1        | 52.4M/445M [00:00<00:02, 193MB/s]model.safetensors:  21%|##1       | 94.4M/445M [00:00<00:01, 257MB/s]model.safetensors:  28%|##8       | 126M/445M [00:00<00:01, 262MB/s] model.safetensors:  38%|###7      | 168M/445M [00:00<00:00, 288MB/s]model.safetensors:  47%|####7     | 210M/445M [00:00<00:00, 307MB/s]model.safetensors:  54%|#####4    | 241M/445M [00:00<00:00, 305MB/s]model.safetensors:  61%|######1   | 273M/445M [00:01<00:00, 263MB/s]model.safetensors:  68%|######8   | 304M/445M [00:01<00:00, 268MB/s]model.safetensors:  78%|#######7  | 346M/445M [00:01<00:00, 289MB/s]model.safetensors:  87%|########7 | 388M/445M [00:01<00:00, 304MB/s]model.safetensors:  97%|#########6| 430M/445M [00:01<00:00, 307MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 281MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '0\n', '0\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '0\n', '0\n', '0\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '0\n', '0\n', '0\n', '2\n', "La réponse est 1.\n\nLa première phrase contient des informations contradictoires (né en 1848, puis quelque chose comme 8 pouces en 1889, juste après sa naissance).  La deuxième phrase est vague mais compatible avec une naissance avant 1900.  Il n'y a donc ni implication ni contradiction.\n", '1\n', '2\n', '0\n', '2\n', '0\n', '0\n', '1\n', '2\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n']
Saved predictions to: predicted_4.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy fr: 0.45226130653266333
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  27%|##7       | 21.0M/76.5M [00:00<00:00, 189MB/s]train-00000-of-00001.parquet:  55%|#####4    | 41.9M/76.5M [00:00<00:00, 196MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 257MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 238MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 403MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 443MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  22%|##1       | 85000/392702 [00:00<00:00, 842787.20 examples/s]Generating train split:  46%|####5     | 180000/392702 [00:00<00:00, 896500.25 examples/s]Generating train split:  69%|######9   | 271000/392702 [00:00<00:00, 897383.74 examples/s]Generating train split:  92%|#########1| 361000/392702 [00:00<00:00, 894567.29 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 893365.61 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 868145.55 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 760379.83 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.33MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 4.00MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 11.2MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   5%|4         | 21.0M/423M [00:00<00:02, 198MB/s]model.safetensors:  10%|9         | 41.9M/423M [00:00<00:01, 205MB/s]model.safetensors:  20%|#9        | 83.9M/423M [00:00<00:01, 276MB/s]model.safetensors:  30%|##9       | 126M/423M [00:00<00:00, 309MB/s] model.safetensors:  40%|###9      | 168M/423M [00:00<00:00, 322MB/s]model.safetensors:  50%|####9     | 210M/423M [00:00<00:00, 332MB/s]model.safetensors:  59%|#####9    | 252M/423M [00:00<00:00, 340MB/s]model.safetensors:  69%|######9   | 294M/423M [00:00<00:00, 346MB/s]model.safetensors:  79%|#######9  | 336M/423M [00:01<00:00, 348MB/s]model.safetensors:  89%|########9 | 377M/423M [00:01<00:00, 346MB/s]model.safetensors:  99%|#########9| 419M/423M [00:01<00:00, 346MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 327MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['คำตอบคือ 0\n', '1\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าครูคิดว่าสิทธิพิเศษนั้นยังคงเป็นอยู่  ซึ่งไม่เกี่ยวข้องกับสมมติฐานว่าผู้พูดไม่ใช่คนเดียวที่ไร่ในวันนั้น\n', '2\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานบอกว่าใครบางคนบอกผู้เล่าเรื่องว่าบุคคลอื่นจะโทรหาพวกเขาหากพบสมมติฐาน สมมติฐานระบุว่าผู้เล่าเรื่องได้รับข้อมูลที่ถูกปฏิเสธและเดินทางไปยังที่แห่งนี้เพื่อพบกับใครบางคน\n\nทั้งสองส่วนไม่ได้มีส่วนเกี่ยวข้องกันโดยตรง  หลักฐานพูดถึงการโทรศัพท์ในอนาคตที่ขึ้นอยู่กับการยืนยันของสมมติฐาน ในขณะที่สมมติฐานอธิบายสถานการณ์ปัจจุบัน  ดังนั้นจึงขัดแย้งกัน\n', '0\n', '2\n', '0\n', '2\n', 'คำตอบคือ **2** (ความขัดแย้ง)\n\nหลักฐานนั้นไม่เกี่ยวข้องกับสมมติฐานใดๆ  และไม่สามารถตีความได้ว่าสนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ เพราะหลักฐานไม่สมบูรณ์และไม่ชัดเจน  ข้อความนั้นมีตัวอักษรและสัญลักษณ์ที่ไม่เกี่ยวข้องกัน ทำให้ไม่สามารถวิเคราะห์ความสัมพันธ์กับสมมติฐานใดๆ ได้\n', '2\n', 'คำตอบคือ **1**\n\nหลักฐานระบุว่ามีการพยายามหลีกเลี่ยงการใช้ระเบิดขนาดใหญ่ (20 ล้านตัน) เนื่องจากความยากลำบากในการจัดการ  สมมติฐานระบุว่าระเบิดไฮโดรเจนจัดการยาก  หลักฐานสนับสนุนสมมติฐานนี้โดยเน้นถึงความไม่ประสงค์ที่จะใช้ระเบิดขนาดใหญ่ซึ่งโดยนัยยะคือ อาจหมายถึงระเบิดไฮโดรเจน (เนื่องจากขนาดมหึมา) ดังนั้นจึงเป็นการสนับสนุนสมมติฐาน\n', 'คำตอบคือ 0\n\nหลักฐาน "ฉันก็เลยไม่แน่ใจจริงๆ ว่าทำไม" ไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐาน "ฉันไม่รู้เหตุผล"  หลักฐานแสดงความไม่แน่นอน ซึ่งไม่ใช่การยืนยันหรือปฏิเสธความไม่รู้\n', '0\n', '0\n', '1\n', '0\n', '0\n', '2\n', '2\n', '2\nหลักฐานพูดถึงการกระทำที่เฉพาะเจาะจง (ใส่ m, 💚 ห้ากองออกมาจาก ยู2) ซึ่งไม่เกี่ยวข้องกับสมมติฐานเกี่ยวกับการทำงานกับความไม่มีความสุขเป็นเวลานาน  หลักฐานและสมมติฐานไม่ได้เกี่ยวข้องกันเลย\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าบุคคลนั้นเป็นคนเดียวในสถานการณ์เฉพาะ  สมมติฐานแสดงความปรารถนาที่จะไม่เป็นเพียงคนเดียวในการดำเนินนโยบายเกี่ยวกับการควบคุมการสอบ  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '2\n', '2\n', '2\nหลักฐานระบุว่ายศเป็นพันจ่าอากาศและเกษียณแล้ว  สมมติฐานถามถึงวันที่เกษียณ  หลักฐานไม่ให้ข้อมูลวันที่เกษียณ จึงขัดแย้งกับสมมติฐาน\n', '1\n', 'คำตอบคือ 0\n\nหลักฐานกล่าวถึงกระแสเงินสดสำหรับ "คัตตี้" ซึ่งเป็นชื่อลูกค้าที่เหมือนกันกับสมมติฐาน แต่หลักฐานไม่ได้ยืนยันหรือปฏิเสธจำนวนเงินที่ได้กล่าวไว้ในสมมติฐาน (10,000 ดอลลาร์ต่อเดือน)  จึงไม่เกี่ยวข้องและไม่ขัดแย้งกันอย่างสมบูรณ์\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่ามีเงินสดจำนวนหนึ่งสำหรับลูกค้าที่ชื่อว่า "utò"  สมมติฐานระบุว่ามีชื่อลูกค้าชื่อ "<unk>utty"  แม้ว่าชื่อจะคล้ายกันและอาจเป็นคนเดียวกันก็ได้  แต่หลักฐานไม่ได้ยืนยันหรือปฏิเสธสมมติฐานโดยตรง  หลักฐานจึงเกี่ยวข้องกับสมมติฐานในระดับหนึ่ง\n', '2\n', '2\n', '2\n', '2\n', '2\n', '0\n', '0\n', '2\n', '2\n', 'ไม่สามารถระบุความสัมพันธ์ได้อย่างชัดเจนระหว่างข้อความที่ให้มาและสมมติฐานใด ๆ เนื่องจากข้อความนั้นไม่สมบูรณ์และขาดบริบท  ดังนั้นจึงไม่สามารถให้คำตอบได้ว่าเป็น 0, 1 หรือ 2  จำเป็นต้องมีข้อมูลเพิ่มเติมเพื่อประเมินความสัมพันธ์ระหว่างข้อความและสมมติฐาน\n', '2\n', '2\n', '2\n', '0\n', '2\n', '2\n', '1\n', '2\n', '0\n', '2\nหลักฐานและสมมติฐานไม่เกี่ยวข้องกัน  หลักฐานพูดถึงการรั่วของรังสีจากเชื้อเพลิงที่ละลายเป็นตะกั่วในเครื่องบินที่ถูกไฟไหม้  ในขณะที่สมมติฐานพูดถึงการควบคุมรังสีในระหว่างการยิง  ไม่มีความเชื่อมโยงโดยตรงระหว่างสถานการณ์ทั้งสอง\n', '2\n', '2\nหลักฐานระบุว่าการหลอมละลายของตะกั่วอาจทำให้รังสีรั่วไหลออกมาขณะที่กำลังยิง ซึ่งขัดแย้งกับสมมติฐานที่ว่ารังสีจะไม่รั่วไหลขณะกำลังยิง\n', 'คำตอบคือ 1\n', '0\n', '0\n', '0\n', '0\n', '2\n', 'คำตอบคือ 1\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานบ่งชี้ว่ามีการฝึกอบรมเกี่ยวกับชุดความดันสูงอยู่แล้ว ดังนั้นจึงสนับสนุนสมมติฐานที่ว่าจะมีการสวมใส่ชุดความดันสูงภายในสิ้นปี\n', 'คำตอบคือ 1\n', '2\n', '2\n', 'หลักฐานที่ให้มานั้นไม่เพียงพอที่จะระบุได้ว่าเกี่ยวข้องหรือขัดแย้งกับสมมติฐาน อย่างไรก็ตาม เนื่องจากหลักฐานไม่ได้ให้ข้อมูลใดๆ เกี่ยวกับสมมติฐาน ฉันจะตอบ 0\n', 'คำตอบคือ 1\n', '0\n', '2\n', '0\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าสัตว์ถูกล็อคเมื่อเรามีสมมติฐานของเรา  หลักฐานนี้ไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานโดยตรง มันเป็นเพียงข้อสังเกตที่เป็นกลาง  เราต้องการข้อมูลเพิ่มเติมเพื่อประเมินความสัมพันธ์ระหว่างหลักฐานกับสมมติฐาน  ดังนั้นจึงไม่มีความเกี่ยวข้องหรือความขัดแย้ง\n', '2\n', '0\n', 'คำตอบคือ 2\n', '0\n', '0\n', '2\n', '0\n', 'คำตอบคือ 2\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n', "คำตอบคือ 0 (มีความเกี่ยวข้อง)\n\nหลักฐานระบุว่า Ramon ยืนอยู่ตรงนั้น ในขณะที่สมมติฐานกล่าวถึง 'youamonath' ที่ยืนอยู่  แม้ว่าชื่อและรายละเอียดจะต่างกัน แต่หลักฐานและสมมติฐานมีส่วนร่วมกันที่เกี่ยวข้องกับบุคคลที่ยืนอยู่ ดังนั้นจึงมีความเกี่ยวข้องกัน\n", '2\n', '2\n', '0\n', 'คำตอบคือ 0\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าพวกเขาไม่เคยบอกสถานที่ที่พวกเขาจะไปเมื่อพวกเขาออกจากที่หนึ่งไปอีกที่หนึ่ง  สมมติฐานก็ระบุสิ่งเดียวกัน  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐาน\n', '2\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานกล่าวถึงการปิดล้อมของประธานาธิบดีเคนเนดี้ในคิวบาและเรือรัสเซียที่มุ่งหน้าสู่คิวบาซึ่งสอดคล้องกับการค้นพบขีปนาวุธ 20 ลูกในสมมติฐาน  การปิดล้อมและเรือรัสเซียเป็นเหตุผลสำคัญที่นำไปสู่การค้นพบขีปนาวุธ\n', '0\n', '0\n', '2\n', '0\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานอธิบายถึงการใช้ร่มชูชีพเพื่อทำให้เกิดการกระแทกที่เพียงพอที่จะทำให้เกิดการระเบิด ซึ่งสอดคล้องกับสมมติฐานที่ว่าต้องการแรงกระแทกเพียงเล็กน้อยเพื่อจุดชนวนขีปนาวุธนิวเคลียร์', '0\n', '0\n', '0\n', '2\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐานที่ว่าชุดมีความคล้ายคลึงกับชุดนักบินอวกาศ', 'คำตอบคือ 0\n\nหลักฐานระบุว่าชุดสูททำจากเงินทั้งหมด  สมมติฐานระบุว่าชุดสูทสามารถเลือกสีได้  ทั้งสองข้อความนี้ไม่ขัดแย้งกันหรือสนับสนุนกันโดยตรง  พวกมันพูดถึงแง่มุมที่ต่างกันของชุดสูท (วัสดุ vs. สี)  ดังนั้นจึงไม่เกี่ยวข้องกัน\n', '2\n', '2\n', '0\n', '1\n', 'คำตอบคือ 0\n\nหลักฐานกล่าวถึงการฝึกนักบินจำนวนมาก (30 หรือ 40 เครื่องบิน) โดยมีพันธมิตรอังกฤษเข้ามาเกี่ยวข้อง สมมติฐานระบุจำนวนสัปดาห์ในการฝึก (5 สัปดาห์) ซึ่งไม่ขัดแย้งกับหลักฐาน แต่ก็ไม่สนับสนุนโดยตรงเช่นกัน หลักฐานและสมมติฐานมีความเกี่ยวข้องกันในแง่ที่ว่าทั้งสองอย่างนี้เกี่ยวข้องกับการฝึกฝนการบินร่วมกับพันธมิตรอังกฤษ แต่หลักฐานไม่ได้รับรองหรือหักล้างสมมติฐานโดยตรง\n', '1\n', '2\n', '2\n', '2\n', '0\n', '2\n', '0\n', 'คำตอบคือ **0**\n\nหลักฐานทั้งสองชิ้นแสดงให้เห็นว่าทั้งสองคนไม่ค่อยอ่านหนังสือ  แต่ไม่ได้สนับสนุนหรือขัดแย้งกันโดยตรง  จึงไม่มีความเกี่ยวข้องหรือขัดแย้งกัน\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่า "ฉันไม่เคยอ่านหนังสือใดเลย" ในขณะที่สมมติฐานระบุว่า "ฉันไม่ได้อ่านหนังสือมากมาย"  หลักฐานเป็นข้อความที่แข็งแกร่งกว่าและขัดแย้งกับสมมติฐานที่อ่อนกว่า\n', '2\n', '2\n', '2\n', '2\n', '2\n', '0\n', '0\n', '2\n', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานอธิบายกระบวนการที่ซับซ้อนและอาจเป็นอันตรายซึ่งเกี่ยวข้องกับการบิน และความยากลำบากในการผ่านการทดสอบก่อนที่จะบินได้  สิ่งนี้ขัดแย้งกับสมมติฐานที่ว่าผู้คนส่วนใหญ่ไม่ผ่านการทดสอบหรือไม่เคยได้บิน เพราะมันแสดงให้เห็นว่ามีกระบวนการที่เข้มงวดและยากที่จะผ่านก่อนจะได้บิน  หลักฐานบ่งชี้ว่าการบินอาจจะไม่ง่ายอย่างที่สมมติฐานคิด\n', 'คำตอบคือ 0\n\nหลักฐานทั้งสองชิ้นแสดงให้เห็นถึงความต้องการการฝึกฝนและความพร้อมก่อนเริ่มต้นภารกิจ (ผ่านห้องชั้นสูงและการฝึกฝนก่อนบิน)  นี่สนับสนุนสมมติฐานว่ามีความต้องการเตรียมตัวก่อนที่จะเริ่มกิจกรรมที่สำคัญ  มันไม่ขัดแย้งกัน  แต่ก็ไม่ได้พิสูจน์หรือปฏิเสธโดยตรงเช่นกัน\n', '2\n', 'คำตอบคือ 0\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ามีบางสิ่งที่สามารถพิสูจน์ได้ สมมติฐานระบุว่าไม่มีอะไรที่ใครก็ตามสามารถพิสูจน์ได้  ทั้งสองข้อความนี้ขัดแย้งกัน\n', 'คำตอบคือ 1\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าน้องสาวของเธอได้พูดกับเธอทุกวันเกี่ยวกับพฤติกรรมของเธอ หลักฐานนี้ขัดแย้งกับสมมติฐานที่ระบุว่าน้องสาวของเธอไม่ได้ทำอะไรถูกต้องเลย  เพราะอย่างน้อยน้องสาวก็พยายามที่จะชี้นำพฤติกรรมของเธอ\n', '1\n', 'คำตอบคือ 0\n', '0\n', 'คำตอบคือ 1\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้พูดอยู่ที่นั่นในตอนเช้า สมมติฐานระบุว่าผู้พูดไม่ได้อยู่ที่นั่นในวันนี้ ข้อความเหล่านี้ขัดแย้งกัน', '0\n', '2\n', '2\n', '2\n', '0\n', 'คำตอบคือ **2** (ความขัดแย้ง)\n\nหลักฐานแสดงให้เห็นว่าบุคคลนั้นหิวและกำลังจะไปทานอาหารกลางวัน  ซึ่งบ่งบอกว่าพวกเขามีความไม่รู้อาหารอยู่บ้าง (อย่างน้อยก็ความรู้เกี่ยวกับความหิวและความต้องการอาหาร)  ตรงกันข้ามกับสมมติฐานที่ว่าพวกเขาไม่มีความไม่รู้อาหารเลยสักนิด\n', '2\n', '0\n', '0\n', '1\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1888  (หรืออาจมีการพิมพ์ผิดเป็น 18849) ซึ่งสอดคล้องกับสมมติฐานที่ว่าบุคคลนั้นเกิดก่อนปี ค.ศ. 20040  เนื่องจาก 1888 นั้นก่อนปี ค.ศ. 20040 อย่างแน่นอน\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1986 หรือ 1987 ข้อเท็จจริงที่อ้างถึง 1880 และ 20039 ไม่เกี่ยวข้องกัน สมมติฐานระบุว่าบุคคลนั้นไม่ได้เกิดก่อนปี 1984 หลักฐานขัดแย้งกับสมมติฐานเนื่องจากระบุถึงปีเกิดที่เกิดขึ้นหลังปี 1984\n', '1\n', '2\n', '0\n', '1\n', 'คำตอบคือ 0\n\nหลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานว่าผู้พูดไม่เคยไปเท็กซัส  ข้อความกล่าวถึงสถานที่ต่างๆ ที่ดูเหมือนจะไม่ใช่เท็กซัส แต่ไม่ได้ระบุว่าเป็นเท็กซัสหรือไม่  จึงไม่สามารถสรุปอะไรได้จากหลักฐานที่มี\n', '2\nหลักฐานกล่าวถึงฐานทัพอากาศสหรัฐฯและริโอเท็กซัส แต่สมมติฐานพูดถึงเกาหลี  สถานที่และเวลาไม่ตรงกัน  จึงขัดแย้งกัน\n', 'คำตอบคือ 0.\n\nหลักฐานระบุว่าเหลือแชมเปญไว้บ้าง แต่ไม่ได้บอกว่าเหลือเท่าไหร่  สมมติฐานบอกว่าเด็กดื่มไปสามขวด  หลักฐานไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐานโดยตรง  มันไม่เกี่ยวข้องกัน\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าบางคนไม่ได้ดื่มแชมเปญ และเด็กๆ ได้ดื่มแชมเปญที่เหลืออยู่ สมมติฐานระบุว่าเด็กๆ ได้แชมเปญไปบ้าง หลักฐานสนับสนุนสมมติฐาน แต่ไม่ได้พิสูจน์มันอย่างเด็ดขาด', '1\n', '2\n', 'คำตอบคือ **1**\n\nหลักฐาน ("เรื่องเล่ามากมายเกี่ยวกับวงการทหาร") สนับสนุนสมมติฐาน ("มีเรื่องราวมากมายที่ว่างเปล่า")  เพราะเรื่องเล่ามักจะเต็มไปด้วยช่องว่าง ความไม่ชัดเจน และการตีความที่แตกต่างกัน  ดังนั้นหลักฐานจึงสนับสนุนสมมติฐานโดยปริยาย  ไม่ใช่การขัดแย้งโดยตรง\n', '2\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n', '2\nหลักฐานระบุว่าการทดสอบเครื่องบินทำให้ผู้เขียนเรียนรู้สิ่งต่างๆ  สมมติฐานกล่าวว่าการทดสอบเครื่องบินสอนผู้เขียนหลายสิ่งหลายอย่าง  หลักฐานและสมมติฐานมีความสัมพันธ์กันแต่ไม่ใช่หลักฐานที่แข็งแกร่ง  ดังนั้นคำตอบจึงเป็น 2 (ความขัดแย้ง)\n', '2\nหลักฐานและสมมติฐานนั้นไม่เกี่ยวข้องกัน  หลักฐานเกี่ยวกับการมีชีวิตและการเรียนรู้ของมนุษย์  ในขณะที่สมมติฐานนั้นเกี่ยวกับการทดสอบเครื่องบินและการจัดการแรงดัน  ไม่มีความเกี่ยวข้องกันระหว่างกัน\n', '2\n', 'คำตอบคือ 1\n', '0\n', '2\nหลักฐานระบุว่า Rudolph Anderson ถูกยิงตาย ขณะที่สมมติฐานระบุว่าทุกคนรอดชีวิตโดยไม่ถูกยิง  นี่จึงเป็นความขัดแย้งกัน\n', '2\n']
Saved predictions to: predicted_5.json
Accuracy th: 0.425
'XNLI' object has no attribute 'evaluate_results'
