README.md:   0%|          | 0.00/20.8k [00:00<?, ?B/s]README.md: 100%|##########| 20.8k/20.8k [00:00<00:00, 111MB/s]
train-00000-of-00001.parquet:   0%|          | 0.00/50.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  63%|######2   | 31.5M/50.2M [00:00<00:00, 311MB/s]train-00000-of-00001.parquet: 100%|##########| 50.2M/50.2M [00:00<00:00, 310MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 308k/308k [00:00<00:00, 353MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 157k/157k [00:00<00:00, 167MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  32%|###1      | 124000/392702 [00:00<00:00, 1229503.95 examples/s]Generating train split:  64%|######4   | 253000/392702 [00:00<00:00, 1258022.98 examples/s]Generating train split:  98%|#########7| 384000/392702 [00:00<00:00, 1273597.27 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1263307.41 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1177884.70 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 976057.66 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 326kB/s]
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|##########| 570/570 [00:00<00:00, 4.21MB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|##########| 232k/232k [00:00<00:00, 42.2MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 466k/466k [00:00<00:00, 55.4MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/440M [00:00<00:01, 239MB/s]model.safetensors:  17%|#6        | 73.4M/440M [00:00<00:01, 287MB/s]model.safetensors:  24%|##3       | 105M/440M [00:00<00:01, 293MB/s] model.safetensors:  33%|###3      | 147M/440M [00:00<00:00, 305MB/s]model.safetensors:  43%|####2     | 189M/440M [00:00<00:00, 316MB/s]model.safetensors:  52%|#####2    | 231M/440M [00:00<00:00, 322MB/s]model.safetensors:  62%|######1   | 273M/440M [00:00<00:00, 326MB/s]model.safetensors:  71%|#######1  | 315M/440M [00:01<00:00, 327MB/s]model.safetensors:  81%|########  | 357M/440M [00:01<00:00, 323MB/s]model.safetensors:  90%|######### | 398M/440M [00:01<00:00, 326MB/s]model.safetensors: 100%|#########9| 440M/440M [00:01<00:00, 325MB/s]model.safetensors: 100%|##########| 440M/440M [00:01<00:00, 315MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '0\n', '1\n', '0\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '2\n', '2\n', '1\n', '1\n', '2\n', '1\n', '0\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 2
Accuracy en: 0.47474747474747475
train-00000-of-00001.parquet:   0%|          | 0.00/73.8M [00:00<?, ?B/s]train-00000-of-00001.parquet:  43%|####2     | 31.5M/73.8M [00:00<00:00, 239MB/s]train-00000-of-00001.parquet:  85%|########5 | 62.9M/73.8M [00:00<00:00, 251MB/s]train-00000-of-00001.parquet: 100%|##########| 73.8M/73.8M [00:00<00:00, 252MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/490k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 490k/490k [00:00<00:00, 214MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/247k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 247k/247k [00:00<00:00, 422MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  24%|##3       | 94000/392702 [00:00<00:00, 924431.71 examples/s]Generating train split:  48%|####8     | 189000/392702 [00:00<00:00, 929681.94 examples/s]Generating train split:  73%|#######2  | 286000/392702 [00:00<00:00, 942126.25 examples/s]Generating train split:  97%|#########7| 382000/392702 [00:00<00:00, 947107.62 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 941044.21 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1000069.63 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 864339.73 examples/s]
tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 2.00/2.00 [00:00<00:00, 19.3kB/s]
config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]config.json: 100%|##########| 459/459 [00:00<00:00, 3.61MB/s]
vocab.txt:   0%|          | 0.00/530k [00:00<?, ?B/s]vocab.txt: 100%|##########| 530k/530k [00:00<00:00, 20.2MB/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 112/112 [00:00<00:00, 981kB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]pytorch_model.bin:   7%|6         | 31.5M/454M [00:00<00:01, 235MB/s]pytorch_model.bin:  14%|#3        | 62.9M/454M [00:00<00:01, 272MB/s]pytorch_model.bin:  21%|##        | 94.4M/454M [00:00<00:01, 283MB/s]pytorch_model.bin:  28%|##7       | 126M/454M [00:00<00:01, 289MB/s] pytorch_model.bin:  35%|###4      | 157M/454M [00:00<00:01, 291MB/s]pytorch_model.bin:  42%|####1     | 189M/454M [00:00<00:00, 285MB/s]pytorch_model.bin:  51%|#####     | 231M/454M [00:00<00:00, 302MB/s]pytorch_model.bin:  58%|#####7    | 262M/454M [00:00<00:00, 287MB/s]pytorch_model.bin:  65%|######4   | 294M/454M [00:01<00:00, 287MB/s]pytorch_model.bin:  72%|#######1  | 325M/454M [00:01<00:00, 285MB/s]pytorch_model.bin:  78%|#######8  | 357M/454M [00:01<00:00, 289MB/s]pytorch_model.bin:  85%|########5 | 388M/454M [00:01<00:00, 282MB/s]pytorch_model.bin:  92%|#########2| 419M/454M [00:01<00:00, 269MB/s]pytorch_model.bin:  99%|#########9| 451M/454M [00:01<00:00, 280MB/s]pytorch_model.bin: 100%|##########| 454M/454M [00:01<00:00, 282MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', None, '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '2\n', None, '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', 'Η απάντηση είναι **0**.  Η υπόθεση (κάλεσα τον αριθμό φτάνοντας στο σπίτι της) υποστηρίζεται άμεσα από το κείμενο.\n', '2\n', None, '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', None, None, '0\n', '0\n', '2\n', '0\n', '2\n', None, '0\n', '2\n', '2\n', '1\n', '1\n', None, '1\n', '1\n', '2\n', '1\n', '1\n', None, '2\n', '1\n', '1\n', '1\n', '1\n', None, '2\n', '0\n']
Saved predictions to: predicted_1.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 11
Accuracy el: 0.48677248677248675
train-00000-of-00001.parquet:   0%|          | 0.00/65.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  48%|####8     | 31.5M/65.4M [00:00<00:00, 253MB/s]train-00000-of-00001.parquet:  96%|#########6| 62.9M/65.4M [00:00<00:00, 268MB/s]train-00000-of-00001.parquet: 100%|##########| 65.4M/65.4M [00:00<00:00, 263MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/447k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 447k/447k [00:00<00:00, 156MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 223k/223k [00:00<00:00, 386MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  25%|##4       | 97000/392702 [00:00<00:00, 960304.69 examples/s]Generating train split:  50%|#####     | 197000/392702 [00:00<00:00, 977304.51 examples/s]Generating train split:  76%|#######5  | 298000/392702 [00:00<00:00, 988249.88 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 984462.19 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 978690.47 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 870100.55 examples/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 48.0/48.0 [00:00<00:00, 399kB/s]
config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]config.json: 100%|##########| 625/625 [00:00<00:00, 4.74MB/s]
vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]vocab.txt: 100%|##########| 872k/872k [00:00<00:00, 39.6MB/s]
tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.72M/1.72M [00:00<00:00, 59.1MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]model.safetensors:   5%|4         | 31.5M/672M [00:00<00:02, 239MB/s]model.safetensors:   9%|9         | 62.9M/672M [00:00<00:02, 265MB/s]model.safetensors:  14%|#4        | 94.4M/672M [00:00<00:02, 273MB/s]model.safetensors:  19%|#8        | 126M/672M [00:00<00:01, 283MB/s] model.safetensors:  23%|##3       | 157M/672M [00:00<00:01, 275MB/s]model.safetensors:  28%|##8       | 189M/672M [00:00<00:01, 282MB/s]model.safetensors:  33%|###2      | 220M/672M [00:00<00:01, 291MB/s]model.safetensors:  37%|###7      | 252M/672M [00:00<00:01, 294MB/s]model.safetensors:  42%|####2     | 283M/672M [00:01<00:01, 283MB/s]model.safetensors:  47%|####6     | 315M/672M [00:01<00:01, 281MB/s]model.safetensors:  53%|#####3    | 357M/672M [00:01<00:01, 293MB/s]model.safetensors:  58%|#####7    | 388M/672M [00:01<00:00, 287MB/s]model.safetensors:  62%|######2   | 419M/672M [00:01<00:00, 291MB/s]model.safetensors:  67%|######7   | 451M/672M [00:01<00:00, 297MB/s]model.safetensors:  72%|#######1  | 482M/672M [00:01<00:00, 301MB/s]model.safetensors:  76%|#######6  | 514M/672M [00:01<00:00, 302MB/s]model.safetensors:  81%|########1 | 545M/672M [00:01<00:00, 304MB/s]model.safetensors:  87%|########7 | 587M/672M [00:02<00:00, 309MB/s]model.safetensors:  94%|#########3| 629M/672M [00:02<00:00, 310MB/s]model.safetensors:  98%|#########8| 661M/672M [00:02<00:00, 310MB/s]model.safetensors: 100%|##########| 672M/672M [00:02<00:00, 293MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '0\n', '2\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '2\n', '0\n', '2\n', '1\n', '0\n', '1\n', '0\n', '1\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '0\n', '1\n', '0\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '1\n', '2\n', '1\n', '1\n', '2\n', '2\n', '2\n', '2\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n']
Saved predictions to: predicted_2.json
Accuracy bg: 0.415
train-00000-of-00001.parquet:   0%|          | 0.00/53.2M [00:00<?, ?B/s]train-00000-of-00001.parquet:  59%|#####9    | 31.5M/53.2M [00:00<00:00, 262MB/s]train-00000-of-00001.parquet: 100%|##########| 53.2M/53.2M [00:00<00:00, 278MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 342k/342k [00:00<00:00, 109MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/173k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 173k/173k [00:00<00:00, 369MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###1      | 123000/392702 [00:00<00:00, 1218327.10 examples/s]Generating train split:  63%|######2   | 247000/392702 [00:00<00:00, 1226858.34 examples/s]Generating train split:  94%|#########4| 370000/392702 [00:00<00:00, 1224637.26 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1221303.04 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1126304.50 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 990686.49 examples/s]
tokenizer_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 310/310 [00:00<00:00, 2.45MB/s]
config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]config.json: 100%|##########| 650/650 [00:00<00:00, 6.14MB/s]
vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]vocab.txt: 100%|##########| 248k/248k [00:00<00:00, 11.9MB/s]
tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]tokenizer.json: 100%|##########| 486k/486k [00:00<00:00, 15.8MB/s]
special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]special_tokens_map.json: 100%|##########| 134/134 [00:00<00:00, 1.17MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]pytorch_model.bin:   7%|7         | 31.5M/440M [00:00<00:01, 243MB/s]pytorch_model.bin:  14%|#4        | 62.9M/440M [00:00<00:01, 265MB/s]pytorch_model.bin:  21%|##1       | 94.4M/440M [00:00<00:01, 243MB/s]pytorch_model.bin:  29%|##8       | 126M/440M [00:00<00:01, 205MB/s] pytorch_model.bin:  36%|###5      | 157M/440M [00:00<00:01, 221MB/s]pytorch_model.bin:  43%|####2     | 189M/440M [00:00<00:01, 236MB/s]pytorch_model.bin:  50%|#####     | 220M/440M [00:00<00:00, 250MB/s]pytorch_model.bin:  57%|#####7    | 252M/440M [00:01<00:00, 258MB/s]pytorch_model.bin:  64%|######4   | 283M/440M [00:01<00:00, 254MB/s]pytorch_model.bin:  72%|#######1  | 315M/440M [00:01<00:00, 257MB/s]pytorch_model.bin:  79%|#######8  | 346M/440M [00:01<00:00, 261MB/s]pytorch_model.bin:  86%|########5 | 377M/440M [00:01<00:00, 261MB/s]pytorch_model.bin:  93%|#########3| 409M/440M [00:01<00:00, 264MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 241MB/s]pytorch_model.bin: 100%|##########| 440M/440M [00:01<00:00, 245MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
Error occurred: 429 Resource has been exhausted (e.g. check quota).. Retrying after 60 seconds...
['2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', None, '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', None, '1\n', '0\n', '0\n', '1\n', '0\n', None, '1\n', '2\n', '0\n', '2\n', '1\n', None, '1\n', '1\n', '1\n', '0\n', '2\n', None, '1\n', '1\n', '1\n', '0\n', '1\n', None, '1\n', '1\n', '1\n', '1\n']
Saved predictions to: predicted_3.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 8
Accuracy es: 0.484375
train-00000-of-00001.parquet:   0%|          | 0.00/55.4M [00:00<?, ?B/s]train-00000-of-00001.parquet:  57%|#####6    | 31.5M/55.4M [00:00<00:00, 226MB/s]train-00000-of-00001.parquet: 100%|##########| 55.4M/55.4M [00:00<00:00, 242MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/360k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 360k/360k [00:00<00:00, 105MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 183k/183k [00:00<00:00, 357MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  31%|###1      | 122000/392702 [00:00<00:00, 1211623.82 examples/s]Generating train split:  63%|######3   | 248000/392702 [00:00<00:00, 1235991.89 examples/s]Generating train split:  95%|#########4| 372000/392702 [00:00<00:00, 1233445.42 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 1230153.50 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 1171514.92 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 1032916.32 examples/s]
tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 25.0/25.0 [00:00<00:00, 170kB/s]
config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]config.json: 100%|##########| 508/508 [00:00<00:00, 4.04MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 811k/811k [00:00<00:00, 29.9MB/s]
tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]tokenizer.json: 100%|##########| 1.40M/1.40M [00:00<00:00, 18.0MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]model.safetensors:   9%|9         | 41.9M/445M [00:00<00:01, 330MB/s]model.safetensors:  19%|#8        | 83.9M/445M [00:00<00:01, 329MB/s]model.safetensors:  28%|##8       | 126M/445M [00:00<00:00, 332MB/s] model.safetensors:  38%|###7      | 168M/445M [00:00<00:00, 330MB/s]model.safetensors:  47%|####7     | 210M/445M [00:00<00:00, 331MB/s]model.safetensors:  57%|#####6    | 252M/445M [00:00<00:00, 330MB/s]model.safetensors:  66%|######5   | 294M/445M [00:00<00:00, 325MB/s]model.safetensors:  75%|#######5  | 336M/445M [00:01<00:00, 323MB/s]model.safetensors:  85%|########4 | 377M/445M [00:01<00:00, 321MB/s]model.safetensors:  94%|#########4| 419M/445M [00:01<00:00, 325MB/s]model.safetensors: 100%|##########| 445M/445M [00:01<00:00, 326MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['0\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '1\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '2\n', '0\n', '2\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '2\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '0\n', '2\n', '1\n', '1\n', '0\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '2\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n', '0\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '1\n', '0\n', '0\n', '0\n', '0\n', '0\n', '2\n', '2\n', '2\n', '0\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '1\n', '1\n', '1\n', '1\n', '0\n', '1\n', '1\n', '1\n', '1\n', '2\n', '0\n']
Saved predictions to: predicted_4.json
Accuracy fr: 0.43
train-00000-of-00001.parquet:   0%|          | 0.00/76.5M [00:00<?, ?B/s]train-00000-of-00001.parquet:  27%|##7       | 21.0M/76.5M [00:00<00:00, 156MB/s]train-00000-of-00001.parquet:  69%|######8   | 52.4M/76.5M [00:00<00:00, 207MB/s]train-00000-of-00001.parquet: 100%|##########| 76.5M/76.5M [00:00<00:00, 223MB/s]
test-00000-of-00001.parquet:   0%|          | 0.00/503k [00:00<?, ?B/s]test-00000-of-00001.parquet: 100%|##########| 503k/503k [00:00<00:00, 167MB/s]
validation-00000-of-00001.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]validation-00000-of-00001.parquet: 100%|##########| 252k/252k [00:00<00:00, 383MB/s]
Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]Generating train split:  22%|##1       | 85000/392702 [00:00<00:00, 840102.17 examples/s]Generating train split:  44%|####4     | 173000/392702 [00:00<00:00, 854388.78 examples/s]Generating train split:  75%|#######4  | 293000/392702 [00:00<00:00, 821085.28 examples/s]Generating train split:  97%|#########7| 381000/392702 [00:00<00:00, 837310.89 examples/s]Generating train split: 100%|##########| 392702/392702 [00:00<00:00, 836128.23 examples/s]
Generating test split:   0%|          | 0/5010 [00:00<?, ? examples/s]Generating test split: 100%|##########| 5010/5010 [00:00<00:00, 921966.61 examples/s]
Generating validation split:   0%|          | 0/2490 [00:00<?, ? examples/s]Generating validation split: 100%|##########| 2490/2490 [00:00<00:00, 825467.67 examples/s]
tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]tokenizer_config.json: 100%|##########| 282/282 [00:00<00:00, 2.24MB/s]
config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]config.json: 100%|##########| 546/546 [00:00<00:00, 4.10MB/s]
sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]sentencepiece.bpe.model: 100%|##########| 905k/905k [00:00<00:00, 17.5MB/s]
/opt/hostedtoolcache/Python/3.11.11/x64/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
model.safetensors:   0%|          | 0.00/423M [00:00<?, ?B/s]model.safetensors:   7%|7         | 31.5M/423M [00:00<00:01, 250MB/s]model.safetensors:  15%|#4        | 62.9M/423M [00:00<00:01, 276MB/s]model.safetensors:  22%|##2       | 94.4M/423M [00:00<00:01, 279MB/s]model.safetensors:  32%|###2      | 136M/423M [00:00<00:00, 295MB/s] model.safetensors:  40%|###9      | 168M/423M [00:00<00:00, 299MB/s]model.safetensors:  50%|####9     | 210M/423M [00:00<00:00, 309MB/s]model.safetensors:  57%|#####6    | 241M/423M [00:00<00:00, 304MB/s]model.safetensors:  64%|######4   | 273M/423M [00:00<00:00, 303MB/s]model.safetensors:  72%|#######1  | 304M/423M [00:01<00:00, 306MB/s]model.safetensors:  79%|#######9  | 336M/423M [00:01<00:00, 307MB/s]model.safetensors:  89%|########9 | 377M/423M [00:01<00:00, 315MB/s]model.safetensors:  97%|#########6| 409M/423M [00:01<00:00, 310MB/s]model.safetensors: 100%|##########| 423M/423M [00:01<00:00, 300MB/s]
Attack entry stored in: output/attacks/attack.txt
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
Reached request limit (15 per minute). Sleeping for 60 seconds...
['2\n', '1\n', 'คำตอบคือ **1**\n\nหลักฐานแสดงให้เห็นถึงการมีปฏิสัมพันธ์ในเชิงบวกกับบุคคล ("พวกเราคุยกันได้ถูกคอจริงๆ") ซึ่งสนับสนุนสมมติฐานที่ว่าการสนทนามีความสัมพันธ์ที่ดี  สัญลักษณ์พิเศษอื่นๆ ในหลักฐานไม่สำคัญต่อการประเมินความสัมพันธ์ของการสนทนา\n', 'คำตอบคือ 0 (เข้ากันได้)\n\nหลักฐานกล่าวถึงสถานการณ์ที่ตัวพูดเป็นส่วนหนึ่งของกองกำลังทางอากาศและสันนิษฐานว่าพวกเขาไม่ใช่คนเดียวที่อยู่บนฟาร์มนั้น หลักฐานนี้ไม่ขัดแย้งกับสมมติฐานที่ว่ามีคนอื่นอยู่บนฟาร์ม  ในความเป็นจริง มันดูเหมือนจะสนับสนุนสมมติฐานนั้นโดยการบอกเป็นนัยว่ามีคนอื่นอยู่ด้วย\n', '2\n', '2\n', '0\n', '2\n', '0\n', '2\n', '1\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าไม่มีวิธีที่จะปล่อยระเบิดไฮโดรเจน 20 oลง n, a <unk><unk>\x99 ได้m และพวกเขาไม่สนใจที่จะปกป้องอะไรเลย ซึ่งขัดแย้งกับสมมติฐานใดๆ ที่อาจระบุว่ามีวิธีการปล่อยระเบิดหรือมีสิ่งที่ต้องได้รับการปกป้อง\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่ามีการเก็บสิ่งของไว้เนื่องจากไม่สามารถทิ้งได้  นี่แสดงให้เห็นถึงความยากลำบากในการจัดการกับสิ่งของนั้น ซึ่งสอดคล้องกับสมมติฐานที่ว่าการจัดการกับระเบิดไฮโดรเจนนั้นทำได้ยากมาก\n', '2\n', '0\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่า Annie Lono เติบโตขึ้นมาใน Augusta และมีบางอย่างเกิดขึ้นในวัยเด็กของเธอ สมมติฐานระบุว่า Annie Lono ไม่สามารถพูดคุยเกี่ยวกับเรื่องราวในวันนี้ หลักฐานไม่สนับสนุนหรือขัดแย้งกับสมมติฐานโดยตรง  มันแค่ให้ข้อมูลพื้นฐานเกี่ยวกับ Annie Lono เท่านั้น  จึงไม่สามารถสรุปความเกี่ยวข้องหรือความขัดแย้งได้อย่างชัดเจน\n', '0\n', '0\n', '2\nหลักฐานไม่เกี่ยวข้องกับสมมติฐาน  หลักฐานกล่าวถึงการนำ "ห้ากอง" ออกจากญี่ปุ่นในปี 2562 ในขณะที่สมมติฐานนั้นไม่ชัดเจนและมี <unk>  จึงไม่สามารถประเมินความเกี่ยวข้องได้  ดังนั้นจึงตอบ 2 (ความขัดแย้ง)  เพราะไม่มีข้อมูลเพียงพอที่จะเชื่อมโยงทั้งสอง\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าผู้พูดไม่ได้ติดต่อกับสิ่งที่ถูกอ้างถึงในสมมติฐาน  นี่หมายความว่าหลักฐานสนับสนุนสมมติฐาน  ดังนั้นจึงเป็นการร่วมกัน  \n', 'ฉันไม่สามารถตอบคำถามนี้ได้ เพราะหลักฐานไม่สมบูรณ์และฉันไม่เข้าใจความหมายของมัน  ฉันต้องการข้อมูลเพิ่มเติมเกี่ยวกับสมมติฐานเพื่อที่จะประเมินความสัมพันธ์ระหว่างหลักฐานและสมมติฐานได้\n', '2\nหลักฐานกล่าวถึงแม่เป็นเพียงคนเดียวที่เรียกใช้หน่วยควบคุมการทดสอบ  สมมติฐานกล่าวถึงบุคคลเพียงคนเดียวที่ดำเนินนโยบายกับข้อสอบ  ทั้งสองประโยคไม่เกี่ยวข้องกันโดยตรง  ไม่มีความสัมพันธ์ที่ชัดเจนระหว่างการทดสอบและนโยบายข้อสอบ  จึงถือว่าขัดแย้งกัน\n', '0\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานที่ให้มา (ยศพันจ่าอากาศเอกและการเกษียณอายุ) ไม่ได้สนับสนุนหรือขัดแย้งกับสมมติฐาน (เกษียณตั้งแต่ปี 2002)  หลักฐานระบุว่าบุคคลนั้นเกษียณแล้ว แต่ไม่ได้ระบุปีที่เกษียณ  ดังนั้นจึงไม่มีความเกี่ยวข้องหรือความขัดแย้ง\n', '1\n', '0\n', '0\n', '2\n', 'คำตอบคือ 0\n', 'คำตอบคือ **2** (ความขัดแย้ง)\n\nหลักฐานระบุว่ามีผู้หญิง 9 คนที่จะช่วยเหลือได้ใน 9 เมืองที่แตกต่างกัน  สมมติฐานกล่าวว่าศูนย์กลางที่จะช่วยเหลืออยู่ห่างออกไป 5 ไมล์  ข้อมูลนี้ไม่เกี่ยวข้องกันและขัดแย้งกัน  จำนวนเมืองและระยะทางไม่ใช่ข้อมูลที่สามารถเชื่อมโยงกันได้\n', '2\n', '1\n', '1\n', 'คำตอบคือ 0\n\nหลักฐานแสดงให้เห็นว่ามีการระบุตัวบุคคลแล้วว่าใครจะทำงานอะไร ซึ่งขัดแย้งกับสมมติฐานที่ว่าพวกเขาไม่สามารถตัดสินใจได้ว่าใครควรทำงานอะไร', '2\n', '2\n', '2\n', '0\n', '2\n', '0\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่ามีข้อมูลบางอย่างจาก "th" ที่ใช้ไปแล้ว  และไม่รู้ว่า hondrov <unk>❤mikov<unk> ตอบอะไร  ซึ่งสอดคล้องกับสมมติฐานที่ว่าไม่มีวีดีโอ จึงสามารถเดาได้เท่านั้น  หลักฐานไม่ขัดแย้งกับสมมติฐาน  แต่ก็ไม่ได้สนับสนุนสมมติฐานโดยตรง  จึงเลือก 1  ซึ่งหมายถึงทั้งสองอย่างมีความเกี่ยวข้องกันแต่ไม่ใช่การสนับสนุนหรือขัดแย้งโดยตรง\n', '0\n', '2\n', '0\n', '2\nหลักฐานกล่าวถึงความเสียหายจากไฟไหม้ที่อาจทำให้รังสีรั่วไหล  ซึ่งขัดแย้งกับสมมติฐานที่ว่ารังสีนิวเคลียร์ถูกควบคุมไว้แล้ว\n', '0\nหลักฐานกล่าวถึงความเป็นไปได้ที่ส่วนประกอบตะกั่วเป็นสาเหตุของการรั่วไหล  สมมติฐานระบุว่าการรั่วไหลอาจเกิดจากส่วนประกอบหลักของเครื่องบินที่กำลังไหม้  หลักฐานสนับสนุนสมมติฐานโดยการเสนอสาเหตุที่เป็นไปได้หนึ่งสาเหตุสำหรับการรั่วไหล  ดังนั้นจึงมีความเกี่ยวข้องกัน\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นเพียงว่าพลอากาศเอกหนึ่งคนเกษียณอายุแล้ว  สมมติฐานระบุว่า *ทุกคน* ที่เป็นผู้นำกองทัพอากาศของอเมริกาได้เกษียณแล้ว  หลักฐานจึงไม่สนับสนุนและไม่ขัดแย้งกับสมมติฐานอย่างสมบูรณ์  มันเป็นเพียงส่วนเล็กๆ ของข้อมูลที่อาจสนับสนุนหรือขัดแย้งกับสมมติฐานได้  ดังนั้นคำตอบที่ดีที่สุดคือ 2 (ความขัดแย้ง)\n', '2\n', '2\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานพูดถึงการเพิ่มขึ้นของเที่ยวบินที่ไม่สามารถอธิบายได้  สมมติฐานกล่าวถึงการเพิ่มขึ้นของการจราจรที่เป็นปัญหา  ทั้งสองอย่างมีความเกี่ยวข้องกันเพราะการเพิ่มขึ้นของเที่ยวบินอาจเป็นสาเหตุของปัญหาการจราจรที่เพิ่มขึ้น  อย่างไรก็ตาม หลักฐานไม่ได้พิสูจน์สมมติฐาน  มันเพียงแค่บ่งบอกถึงความเป็นไปได้เท่านั้น\n', '2\n', '2\n', '1\n', 'หลักฐานบ่งชี้ว่ามีการฝึกอบรมในชุดสูทความดันอากาศ ซึ่งสนับสนุนสมมติฐานว่าจะได้รับการฝึกฝนให้สวมชุดแรงดันสูง ดังนั้นคำตอบจึงคือ **0**\n', 'คำตอบคือ 1\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐาน\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐาน "มี ไม่มี:และ<unk>มันเหมือนกันกับสิ่งที่ฉันพยายามที่จะทําสมมติฐาน:เห็นได้อย่างชัดเจนว่าฉันพยายามที่จะทําสิ่งนี้" สนับสนุนสมมติฐานที่ว่าผู้พูดกำลังพยายามทำอะไรบางอย่าง  ประโยคแสดงให้เห็นว่าผู้พูดตระหนักถึงความพยายามของตนเอง  ดังนั้นหลักฐานนี้จึงสนับสนุนสมมติฐานอย่างเต็มที่\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าจำเป็นต้องมีจำนวนรวมเพื่อแก้ปัญหา  ซึ่งสนับสนุนสมมติฐานที่ว่าจำเป็นต้องมียอดรวมเพื่อแก้ปัญหา\n', '2\n', "คำตอบคือ 1\n\nหลักฐานระบุว่าผู้เขียนพยายามทำการคาดการณ์โดยใช้ข้อมูลบางส่วน ('ผล [2] นั้น')  สมมติฐานนั้นระบุว่าผู้เขียนจะเลือกบางสิ่งจากแหล่งข้อมูลที่ไม่รู้จัก ('<unk>รวม').  แม้ว่ารายละเอียดจะไม่ตรงกันเป๊ะ แต่หลักฐานก็สนับสนุนแนวคิดทั่วไปของสมมติฐาน ซึ่งคือการเลือกและคาดการณ์บางสิ่งจากข้อมูลที่มีอยู่\n\nดังนั้นจึงเลือก 1 (ทั้ง)\n", 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นถึงทั้งความผิดหวังและความสุขในเวลาเดียวกัน  นี่เข้ากันได้กับสมมติฐานที่ว่าเขา *ทั้ง* ผิดหวัง *และ* มีความสุข', '1\n', '0\n', '0\n', '2\n', '2\n', '0\n', '1\n', '2\n', '0\n', '2\n', '0\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานที่ว่า "อุบัติเหตุคือความจริง ความสว่าง!" ไม่เกี่ยวข้องกับสมมติฐานที่ว่า "เธอไม่ได้หนักขนาดนั้น"  ทั้งสองประโยคไม่เกี่ยวข้องกันทางตรรกะ  หลักฐานไม่สนับสนุนหรือหักล้างสมมติฐานเลย\n', '2\n', 'คำตอบคือ 0\n', '0\n', '0\n', '0\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าพวกเขาไม่เคยแจ้งให้ทราบถึงสถานที่ราคาถูกที่พวกเขาสร้างแม้กระทั่งเมื่อพวกเขาย้ายออกไป สมมติฐานระบุว่าพวกเขามักจะแจ้งให้ทราบว่าเราอยู่ที่ไหนในปีจะไปที่ไหน หลักฐานและสมมติฐานจึงขัดแย้งกัน\n', 'คำตอบคือ 2 (ความขัดแย้ง)\n\nหลักฐานระบุว่าพวกเขาไม่ได้บอกว่าพวกเขาจะไปไหน  ซึ่งขัดแย้งกับสมมติฐานที่ว่าพวกเขา *ไม่เคย* บอกเราว่าพวกเขาจะไปไหน  หลักฐานแสดงให้เห็นว่าพวกเขา *อาจ* จะบอกเราบ้าง แต่พวกเขาไม่ได้บอกทั้งหมด  ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน\n', '2\n', '0\n', '0\n', '0\n', '2\n', '0\n', '2\n', '2\n', '0\n', '0\n', '0\n', '2\n', '0\n', '2\n', '0\n', 'ฉันไม่สามารถระบุได้ว่าหลักฐานนั้นเกี่ยวข้องหรือขัดแย้งกับสมมติฐานใดๆ เพราะหลักฐานที่ให้มานั้นไม่สมบูรณ์และไม่ชัดเจน  มีคำว่า "<unk>" อยู่หลายที่ ทำให้ไม่สามารถเข้าใจบริบทและความหมายของข้อความได้  ดังนั้นจึงไม่สามารถให้คำตอบได้ว่าเป็น \'0\', \'1\' หรือ \'2\'\n', '0\n', '2\n', '0\n', 'คำตอบคือ 1\n\nหลักฐานที่ว่ายายของคุณเคยพูดถึงเพื่อนและครอบครัวของพวกเขาในวัยเด็กนั้นเกี่ยวข้องกับสมมติฐานที่ว่ายายของคุณปฏิเสธที่จะพูดคุยเกี่ยวกับวัยเด็กของเธอ  มันแสดงให้เห็นว่ายายของคุณอาจพูดถึงบางแง่มุมของวัยเด็กของเธอ แต่ไม่ใช่ทั้งหมด  หรืออาจมีสิ่งที่เธอเลือกที่จะไม่พูดถึง  ดังนั้น หลักฐานนี้จึงสนับสนุนสมมติฐานบางส่วน ไม่ใช่ทั้งหมด\n', 'คำตอบคือ 2\n\nหลักฐานชิ้นแรกพูดถึงเรื่องราวที่เล่าโดยคุณยายเกี่ยวกับครอบครัวของเธอ *ในอดีต* ในปี 1985 ในขณะที่หลักฐานชิ้นที่สองพูดถึงคุณยายคนหนึ่งที่บอกเล่าเกี่ยวกับครอบครัวของเธอ *ในอนาคต*  นี่จึงเป็นข้อมูลที่ขัดแย้งกัน\n', '2\n', 'คำตอบคือ 1 (ทั้งสองอย่าง)\n\nหลักฐานสนับสนุนสมมติฐานที่ว่าชุดมีลักษณะคล้ายกับชุดนักบินอวกาศและนักบิน แต่ยังเพิ่มข้อมูลเพิ่มเติมเกี่ยวกับคุณสมบัติการสะท้อนแสงและสีของชุด', '2\n', '2\n', '2\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐานอย่างชัดเจน  ข้อความระบุว่ามีการฝึกนักบินอังกฤษร่วมกับพันธมิตรทั่วโลก ซึ่งสอดคล้องกับการฝึกอบรมร่วมกับทหารชาติอื่นๆ\n', '2\n', 'คำตอบคือ 0\n\nหลักฐาน "เพราะ &:ดังนั้น, เธอเป็น<_>, ดูดีๆ, ดูบริษัทดังกล่าว" ไม่ได้สนับสนุนหรือขัดแย้งโดยตรงกับสมมติฐาน "เธอบอกให้ฉันหาบางสิ่งบางอย่าง"  มันให้บริบทบางอย่างเกี่ยวกับตัวเธอ แต่ไม่ได้เกี่ยวข้องกับการกระทำของการขอให้คนอื่นหาอะไรบางอย่าง\n', '2\n', 'คำตอบคือ 0 (เกี่ยวข้อง)\n\nหลักฐานระบุว่าพวกเขาเดินทางไปทางเหนือ และมีการหยุดพักหลายครั้งระหว่างทาง  ทั้งสองส่วนเกี่ยวข้องกับการเดินทาง  แม้จะไม่ได้สนับสนุนหรือขัดแย้งโดยตรงกับสมมติฐานที่ครอบคลุมทั้งหมด แต่ก็ให้ข้อมูลที่เกี่ยวข้องกับเหตุการณ์การเดินทาง\n', '2\n', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้พูดอยากอ่านหนังสือเล่มใดเล่มหนึ่ง  สมมติฐานระบุว่าผู้พูดไม่เคยซื้อหนังสือที่ยาวกว่าหนึ่งร้อยหน้า  ทั้งสองข้อความนั้นไม่เกี่ยวข้องกันโดยตรง  ความต้องการที่จะอ่านหนังสือเล่มใดเล่มหนึ่งไม่ได้หมายความว่าผู้พูดจะต้องซื้อหรือเคยซื้อหนังสือเล่มนั้น  และความจริงที่ว่าผู้พูดไม่เคยซื้อหนังสือที่มีความยาวมากกว่าหนึ่งร้อยหน้าไม่ได้บอกอะไรเกี่ยวกับความต้องการที่จะอ่านหนังสือเล่มใดเล่มหนึ่ง\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าผู้เขียนไม่ได้สังเกตเห็นบทความใดๆ ที่ควรคัดลอก  ซึ่งไม่เกี่ยวข้องโดยตรงกับสมมติฐานที่ว่าพวกเขาไม่ได้อ่านหนังสือมากมาย  แม้ว่าจะสามารถเป็นไปได้ที่การอ่านหนังสือไม่มากจะทำให้ไม่พบกับบทความเหล่านั้น  แต่ความสัมพันธ์นั้นไม่ใช่สิ่งที่ตรงไปตรงมาหรือชัดเจน  ดังนั้นจึงไม่สามารถจัดเป็นการสนับสนุนหรือการขัดแย้งได้\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานแสดงให้เห็นว่าผู้บรรยายหยิบสิ่งของขึ้นมา  ซึ่งขัดแย้งกับสมมติฐานที่ว่าผู้บรรยายคิดว่าการไม่มีกระเป๋าไม่ใช่ปัญหาของตนเอง  การหยิบสิ่งของขึ้นมาบ่งบอกว่าผู้บรรยายพบกับปัญหาในการพกพาสิ่งของนั้น  ซึ่งขัดแย้งกับความเชื่อเดิมของตน\n', '0\n', '2\n', '2\n', '0\n', '2\n', 'คำตอบคือ 1\n', '2\n', '2\n', '2\n', 'คำตอบคือ 0\n\nหลักฐานแสดงให้เห็นว่านักบินต้องผ่านการฝึกอบรมก่อนการบิน ซึ่งสอดคล้องกับสมมติฐานที่ว่าพวกเขาต้องผ่านการฝึกอบรมเป็นจำนวนมากก่อนการบิน  รายละเอียดอื่นๆในหลักฐาน (หมายเลขห้อง, ชุดสูทแรงดัน) ไม่ได้ขัดแย้งกับสมมติฐาน\n', '2\n', '2\n', '2\n', '0\n', 'หลักฐานกล่าวถึงการลงคะแนนเสียงของสภาเท็กซัสเพื่อให้หน่วยทหารเป็นหน่วยทูตเท็กซัส  อย่างไรก็ตาม หลักฐานไม่ได้ระบุว่าหน่วยทหารสหรัฐฯอนุญาตให้เป็นเช่นนั้นหรือไม่  ดังนั้นจึงไม่รองรับหรือขัดแย้งกับสมมติฐาน  คำตอบจึงเป็น **0**\n', '0\n', '0\n', '1\n', 'คำตอบคือ 1\n', '2\n', 'หลักฐานสนับสนุนสมมติฐาน  คำตอบคือ 1\n', 'คำตอบคือ 1\nหลักฐานสนับสนุนสมมติฐานอย่างชัดเจน เพราะการโกหกอย่างต่อเนื่องแสดงให้เห็นว่าน้องสาวของเธอมองว่าน้องสาวของเธอไม่สามารถทำอะไรได้ถูกต้อง\n', '0\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าผู้ส่งข้อความและโทรไปที่บ้านของบุคคลนั้น สมมติฐานระบุว่าผู้ส่งโทรหาพ่อแม่เมื่อมาถึงบ้าน  สิ่งเหล่านี้ไม่สอดคล้องกัน  สมมติฐานอาจเป็นจริงได้หากบ้านของบุคคลนั้นเป็นบ้านของพ่อแม่  แต่หลักฐานไม่รองรับสมมติฐานนั้น  ดังนั้นจึงถือว่าขัดแย้งกัน\n', 'คำตอบคือ 1\n\nหลักฐานระบุว่าผู้พูดนั้นขี้เกียจเกินกว่าจะไปบ้านและโทรหาหมายเลขที่ไม่ระบุตัวตนเมื่อมาถึงที่บ้าน  สมมติฐานกล่าวว่าพวกเขา *ควร* โทร แต่โทรศัพท์ของพวกเขาทำเช่นนั้นไม่ได้  หลักฐานรองรับบางส่วนของสมมติฐานโดยแสดงให้เห็นถึงความพยายามที่จะโทรโดยใช้โทรศัพท์  แม้ว่าจะมีความไม่ลงรอยกันระหว่างความขี้เกียจของผู้พูดกับความจำเป็นในการโทร', 'คำตอบคือ 2\n\nหลักฐานระบุว่าช่างเชื่อว่าเขาอยู่ที่นั่นในตอนเช้าและได้พบกับบุคคลนั้น สมมติฐานระบุว่าเขาไม่ได้ไปที่นั่นในวันนั้น ดังนั้นหลักฐานจึงขัดแย้งกับสมมติฐาน', '0\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าพยานอยู่ในสถานที่นั้นในฤดูกาลนั้น แต่ไม่สามารถจำรายละเอียดได้อย่างชัดเจน สมมติฐานระบุว่าพยานและบุคคลที่สองมาที่สถานที่นั้นในเดือนกุมภาพันธ์ หลักฐานไม่ได้ยืนยันหรือปฏิเสธสมมติฐาน', '2\n', '2\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่าเราไม่รู้ว่าพวกเขากำลังสร้างสมมติฐานใดๆ  สมมติฐานที่ถูกกล่าวถึงนั้นไม่มีการระบุ  ดังนั้น หลักฐานจึงไม่สามารถสนับสนุนหรือขัดแย้งกับสมมติฐานใดๆ ได้  แต่เนื่องจากสมมติฐานถูกตั้งขึ้นโดยปริยาย  หลักฐานจึงขัดแย้งกับมัน\n', '2\n', '0\n', 'คำตอบคือ 1\n', 'คำตอบคือ 1\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าบุคคลนั้นกำลังดิ้นรนทางอารมณ์กับบางสิ่งบางอย่างถึงขั้นที่พวกเขาคิดที่จะยอมแพ้  นี่สนับสนุนสมมติฐานที่ว่าพวกเขากำลังทุกข์ทรมานจากบางสิ่งบางอย่าง', '2\n', 'คำตอบคือ 0\nหลักฐานระบุว่าบุคคลนั้นเกิดในปี 1880 บวกหรือลบไม่กี่ปี  ซึ่งยังคงอยู่ในช่วงก่อนปี 1900 สมมติฐานระบุว่าบุคคลนั้นเกิดก่อนปี ค.ศ. 1900 หลักฐานจึงสนับสนุนสมมติฐาน\n', 'คำตอบคือ 0\n\nหลักฐานระบุว่าเขาเกิดในปี 1880 แต่ไม่ได้ให้ข้อมูลเกี่ยวกับเดือนที่แน่นอน  สมมติฐานระบุเดือนที่เกิดเป็นมกราคมถึงธันวาคม ปี 1880  หลักฐานจึงไม่ขัดแย้งกับสมมติฐาน แต่ก็ไม่สนับสนุนสมมติฐานอย่างเต็มที่เช่นกัน  ดังนั้นจึงเป็นความเกี่ยวข้องบางส่วน\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n\nหลักฐานสนับสนุนสมมติฐานว่าการขันสกรูเข้าไปอาจทำให้ปอดเสียหายได้  เอกซเรย์ปอดแสดงให้เห็นว่าสกรูเข้าไปในหลอดลมซึ่งเป็นอันตรายต่อปอด\n', 'คำตอบคือ 1\n\nหลักฐานแสดงให้เห็นว่าผู้พูดได้รับคำสั่งไปยัง "akael <unk>io" และในที่สุดก็ไปถึงฐานทัพอากาศ " <unk>💕ughlin" สมมติฐานระบุว่าผู้พูดถูกส่งไปที่ "el <unk>io เท็กซัสเพื่อทำงาน" แม้ว่าจะมีข้อมูลที่หายไป (<unk>) แต่หลักฐานสนับสนุนสมมติฐานเนื่องจากทั้งสองอย่างบ่งชี้ถึงการส่งไปยังสถานที่ที่เฉพาะเจาะจงเพื่อทำงาน  จึงเป็นไปได้สูงว่า "<unk>io" คือ Texas และ "<unk>ughlin" เป็นฐานทัพอากาศใน Texas\n', '2\n', '2\n', '2\n', 'คำตอบคือ 1\n', 'คำตอบคือ 2\n\nหลักฐานระบุว่ามีการเสิร์ฟแชมเปญ (แอลกอฮอล์) แก่เด็กๆ ซึ่งขัดแย้งกับสมมติฐานที่ว่างานเลี้ยงไม่มีการเสิร์ฟแอลกอฮอล์\n', '2\n', '2\n', '0\n', '2\n', '2\n', '2\n', '2\n', '2\n', '0\n', '2\n', '1\n']
Saved predictions to: predicted_5.json
Number of missing values in 'true': 0
Number of missing values in 'predicted': 1
Accuracy th: 0.45226130653266333
'XNLI' object has no attribute 'evaluate_results'
