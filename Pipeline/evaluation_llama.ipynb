{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T13:47:57.601119600Z",
     "start_time": "2024-09-21T13:47:57.597667500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import replicate\n",
    "import numpy as np"
   ],
   "id": "40a0c66ff49d6be1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T13:47:59.195355900Z",
     "start_time": "2024-09-21T13:47:58.091727200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Multi-EURLEX dataset\n",
    "dataset = load_dataset('multi_eurlex', 'all_languages', split='test')\n",
    "\n",
    "# Define label options (21 categories)\n",
    "label_options = [\n",
    "    \"POLITICS\", \"INTERNATIONAL RELATIONS\", \"EUROPEAN UNION\", \"LAW\", \"ECONOMICS\",\n",
    "    \"TRADE\", \"FINANCE\", \"SOCIAL QUESTIONS\", \"EDUCATION AND COMMUNICATIONS\", \"SCIENCE\",\n",
    "    \"BUSINESS AND COMPETITION\", \"EMPLOYMENT AND WORKING CONDITIONS\", \"TRANSPORT\",\n",
    "    \"ENVIRONMENT\", \"AGRICULTURE, FORESTRY AND FISHERIES\", \"AGRI-FOODSTUFFS\",\n",
    "    \"PRODUCTION, TECHNOLOGY AND RESEARCH\", \"ENERGY\", \"INDUSTRY\", \"GEOGRAPHY\",\n",
    "    \"INTERNATIONAL ORGANISATIONS\"\n",
    "]\n",
    "\n",
    "# Preprocess the dataset and map true labels to category numbers\n",
    "def preprocess_dataset(dataset, label_options):\n",
    "    preprocessed_data = []\n",
    "    for item in dataset:\n",
    "        text = item['text']['en']  # Extract English text\n",
    "        labels = item['labels']    # True label numbers\n",
    "        preprocessed_data.append({\"text\": text, \"labels\": labels})\n",
    "    return preprocessed_data\n",
    "    # return preprocessed_data[:15]"
   ],
   "id": "e8c0102d5b4dca76",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\andre\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\multi_eurlex\\5a12a7463045d4dcb12896b478c09b5a8a131a02b7e7bce059ba7ececc6584ee (last modified on Sat Sep 14 15:48:28 2024) since it couldn't be found locally at multi_eurlex, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def unify_string(string_list):\n",
    "    # Join the list of strings into one unified string with no separator\n",
    "    unified_string = ''.join(string_list)\n",
    "\n",
    "    # Optionally, strip leading/trailing spaces\n",
    "    return unified_string.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T13:49:57.987996500Z",
     "start_time": "2024-09-21T13:49:57.982713800Z"
    }
   },
   "id": "21dbe7f9e40b5d30"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Initialize the client with the token\n",
    "client = replicate.Client(api_token=os.getenv(\"REPLICATE_API_TOKEN\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T13:49:58.224148900Z",
     "start_time": "2024-09-21T13:49:58.218654700Z"
    }
   },
   "id": "934b9771c3431b18"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def classify_text_with_llama_in_chunks(text, label_options, chunk_size=4096):\n",
    "    prompt_template = \"ONLY GIVE THE CATEGORIES IN YOUR ANSWER. Classify the following text into one or more of these categories: {}. Text: {}.\"\n",
    "    \n",
    "    def chunk_text(text, chunk_size):\n",
    "        # Split the text into smaller chunks of size chunk_size\n",
    "        words = text.split()  # Split by spaces to preserve words\n",
    "        chunks = []\n",
    "        \n",
    "        # Create chunks of words with a rough size of chunk_size\n",
    "        current_chunk = []\n",
    "        current_size = 0\n",
    "        \n",
    "        for word in words:\n",
    "            current_size += len(word) + 1  # +1 for the space\n",
    "            if current_size > chunk_size:\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "                current_chunk = []\n",
    "                current_size = len(word) + 1  # Reset size for the new chunk\n",
    "            current_chunk.append(word)\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(' '.join(current_chunk))  # Add the last chunk\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "    # Split the text into manageable chunks\n",
    "    text_chunks = chunk_text(text, chunk_size)\n",
    "    accumulated_response = []\n",
    "\n",
    "    # Loop through the chunks and call the model on each one\n",
    "    for i, chunk in enumerate(text_chunks):\n",
    "        prompt = prompt_template.format(', '.join(label_options), chunk)\n",
    "        \n",
    "        try:\n",
    "            output = client.run(\"meta/llama-2-7b-chat\", input={\"prompt\": prompt})\n",
    "            response = unify_string(output)\n",
    "\n",
    "            if response:\n",
    "                accumulated_response.append(response)\n",
    "            else:\n",
    "                print(f\"Error: No response from the API for chunk {i+1}.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Exception during API call for chunk {i+1}: {e}\")\n",
    "    \n",
    "    # Return all classifications accumulated from all chunks\n",
    "    print(\"Accumulated response: \", accumulated_response)\n",
    "    return ' '.join(accumulated_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T13:49:58.407202300Z",
     "start_time": "2024-09-21T13:49:58.399861200Z"
    }
   },
   "id": "6379db87d37e30a5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Extract relevant labels from LLaMa's output\n",
    "def extract_labels_from_generated_text(generated_text, label_options):\n",
    "    relevant_labels = []\n",
    "    for label in label_options:\n",
    "        if label.lower() in generated_text.lower():\n",
    "            relevant_labels.append(label)\n",
    "    return relevant_labels\n",
    "\n",
    "\n",
    "# Map label names back to indices\n",
    "def map_labels_to_indices(label_names, label_options):\n",
    "    label_indices = [label_options.index(label) for label in label_names if label in label_options]\n",
    "    return label_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T13:49:58.587632300Z",
     "start_time": "2024-09-21T13:49:58.583133100Z"
    }
   },
   "id": "a85df4a0f9bb06d9"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def evaluate_llama_on_dataset(dataset, label_options):\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    count = 0  # Track the number of requests\n",
    "\n",
    "    print(len(dataset))\n",
    "    i=0\n",
    "    for entry in dataset:\n",
    "        if i>0:\n",
    "            break\n",
    "        text = entry['text']\n",
    "        true_labels = entry['labels']\n",
    "        generated_text = classify_text_with_llama_in_chunks(text, label_options)\n",
    "        predicted_label_names = extract_labels_from_generated_text(generated_text, label_options)\n",
    "        predicted_labels = map_labels_to_indices(predicted_label_names, label_options)\n",
    "\n",
    "        # Store true and predicted labels for comparison\n",
    "        all_true_labels.append(true_labels)\n",
    "        all_predicted_labels.append(predicted_labels)\n",
    "        i+=1\n",
    "\n",
    "    return all_true_labels, all_predicted_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T13:49:58.758958500Z",
     "start_time": "2024-09-21T13:49:58.755458700Z"
    }
   },
   "id": "bac5a27e882a61cb"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "Exception during API call for chunk 1: ReplicateError Details:\n",
      "title: Unauthenticated\n",
      "status: 401\n",
      "detail: You did not pass an authentication token\n",
      "Accumulated response:  []\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "preprocessed_data = preprocess_dataset(dataset, label_options)\n",
    "\n",
    "# Run the evaluation on the entire preprocessed dataset using Gemini\n",
    "true_labels, predicted_labels = evaluate_llama_on_dataset(preprocessed_data, label_options)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T13:50:02.413033700Z",
     "start_time": "2024-09-21T13:49:58.938843700Z"
    }
   },
   "id": "65e4f1c69c1499bc"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Convert true and predicted labels to binary format using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=list(range(len(label_options))))\n",
    "\n",
    "# Binarize the true and predicted labels\n",
    "binary_true = mlb.fit_transform(true_labels)\n",
    "binary_pred = mlb.transform(predicted_labels)\n",
    "\n",
    "# Get indices of labels with non-zero true or predicted samples\n",
    "relevant_labels = np.where((binary_true.sum(axis=0) + binary_pred.sum(axis=0)) > 0)[0]\n",
    "\n",
    "# Filter binary_true and binary_pred to only include relevant labels\n",
    "filtered_binary_true = binary_true[:, relevant_labels]\n",
    "filtered_binary_pred = binary_pred[:, relevant_labels]\n",
    "\n",
    "# Calculate precision, recall, F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    filtered_binary_true, filtered_binary_pred, average='macro', zero_division=0\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T13:48:07.194041100Z",
     "start_time": "2024-09-21T13:48:07.186889800Z"
    }
   },
   "id": "3b950f2fce84c680"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
